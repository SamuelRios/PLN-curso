Pseudonomização em Textos Legais de acordo com a LGPD: Uma Abordagem de Reconhecimento de Entidades Nomeadas

Marcelo Anselmo1[0009−0005−1145−3501] e Bruno César Ribas2[0000−0001−6314−1511]

1 Departamento de Ciência da Computação, Universidade de Brasília, Brasília, Brasil - marcelo.anselmo@aluno.unb.br
2 Departamento de Ciência da Computação, Universidade de Brasília, Brasília, Brasil - bruno.ribas@unb.br

Resumo. Este estudo explora a aplicação do Reconhecimento de Entidades Nomeadas (REN) para a pseudonomização de dados em textos legais, com o objetivo de proteger Informações de Identificação Pessoal (IIP) em conformidade com a Lei Geral de Proteção de Dados Pessoais (LGPD) do Brasil. A pesquisa destaca o desafio de equilibrar a privacidade de dados e sua utilidade, apresentando uma metodologia que utiliza tecnologias de inteligência artificial para identificar e obscurecer IIP em documentos legais de forma eﬁcaz. Neste estudo, propomos um modelo de Transformador associado a técnicas de Regex para identificar entidades em um texto. Para testar o modelo, criamos um novo conjunto de dados a partir do conjunto de dados existente LenerBR. Além disso, utilizamos uma função e engenharia de prompt aplicada ao modelo Llama 8B versão 3 para gerar dados sintéticos. Os testes mostraram a necessidade de ajustes adicionais no modelo proposto. O futuro trabalho se concentrará em melhorar a precisão e eﬁciência do modelo, bem como na identificação de dados sensíveis e aprendizado com interações de usuários.

Palavras-chave: Pseudonomização de Dados · Reconhecimento de Entidades Nomeadas · Privacidade de Informação · Textos Legais · LGPD · Transformador.
Essa prática não apenas permite a personalização de experiências online, mas também expõe usuários a riscos de privacidade, incluindo a venda ilegal de dados nesses mercados sombrios, potencialmente para uso em atividades criminosas [3]. Esse cenário destaca a importância crítica de proteger dados pessoais, não apenas para a privacidade individual, mas também para a segurança global da sociedade. A solução para esses problemas manifestou-se por meio de regulamentações e leis dedicadas à proteção de dados, como a Regulamentação Geral de Proteção de Dados (RGPD) na União Europeia e a Lei Geral de Proteção de Dados (LGPD) no Brasil [9].

O principal problema abordado nesse trabalho é a dificuldade de equilibrar a privacidade individual com a necessidade de usar suas informações em textos legais e administrativos. Esse problema se aprofunda quando se trata de identificar e esconder informações pessoais sensíveis (PII) sem comprometer a integridade e a utilidade dos dados. Usando recursos como modelos de Transformer e técnicas de Regex, um equilíbrio efeito entre privacidade e utilidade é buscado, como já foi alcançado em outros estudos, como o trabalho de G. M. GR, S. Abhi e R. Agarwal [5].

O objetivo desse estudo é investigar e demonstrar a efeicácia da Reconhecimento de Entidades Nomeadas (NER) aplicada à pseudonomização de PII em documentos legais. Propõe-se desenvolver e testar um modelo capaz de identificar e esconder eficientemente entidades nomeadas que correspondem a PII. A Figura 1 ilustra o pipeline adotado em nossa metodologia.

Outra nota importante é a Resolução CNMP nº 281, datada de 12 de dezembro de 2023, em seu Artigo 79, que apresenta a pseudonomização como alternativa para proteger os dados pessoais de pessoas naturais em procedimentos ou processos dentro do Ministério Público Federal.

Fig. 1. Pipeline adotado em nossa metodologia

Os textos legais são frequentemente longos e complexos, priorizando a formalidade sobre a legibilidade [12].
No entanto, a implementação de técnicas avançadas, como modelos de inteligência artificial, frequentemente depende de grandes volumes de dados anotados para treinamento, o que pode ser desafiador em termos de custo e tempo [13]. Considerando isso, enfrentamos um desafio fundamental: a necessidade de dados serem rotulados de forma confiável e eficiente. Tradicionalmente, esse rotulamento é feito manualmente, um processo que, apesar de melhorar a precisão dos modelos de inteligência artificial, é notoriamente tempo-consumidor e caro [4]. Esse cenário impõe um alto custo em termos de tempo, dinheiro e esforço, limitando a escalabilidade das soluções. Este artigo está estruturado da seguinte forma: Seção 2 apresenta os conceitos de fundo, cobrindo conceitos fundamentais, como os relacionados à proteção de dados pessoais e pseudonomização. Seção 3 descreve o trabalho relacionado, destacando estudos anteriores que abordaram problemas semelhantes. Seção 4 apresenta a metodologia proposta, detalhando os dados utilizados, ferramentas e termos utilizados. Seção 5 discute os resultados esperados para cada conjunto de testes. Finalmente, Seção 6 apresenta as conclusões e sugestões para trabalho futuro.

2 Conceitos de Fundo

2.1 Lei Geral de Proteção de Dados (LGPD)

A Lei Geral de Proteção de Dados (LGPD, Lei nº 13.709, de 14 de agosto de 2018) do Brasil é uma regulamentação que estabelece diretrizes para a coleta, uso, processamento e armazenamento de dados pessoais. A lei concede aos indivíduos mais controle sobre suas informações pessoais, ao mesmo tempo em que equilibra direitos de privacidade com avanços tecnológicos. A LGPD exige que qualquer operação envolvendo dados pessoais seja baseada em justificativas legais claras e respeite princípios estritos, como propósito, adequação e necessidade [3].

2.2 Dados Pessoais (DP)

Dados pessoais (LGPD, Art. 5, I) se referem à informação que identifica ou pode identificar diretamente ou indiretamente uma pessoa natural.
Essa definição é ampla e inclui variedade de tipos de informações, desde nomes e identidades digitais até características físicas e eletrônicas, como fotos e dados de localização. Essa informação é crucial na sociedade digital, sendo utilizada em vários contextos, desde a verificação de identidade até a personalização de serviços. No entanto, lidar com ela envolve riscos significativos de privacidade, o que requer medidas de proteção robustas para garantir a segurança e confidencialidade dos dados 5. 2.3 Anonimização vs. Pseudonimização Anonimização e pseudonimização são dois conceitos fundamentais na gestão de privacidade de dados. Anonimização (LGPD, Art. 5, XI) refere-se ao processo 4 https://www.planalto.gov.br/ccivil_03/_ato2015-2018/2018/lei/l13709.htm 5 https://www.serpro.gov.br/lgpd/menu/protecao-de-dados/dados-pessoais-lgpd 4 M. Anselmo e B. Ribas pelo qual os dados pessoais são processados para remover a capacidade de associar permanentemente esses dados a um indivíduo específico, sem usar informações adicionais. Isso significa que, uma vez anonimizados, os dados não podem ser relacionados novamente ao proprietário, mesmo com o uso de meios técnicos razoáveis. Esse processo é irreversível, garantindo um alto nível de proteção para a identidade individual. Por outro lado, a pseudonimização (LGPD, Art. 13, § 4) é uma técnica que modifica os dados pessoais de forma que a identificação do proprietário não possa ser feita sem usar informações adicionais, que são mantidas separadamente e sob medidas de segurança estritas pelo controlador de dados. Diferentemente da anonimização, a pseudonimização é reversível, desde que as informações adicionais sejam tornadas disponíveis 6. Esse método será adotado nesse trabalho, pois permite proteger os dados sem perder sua utilidade para análise e pesquisa. 2.4 Geração de Texto com Recuperação de Informação (RAG) A RAG é uma abordagem avançada em modelos de processamento de linguagem natural (NLP) que integra a recuperação de informações com a geração de texto [6].
Este método permite que o modelo recupere documentos relevantes que são utilizados para informar a geração de texto subsequente. A habilidade única do RAG para combinar memória paramétrica e não-paramétrica permite que ele adapte tanto a recuperação quanto a geração de conteúdo para tarefas NLP específicas, melhorando a precisão e a relevância da informação gerada. Ao utilizar o RAG, podemos incorporar uma vasta quantidade de informações legais pré-existentes para melhorar a qualidade do nosso conjunto de dados gerados.

3 Trabalhos Relacionados

No artigo de Patsakis e Lykousas (2023) [11], os autores exploram o desafio de anonimizar efetivamente o texto na era dos grandes modelos de linguagem. Este estudo questiona a eﬀicácia dessas abordagens e avalia sua capacidade de prevenir a identificação, especialmente com o uso de inteligência artificial em grandes conjuntos de dados. Um experimento é conduzido usando GPT em textos anonimizados de personalidades bem conhecidas para verificar se esses modelos de linguagem podem reidentificar indivíduos. Eles argumentam que, apesar dos avanços tecnológicos, ainda há obstáculos significativos em proteger a privacidade de dados em textos processados por essas ferramentas.

No trabalho de de Andrade et al. (2023) [1], os autores apresentam uma abordagem chamada PromptNER, que se concentra em NER em dados sensíveis usando instâncias rotuladas automaticamente. Os autores propõem uma abordagem que emprega LLMs para identificar entidades em queixas e, em seguida, treina modelos mais simples como o método SpERT. O modelo de NER aprimorado apresenta melhoras substanciais no F-score, variando de 41% a 129% em comparação com modelos que utilizam apenas dados rotulados manualmente. Este estudo é crucial porque combina métodos de inteligência artificial para melhorar a eficiência em identificar e manipular dados pessoais.
(2021) [7] investigam o uso de redes neurais para reconhecimento de entidades nomeadas em documentos legais em português. Os autores utilizaram bibliotecas Spacy e FLAIR. Seus resultados demonstram a capacidade dessas tecnologias avançadas de lidar com a complexidade linguística do português, fornecendo uma base técnica para o desenvolvimento de soluções mais efeitos. Nunes e dos Santos (2023) [9] discutem a aplicação e impacto da LGPD no contexto brasileiro, focalizando em uma abordagem tecnológica e agnóstica. Eles enfatizam a necessidade das organizações se adaptarem às exigências legais e a importância de implementar medidas efeitos para proteger dados pessoais. Este estudo destaca que implementar a LGPD requer uma abordagem técnica e organizacional integral. Multiplos ferramentas, como Sistemas de Gerenciamento de Dados (DMS), anonimização, pseudonomização, criptografia e auditoria, são destacadas como essenciais para conformidade. Técnicas como Big Data e Aprendizado de Máquina podem melhorar a conformidade, enquanto privacidade por design e eDiscovery são enfatizados como críticas para proteger dados. GR, Shinu e Agarwal (2023) [5] apresentaram um modelo híbrido que combina RegEx e NER para análise e matching de currículos. Este trabalho ilustra a aplicabilidade de técnicas de NER ao lado de expressões regulares para extrair e processar informações de forma eficiente em documentos estruturados como currículos. A metodologia proposta é relevante para nosso estudo, pois demonstra a eficácia de integrar NER e RegEx em tarefas de identificação de dados e pseudonomização. Luz de Araujo et al. (2018) [2] desenvolveram LeNER-BR, um conjunto de dados especificamente para Reconhecimento de Entidades Nomeadas em textos legais brasileiros. Seus resultados fornecem uma base essencial para validar modelos de NER no contexto legal brasileiro. O conjunto de dados que propuseram serve como recurso valioso para treinar e testar novas metodologias, incluindo o abordagem do nosso estudo.
(2024) [10] investigou a combinação de modelos de linguagem baseados em prompts e supervisão fraca para rotular a tarefa de Reconhecimento de Entidades Nomeadas (REN) em documentos legais. Eles destacaram a eﬀicácia de suas técnicas em melhorar a precisão e a automação do processo de REN, que é crucial para a pseudonomização de dados em conformidade com as regulamentações de privacidade.

4 Metodologia

4.1 Dados Pessoais Usados

Categorizamos termos de acordo com alguns tipos de Dados Pessoais (DP). É importante notar que o espectro de termos é muito mais amplo do que aqueles discutidos nesse estudo, no entanto, destacamos alguns termos populares. Observe que o CPF é um número de identidade brasileiro. Os termos utilizados para gerar dados sintéticos estão apresentados na Tabela 1 abaixo.

Tabela 1. Termos Selecionados para Identificação de Dados Pessoais (DP)

Termo Exemplo
NOME João da Silva
DATA 12 de janeiro de 2013
ENDEREÇO Rua do Alecrim, 0
CPF 123.456.789-00
TELEFONE (11) 99999-9999
EMAIL example@example.com
DINHEIRO R$ 1.000,00
CEP 12345-678

4.2 Conjunto de Dados

Para esse estudo, utilizamos o conjunto de dados LenerBR derivado do estudo de Luz de Araujo e Pedro Henrique [2] e disponível em [8]. Esse conjunto de dados consiste exclusivamente de documentos legais. Ele inclui rótulos para pessoas, lugares, entidades temporais e organizações, bem como etiquetas específicas para entidades legais e processos judiciais. Utilizamos as funções da biblioteca Faker [9] para gerar dados sintéticos. A biblioteca Faker é uma ferramenta Python que gera dados falsos de acordo com a função utilizada. É útil para criar dados sintéticos para testes e prototipagem. Criamos uma função Python que gera dados aleatórios para um a dois itens por termo utilizando a biblioteca Faker. A Figura 2 abaixo mostra exemplos de dados gerados por nossa função.

Fig. 2. Exemplo de dados gerados ao executar nossa função duas vezes.
As entidades em português e sua respectiva tradução para inglês, escondidas as entidades que têm a mesma tradução, são: “NOME” (NOME), “DATA” (DATA), “ENDERECO” (ENDEREÇO), “TELEFONE” (TELEFONE), “DINHEIRO” (DINHEIRO), “CEP” (CÓDIGO DE CEPOST). Como visto nas imagens anteriores, geramos dados sintéticos para o termo CPF. Para este termo, sendo um identificador pessoal, alteramos os valores do dígito de verificação. Conforme o estudo de [8], o dígito de verificação é um número calculado a partir dos outros números do CPF. É usado para verificar se o número é consistente matematicamente com os padrões definidos pelas agências competentes brasileiras. Essa ação visa garantir que sejam gerados CPF inválidos, assim evitando a exposição de dados sensíveis. Aplicamos técnicas de engenharia de prompts com RAG para criar dados sintéticos. Para esse propósito, usamos o modelo Llama versão 3 com 8 bilhões de parâmetros, um modelo de linguagem de grande escala e de código aberto da Meta. Ele está disponível gratuitamente para fins de pesquisa. Algumas das principais configurações para executar o modelo Llama foram: “temperatura=0,2” e “max_new_tokens=512”. O ambiente de teste foi uma máquina local com um GPU de 24GB de VRAM e um processador Intel I9 da 10ª geração. Para cada texto gerado, o tempo foi de cerca de 12 segundos. Essas configurações foram usadas para gerar os dados sintéticos. Nosso código está disponível em um repositório do GitHub. Um exemplo de prompt para gerar um texto sintético e a resposta a esse prompt está mostrado na Figura 3 abaixo. Fig. 3. Engenharia de prompts para gerar um exemplo sintético. Usando esse modelo de prompt da Figura 3, geramos 600 dados sintéticos de textos legais. Esses exemplos foram usados para avaliar o novo modelo proposto para LGPD.
Observamos que, mesmo com o comando passado para o prompt para usar todos os dados sintéticos, o modelo não utilizou o valor "29566719" para "CEP". Portanto, criamos uma função que remove esses dados do JSON gerado já exibido em 2.4.3 Modelo de NER para Avaliação Usamos um modelo pré-treinado BERT para reconhecimento de entidade nomeada em português, fornecido por Pierre. Esse modelo aproveitou o mesmo conjunto de dados mencionado anteriormente, o LenerBR. No entanto, nosso estudo alterou os nomes de algumas entidades exibidas no modelo original, removeu outras e adicionou novas entidades. O modelo original possuía 6 entidades, enquanto nosso modelo tem 8 entidades. As mudanças mencionadas estão apresentadas na Tabela 2 abaixo.

Tabela 2. Mudanças em entidades para o novo modelo de NER

Modelo Original Modelo Atual Situação
PESSOA NOME Alterado
TEMPO DATA Alterado
LOCAL ENDEREÇO Alterado
JURISPRUDÊNCIA Removida
LEGISLAÇÃO Removida
ORGANIZAÇÃO Removida
- CPF Adicionado
- TELEFONE Adicionado
- E-MAIL Adicionado
- DINHEIRO Adicionado
- CÓDIGO DE ZIPE Adicionado

Para as novas entidades, empregamos expressões regulares (Regex) para melhorar a precisão do NER. Regex provou ser uma técnica valiosa para identificar e substituir padrões de texto específicos (destacados no estudo [5]), como números de telefone, endereços de e-mail e outros identificadores pessoais, que não são sempre capturados por métodos de NER padrão. Essa abordagem complementar permitiu um filtro mais granular de dados adicionados, fortalecendo a eficácia da identificação ao lidar com uma ampla variedade de formatos.

5 Resultados

5.1 Avaliação do Novo Modelo de NER

Com base no conjunto de dados gerado, realizamos avaliações utilizando a pontuação F1. A tabela abaixo contém os resultados obtidos.

Tabela 3. Resultados da Avaliação

Entidade Precisão Recall F1-Score Suporte
NOME 0,73 0,83 0,777 948
DATA 0,913 0,994 0,952 856
ENDEREÇO 0,363 0,391 0,377 1135
CPF 0,988 1,0 0,994 887
TELEFONE 0,982 0,944
963 987 Correio Eletrônico 0,99 1,0 0,995 938 Dinheiro 0,971 1,0 0,985 965 Código Postal 1,0 0,526 0,69 851 Geral 0,837 0,826 0,832 - Observamos que a entidade que melhor se saiu foi o "Correio Eletrônico" com um F1-Score de 0,995, enquanto a pior foi o "ENDEREÇO" com um F1-Score de 0,377. É importante notar que o primeiro é identificado por meio de Regex, enquanto o último pelo modelo de NER. Com um simples análise do "ENDEREÇO", nossa suposição é que ele contém texto que possa ser confundido com nomes de pessoas, animais, entre muitos outros. Também há o fato de que durante o processo de geração de dados sintéticos, o modelo pode ter gerado endereços que são incomuns, o que pode ter tornado mais difícil a identificação correta. O modelo alcançou um F1-Score geral de 0,832, o que é um resultado satisfatório para um modelo de NER. A entidade "CÓDIGO POSTAL" teve um F1-Score de 0,69, o que é abaixo das expectativas. Este resultado pode ser atribuído à dificuldade do modelo em identificar corretamente códigos postais, que consistem em 8 dígitos e um hífen. O hífen não foi capturado pelo padrão de Regex inicial, pois havíamos feito o hífen obrigatório, portanto, um código postal como "12345678" não foi reconhecido. Para abordar esse problema, adicionamos uma expressão regular para também identificar códigos postais sem hífen. A tabela 4 contém os resultados obtidos após essa correção. Tabela 4. Resultados de Avaliação com Correções de Regex. Entidade Precisão Recall F1-Score Suporte NOME 0,73 0,83 0,777 948 DATA 0,913 0,994 0,952 856 ENDEREÇO 0,363 0,391 0,377 1135 CPF 0,988 1,0 0,994 887 TELEFONE 0,982 0,944 0,963 987 CORREIO ELETRÔNICO 0,99 1,0 0,995 938 DINHEIRO 0,971 1,0 0,985 965 CÓDIGO POSTAL 1,0 0,999 0,999 851 Geral 0,845 0,879 0,862 - Ao comparar as tabelas 3 e 4, podemos ver que a correção do modelo com a adição de expressões regulares para a identificação de códigos postais signiﬁcamente melhorou o F1-Score para essa entidade. O F1-Score para CÓDIGO POSTAL aumentou de 0,69 para 0,99, o que é um resultado excelente.
O F1-Score global do modelo também melhorou, de 0,83 para 0,86. Isso demonstra que adicionar expressões regulares para corrigir erros de identificação de entidade pode melhorar significativamente a precisão de identificação. É interessante notar que termos identificados usando Regex, como "CPF", "PHONE", "EMAIL", "MONEY" e "ZIP CODE", obtiveram F1-Scores que não sempre foram perfeitos. Ao investigar mais a fundo, observamos alguns comportamentos interessantes. Para essa análise, vamos focar na coluna "Entity" e nos valores identificados com Regex. Analisando o valor de "Recall" para "CPF", vemos uma pontuação de 100%, o que significa que o modelo identificou corretamente todos os casos em que "CPF" não deve aparecer. No entanto, para "Precision", o valor foi de 98,2%, indicando a porcentagem corretamente identificada. Ao analisar os casos em que o modelo errou, observamos alguns casos como o mostrado abaixo na Figura 4. Fig. 4. Problemas relativos à precisão do modelo. Isso indica que, embora tenhamos instruído o LLM a gerar texto sem criar novos termos, ele fez. Esse comportamento se repete para os outros termos Regex sobre "Precision". Quanto ao "Recall", o modelo identificou corretamente todos os casos, exceto por "PHONE", que obteve uma pontuação de 94,4%. Nesse caso, nosso modelo cometeu um erro em apenas uma instância, resultando em um falso positivo, como mostrado no exemplo na Figura 5. Ainda é válido dizer que nosso modelo proposto também identificou corretamente uma entidade de dados adicional. Dessa forma, vemos uma espécie de inversão da nossa proposta, onde nosso modelo acaba corrigindo o novo conjunto de dados, melhorando sua qualidade. Isso é um ponto positivo, pois demonstra que o modelo pode ser usado para melhorar a qualidade dos dados, mesmo se não for seu objetivo primário. Fig. 5. Problemas relativos ao "Recall" 5.2 Exemplo de Uso do Novo Modelo de NER Para o exemplo a seguir, usamos o texto sintético gerado, como mostrado na Figura 3.
Criamos uma interface utilizando Python para facilitar a pseudonomização do texto. Assim, estabelecemos um campo de entrada e dois campos de saída. O campo de entrada é para o texto original, e os campos de saída são para os termos identificados e outro para o segredo de pseudonomização. A Figura 6 abaixo contém o texto original, enquanto as Figuras 7 e 8 contêm dados relacionados aos outputs gerados. Fig. 6. Dados de Entrada 12 M. Anselmo e B. Ribas Como mostrado nas Figuras 7 e 8 abaixo, novamente está a tradução das entidades do português para o inglês: “NOME” (NOME), “DATA” (DATA), “ENDERECO” (ENDEREÇO), “TELEFONE” (TELEFONE), “DINHEIRO” (DINHEIRO), “CEP” (CEP). Fig. 7. Dados de Saída - Reconhecimento de Entidade Fig. 8. Dados de Saída - Segredo de Pseudonomização Título Suprimido devido à Extensão Excessiva 13 5.3 Limitações Como com qualquer sistema automatizado, há limitações que devem ser consideradas para garantir a eﬀicácia e precisão da pseudonomização. Uma dessas limitações é a necessidade de revisão humana. Nossa modelo pode ocasionalmente cometer erros na pseudonomização de entidades nomeadas. Isso requer um processo subsequente de revisão humana para corrigir possíveis erros e garantir que os dados sejam corretamente escondidos, de acordo com os requisitos legais. Outra limitação significativa é a falta de cross-referenciamento entre termos identificados previamente no documento. Por exemplo, se o sistema identificar “Maria Silva” como pessoa em uma parte do texto, pode não reconhecer “Maria” em uma referência subsequente como a mesma pessoa, potencialmente rotulando-a diferentemente, como “NOME_2”. Este problema, que parece simples de resolver, pode envolver questões complexas, como homônimos e o contexto geral do texto. Além disso, o modelo pode gerar falsos positivos, que são erros onde dados não pessoais são erroneamente categorizados com um rótulo diferente. Por exemplo, um nome de rua pode ser incorretamente identificado como nome de pessoa.
Finalmente, o modelo luta para identificar e corrigir erros tipográficos em informações críticas, como CPF ou números de telefone. Esses erros tipográficos, que podem incluir espaços ou caracteres incorretos inseridos entre números, não são reconhecidos pelo sistema, o que pode levar a um fracasso em ocultar corretamente esses dados sensíveis. Este problema provavelmente será abordado em trabalhos subsequentes através da otimização do modelo de transformer.

6 Conclusão
Este estudo abordou o desafio de pseudonomizar Informação Pessoalmente Identificável (IPI) em textos legais para cumprir com a Lei Geral de Proteção de Dados Pessoais (LGPD) do Brasil. Empregamos tecnologias de inteligência artificial, incluindo um modelo de Transformer e técnicas Regex, para identificar e ocultar IPI de forma eficaz. Os testes revelaram que, embora nosso modelo tenha apresentado resultados iniciais promissores, ajustes são necessários para melhorar sua precisão e efeicácia. As conclusões destacam que o abordagem combinada de NER e Regex é promissora, permitindo uma identificação mais precisa de entidades. No entanto, limitações metodológicas incluem a necessidade de ajustes contínuos do modelo para lidar com casos atípicos e a dependência de dados de treinamento de alta qualidade para manter a precisão. Além disso, a técnica enfrenta desafios para identificar consistentemente todas as categorias de IPI, com algumas entidades, como endereços, apresentando resultados mais baixos em comparação com outras, como CPFs e e-mails. Em resumo, enquanto os resultados iniciais em dados sintéticos foram promissores, testes em dados reais são necessários para garantir a efeicácia do modelo em ambientes práticos. A principal vantagem do modelo proposto é sua natureza leve, permitindo que ele opere em sistemas com capacidade computacional menor. Esta característica torna o modelo particularmente valioso para aplicações em ambientes com recursos limitados ou onde a velocidade de processamento é crucial.
Trabalhos Futuros

Um dos principais objetivos para os trabalhos futuros é mitigar as limitações do modelo atual, especialmente em termos de consistência na identificação de entidades e redução de erros, como falsos positivos e não-cross-referenciamento de entidades nomeadas. A ideia é refinar o modelo existente e incorporar feedback mais preciso na fase de treinamento do modelo para melhorar sua precisão e efiência. Os planos também incluem o desenvolvimento de um modelo interativo que aprende com correções feitas pelos usuários. Essa abordagem de aprendizado ativo permitirá que o sistema refine continuamente sua identificação e categorização de dados pessoais, ajustando-se às peculiaridades do texto jurídico e às preferências específicas de pseudonomização do usuário. Por fim, um dos focos será identificar novos termos relacionados a dados pessoais que estão surgindo constantemente com mudanças nas práticas de coleta de dados e legislação. Reconhecendo que novos tipos de dados pessoais podem surgir, o modelo precisa estar preparado e pronto para responder a essas novas demandas, permitindo que todos os tipos de dados pessoais sejam identificados e protegidos adequadamente de acordo com os padrões legais e éticos mais recentes.

Agradecimentos. Os autores agradecem o uso do modelo Llama versão 3 para gerar dados para melhorar o conjunto de dados utilizado nesta pesquisa. A geração de dados sintéticos incluiu informações sensíveis para garantir a robustez do modelo. Os autores tomam toda a responsabilidade pelo conteúdo do artigo, incluindo a garantia da originalidade e correção de todo o texto, e tomaram todas as precauções necessárias para garantir que nenhuma informação sensível real seja usada ou exposta.