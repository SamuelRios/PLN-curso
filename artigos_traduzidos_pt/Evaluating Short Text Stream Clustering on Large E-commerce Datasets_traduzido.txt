Avaliando Aglomerados em Stream de Texto Breve em Dados de E-commerce Grandes

Cesar Andrade1,3 0009-0005-2218-6648, Rita P. Ribeiro1,3 0000-0002-6852-8077, e João Gama2,3 0000-0003-3357-1195

1 Departamento de Ciência da Computação, Faculdade de Ciências, Universidade do Porto, 4169-007 Porto, Portugal up202101459@edu.fc.up.pt, rpribeiro@fc.up.pt
2 Faculdade de Economia, Universidade do Porto, 4200-464 Porto, Portugal
Faculdade de Ciência da Computação, Universidade do Porto, Porto, Portugal jgama@fep.up.pt
3 INESC TEC, 4200-465 Porto, Portugal

Resumo. A Alocação Dirichlet Latente (LDA) é um método fundamental para aglomerar stream de texto breve. No entanto, quando aplicada a grandes conjuntos de dados, enfrenta desafios significativos e sua performance é avaliada comumente em conjuntos de dados específicos de domínio, como notícias e tweets. Este estudo visa preencher essa lacuna avaliando a eficácia de métodos de aglomeramento de texto breve em um grande e diverso conjunto de dados de e-commerce. Especificamente, investigamos bem esses algoritmos de aglomeramento se adaptam às dinâmicas complexas e à escala maior de stream de texto de e-commerce, que diferem de seus domínios de aplicação usual. Nossa análise se concentra no impacto de pontuações de homogeneidade alta nos valores de Informação Mutua Normalizada (NMI) relatados. Particularmente, examinamos se essas pontuações são infladas devido à preponderância de clusters de um elemento único. Para abordar potenciais viéses na avaliação de aglomeramento, propomos usar o Critério de Informação de Akaike (AIC) como métrica alternativa para reduzir a formação de clusters de um elemento único e fornecer uma medida mais balanceada de desempenho de aglomeramento. Presentamos novas perspectivas para aplicar métodos de aglomeramento de texto breve em situações reais, especialmente em setores como e-commerce, onde volumes e dinâmicas de dados de texto apresentam desafios únicos.

Palavras-chave: Aglomeramento de Stream de Texto Breve · Alocação Dirichlet Latente · Online.
Introdução O agrupamento de texto em streams curtos tornou-se uma técnica essencial no processamento de linguagem natural (NLP), permitindo a descoberta de estruturas ocultas em grandes coleções de dados de texto não estruturados. Entre as várias abordagens, o agrupamento de texto em streams curtos com base na Alocação Dirichlet Latente (LDA) tem sido amplamente pesquisado devido à sua eficácia em agrupar textos semelhantes e descobrir padrões temáticos. Embora esses métodos tenham mostrado resultados promissores em domínios como feeds de notícias e plataformas de mídias sociais, sua aplicação a conjuntos de dados maiores e mais complexos permanece menos explorada.

2 Cesar Andrade et al. O desempenho dos métodos tradicionais de agrupamento de texto em streams curtos com base na LDA é bem documentado em cenários envolvendo conjuntos de dados relativamente pequenos, com poucas exceções [1]. No entanto, esses métodos frequentemente lutam quando escalados para conjuntos de dados maiores comumente encontrados em indústrias como comércio eletrônico. A natureza dinâmica e volumosa dos dados de texto do comércio eletrônico apresenta desafios únicos não típicos de outros domínios, como notícias ou mídias sociais. Manipular o grande número de descrições de produtos, resenhas de usuários e logs de consultas requer algoritmos de agrupamento robustos, escaláveis e adaptáveis à natureza evolutiva dos dados. Um desafio significativo na avaliação do desempenho dos métodos de agrupamento é a dependência de métricas como Informação Mutua Normalizada (NMI). Embora a NMI seja útil para medir a precisão estatística dos resultados de agrupamento, não captura plenamente os aspectos práticos dos clusters formados, especialmente na presença de clusters de elementos únicos, que podem inflar artificialmente as pontuações de homogeneidade [2,3]. Essa limitação chama a atenção para um quadro de avaliação mais amplo para melhor entender a utilidade prática dos resultados de agrupamento. Nossa pesquisa busca estender a aplicação desses métodos de agrupamento para entender melhor sua escalabilidade e adaptabilidade, especialmente se concentrando em: 1.
Como esses métodos desempenham com conjuntos de dados de e-commerce extensos; 2. as métricas de qualidade de agrupamento, especialmente em relação à pontuação de homogeneidade e formação de clusters de um elemento único; 3. o potencial de métricas alternativas como o Critério de Informação de Akaike (AIC) para fornecer avaliações mais confiáveis dos resultados de agrupamento. Este artigo está organizado da seguinte maneira. A Seção 2 revisa o trabalho relacionado sobre agrupamento baseado em similaridade e agrupamento baseado em modelo, detalhando os abordagens online. A Seção 3 apresenta nossa proposta e detalha o conjunto de dados, a preparação do conjunto de dados, os métodos avaliados e o setup experimental. A Seção 4.2 relata os resultados. A Seção 5 discute vários aspectos do experimento. Finalmente, A Seção 6 conclui o artigo e sugere direções de pesquisa futuras.

2 Trabalho Relacionado Dois áreas de estudo emergem no agrupamento de streams de texto curto: abordagens baseadas em similaridade e abordagens baseadas em modelo. O agrupamento baseado em similaridade se baseia em similaridades pares, enquanto o agrupamento baseado em modelo se baseia em modelos estatísticos que definem a distribuição de dados. 2.1 Agrupamento Baseado em Similaridade Avanços recentes, incorporando modelos de linguagem treinados como BERT [4] acoplados com algoritmos de agrupamento como HDBSCAN [5], têm demonstrado ser promissores em tarefas de agrupamento de texto. O BERT gera embeddings de contexto, permitindo uma compreensão mais profunda do contexto e modelagem da estrutura da linguagem [6]. Essas embeddings servem como entradas para algoritmos de agrupamento. Estudos [7,8] demonstraram a superioridade de combinar embeddings de BERT e HDBSCAN para agrupamento de texto curto sobre métodos tradicionais. Além disso, o ELINAC [9] introduziu um método baseado em auto-encoder para agrupamento de faturas eletrônicas. Embora BERT e transformers sejam uma tendência nova, seu uso em agrupamento de streams de texto curto com métodos LDA traz um custo computacional adicional [10], levantando questões de escala, especialmente para conjuntos de dados grandes.
2 Abordagens de Agrupamento com Base em Modelo para agrupamento de fluxos de texto curto com base em modelo dividem-se em duas categorias: métodos em lotes e métodos online. Os métodos em lotes manipulam dados em blocos separados, enquanto os métodos online processam continuamente novos dados de entrada. Os métodos em lotes, como a Alociação Dirichlet Latente (LDA)[11], é uma técnica de agrupamento de fluxo de texto com base em modelo que inspirou numerosas extensões. Essas extensões abordam desafios relacionados à evolução de tópicos, representação semântica e natureza dinâmica de fluxos de texto. Inicialmente, modelos como DCT[12] buscaram simplificar as atribuições de tópicos ao atribuir um único tópico a cada documento. Embora eficazes para textos curtos, essa abordagem carecia de adaptabilidade para lidar com contagens de tópicos em mudança dentro dos fluxos. O MStream [13] surgiu em resposta a esse desafio, gerenciando contagens de tópicos ao descartar documentos em lote obsoletos e se adaptando a tópicos evoluindo. No entanto, a dependência do MStream em representação de documentos por termo único limitou sua capacidade de navegar espaços semânticos, afetando a pureza dos clusters. Para melhorar a representação semântica, o NPMM [14] utilizou embeddings de palavras pré-ensinadas, avançando a compreensão de semântica de texto. No entanto, essas embeddings tinham natureza estática e dependente do idioma, o que limitou sua adaptabilidade a paisagens semânticas evoluindo. Com base nas limitações do NPMM, o DP-BMM [15] introduziu sequências desordenadas de bi-terme para representação semântica, detectando dinamicamente contagens de tópicos. No entanto, esse enfase na representação semântica não abordou diretamente desafios apresentados por dados esparsos e de alta dimensionalidade. A introdução do DCSS [16] e do FastStream [17] marcou milhões significativos. O DCSS, utilizando o processo de Dirichlet, demonstrou superioridade em estabilidade e adaptabilidade ao aprender autonomamente contagens de tópicos e se ajustar à deriva de tópicos. O FastStream introduziu melhorias de eficiência e adaptabilidade, empregando um mecanismo de indexação de clusters e limiares de similaridade dinâmicos para acelerar o processamento.
[18] propôs um método de classificação iterativa, melhorando a aglomeração de textos curtos. No entanto, uma limitação comum entre esses estudos é que eles não se concentram em conjuntos de dados complexos e grandes, especialmente em e-commerce. Abordagens online O Modelo Dirichlet Semântico Online (OSDM) [19] destaca-se em agrupamento dinâmico, integrando dados semânticos de ocorrência de palavras em um modelo gráfico para processamento de texto em tempo real sem números fixos de clusters ou tamanhos de lote. Testado nos conjuntos de dados News, Reuters e Tweets e suas versões sintéticas, o OSDM utiliza métricas como Pureza, V-Measure, Homogeneidade e Informação Mutua Normalizada (NMI) para avaliação, adicionando precisão ao seu conjunto de métricas para uma análise minuciosa do desempenho. 4 Cesar Andrade et al. Seguindo os passos do OSDM, o Modelo Gráfico Semântico Online (OSGM) [20] também emprega um esquema de Urn Poli para gerenciar dinamicamente a agrupação de documentos, se concentrando em suavização semântica e co-ocorrência de termos para uma clareza e resolução de ambiguidade aprimoradas. A avaliação do OSGM reflete a do OSDM, utilizando os mesmos conjuntos de dados e métricas para garantir a consistência na avaliação do desempenho e a comparabilidade entre métodos. A introdução do EINDM [21], um modelo Dirichlet aprimorado por contexto para agrupação online em streams de textos curtos, adiciona mais um nível ao campo. Ao utilizar uma representação semântica de termos com base em janela e novas métricas de agrupamento como especificidade de palavra, o EINDM captura eficazmente a natureza evolutiva dos dados de texto. Testado em conjuntos de dados semelhantes ao OSDM e OSGM, o EINDM utiliza as mesmas métricas, exceto pela precisão, se concentrando em aspectos nucleares da eficácia da agrupação. O EStream [22] combina técnicas de agrupamento online e offline para oferecer uma solução versátil para a agrupação de streams de texto. Diferentemente dos outros métodos, o EStream expande seus testes para incluir conjuntos de dados adicionais como NT e SO-T, ao lado de News-T e Tweets-T.
Este abordagem permite uma validação mais ampla de sua eficácia, utilizando os mesmos métricas centrais para garantir uma avaliação abrangente de seu desempenho em diferentes cenários de fluxos de texto. Embora esses métodos de agrupamento de fluxos de texto curtos mostrem inovação e eficácia, especialmente quando avaliados com conjuntos de dados de Notícias e Tweets. No entanto, o foco em esses domínios limitados levanta questões sobre sua adaptabilidade e desempenho em contextos mais amplos, como conjuntos de dados maiores ou campos específicos como comércio eletrônico. A exploração de conjuntos de dados variados pode fornecer insights mais profundos sobre a escalabilidade e aplicabilidade dessas técnicas de agrupamento em cenários reais-world diversificados. A avaliação de métodos de agrupamento frequentemente se baseia na Informação Mutua Normalizada (NMI). No entanto, a NMI sozinha não leva em conta fatores qualitativos como a formação de clusters muito pequenos ou de um único elemento. Uma avaliação mais refinada considerando a distribuição de tamanho de clusters e a meaningfulness dos clusters formados pode levar a uma compreensão mais abrangente da eficácia do agrupamento, garantindo desempenho estatístico e significância prática.

Nossa Metodologia

Recentes estudos que utilizaram abordagens online de LDA para agrupar fluxos de texto curtos relataram realizações de desempenho substanciais. No entanto, esses estudos têm se concentrado predominantemente em conjuntos de dados menores, principalmente em domínios específicos como Notícias e Tweets. Esse foco deixou um vazio significativo em nossa compreensão sobre a escalabilidade e eficácia dessas metodologias em conjuntos de dados maiores e mais variados, especialmente em setores dinâmicos como comércio eletrônico. Diante dessas limitações, nosso estudo visa:

1. Avaliar a eficácia do método em um conjunto de dados de comércio eletrônico que varia significativamente em tamanho e número de clusters para determinar adaptabilidade e escalabilidade.
Essa avaliação ajudará a entender bem o desempenho do método quando submetido às complexidades e dinâmicas variadas de textos de e-commerce em comparação com streams de textos curtos tradicionais. 2. Investigue a influência dos escores de homogeneidade alta nos valores de NMI relatados, principalmente se a prevalência de clusters de elementos únicos infla esses escores. Este aspecto é crucial para garantir que os valores de NMI refletam a eficácia de clustering em vez de artefatos do processo de clustering. 3. Propus e teste o uso do Critério de Informação de Akaike (AIC) como métrica alternativa para mitigar a formação de clusters de elementos únicos. Incluir AIC é esperado que forneça um quadro de avaliação mais robusto que desencoraje soluções de clustering simplistas demais e promova resultados de clustering mais significativos e práticos. A metodologia envolve uma busca sistemática em grade across datasets com tamanho de instâncias variando de 10.000 a 150.000 para avaliar como os parâmetros variam o desempenho. Isso estabelecerá o groundwork para uma análise detalhada, onde cada tamanho de dataset informa os ajustes de parâmetro para o próximo, garantindo refinamento e otimização contínuos tanto do AIC quanto do NMI. A otimização do AIC visa minimizar o valor do AIC, enquanto a otimização do NMI visa maximizar a pontuação do NMI. Essa abordagem busca fornecer insights sobre o desempenho do método em várias situações e melhorar práticas de clustering. 3.1 Datasets Nossa análise experimental empregou um conjunto de datasets com base no Projeto NF-e Brasileiro, iniciado em 2006, que revolucionou a documentação fiscal ao transitar para um sistema eletrônico. Esse shift gerou um volume grande de dados, incluindo detalhes de faturas completas, tornando-o um recurso valioso para aplicações de aprendizado de máquina, como detecção de fraude fiscal. Analisamos um subconjunto do dataset NF-e de novembro de 2021, fornecido pelo Departamento de Finanças do Estado do Amazonas.
O conjunto de dados contém várias características-chave, incluindo: – GTIN: O GTIN é um identificador para itens comerciais desenvolvido e controlado pela GS1, anteriormente EAN/UCC. GTINS, anteriormente chamados de códigos EAN, são atribuídos a qualquer item (produto ou serviço) que possa ser precificado, encomendado ou notificado em qualquer ponto da cadeia de abastecimento. – NCM: O NCM4, que é uma nomenclatura regional para a categorização de bens adotada desde 1995, é utilizada em todas as operações de comércio exterior dos países do Mercosul. O NCM é baseado no HS, uma expressão condensada do "Sistema de Descrição e Codificação de Bens Harmonizados" mantido pela OMC. Foi criado para melhorar e facilitar o comércio internacional e seu controle estatístico. – Descrição do Produto: Campo de texto livre na nota fiscal com uma breve descrição do produto.

O Mercosul (ou Mercado Comum do Sul, em sua sigla em espanhol) é um processo de integração regional, inicialmente estabelecido pela Argentina, Brasil, Paraguai e Uruguai, e posteriormente juntado pela Venezuela e Bolívia*.

Tabela 1: Exemplos de produtos brasileiros com GTIN e NCM. Códigos NCM 22030000 (embalagem de cerveja geral) e 22030010 (tipos específicos como cerveja de trigo). Ambos compartilham o NCM4 2203 ("cerveja"), mas os dígitos adicionais fornecem detalhes específicos sobre tipo e embalagem 3.

2.2 Pre-processamento de dados Para melhor entender as propriedades intrínsecas do nosso conjunto de dados, segmentamos os dados em blocos gerenciáveis, aumentando em incrementos de 10.000 até um máximo de 150.000 instâncias. Essa segmentação é projetada para facilitar a análise e garantir que cada subconjunto permaneça um tamanho prático para avaliação de agrupamento detalhada. Em nossa análise, distinguimos entre dois formatos de codificação utilizados para geração do conjunto de dados: NCM4 e NCM8.
O código NCM4 indica categorias de produtos mais amplas utilizando apenas os quatro primeiros dígitos, fornecendo uma visão geral das grupos de itens. Em contraste, o código NCM8 utiliza todos os oito dígitos para uma classificação mais detalhada e específica, revelando distinções mais finas nos tipos de produtos. 

20000 40000 60000 80000 100000 120000 140000 Tamanho 0 2000 4000 6000 8000 10000 12000 14000 K K gtin nfe4 nfe8 20000 40000 60000 80000 100000 120000 140000 Tamanho 10000 20000 30000 40000 50000 60000 70000 80000 V V gtin nfe4 nfe8 20000 40000 60000 80000 100000 120000 140000 Tamanho 6,8 7,0 7,2 7,4 7,6 7,8 8,0 8,2 Média Len Média Len gtin nfe4 nfe8 Fig. 1: Características dos conjuntos de dados: número de documentos (D), número de clusters (K), tamanho da vocabulária (V), comprimento médio dos documentos (AvgLen).

O comportamento do métrico 'K', que representa o número de clusters, varia significativamente ao longo de diferentes agrupamentos de dados. Para NCM4, há um aumento gradual em 'K', marcado por aumentos maiores esporádicos que sugerem complexidades emergentes nos dados à medida que o volume cresce. O NCM8 apresenta um aumento mais uniforme em 'K', sugerindo um aprimoramento linear na diversidade de tópicos correspondente ao tamanho dos dados. Os clusters de GTIN, adaptados a descrições de produtos específicas, mostram uma tendência ascendente abrupta em 'K'. Isso indica um aumento na amplitude de tópicos e reflete a natureza detalhada e expansiva do GTIN, onde a adição de mais especificidades de produtos leva a uma maior diversidade nos tópicos identificados.

Avaliando o STSC em Conjuntos de Dados de E-commerce Grandes

Quanto ao tamanho da vocabulária 'V', o conjunto de dados GTIN apresenta um crescimento pronunciado, indicando um léxico expansivo que acomoda a diversidade crescente de produtos. No entanto, para subconjuntos de NCM—NCM4 e NCM8—o crescimento em 'V' é mais medido, destacando que enquanto as descrições de produtos GTIN podem capturar um maior número de clusters devido às variações únicas de produtos, um código NCM único pode abranger uma ampla gama de produtos, portanto, um léxico maior.
Finalmente, na nossa preparação de dados, cuidadosamente controlamos a média da extensão dos documentos ('Avg Len') para garantir que os clusters não sejam demasiado pequenos ou grandes, o que poderia distorcer a análise. O métrico 'Avg Len' apresenta variações mínimas ao longo dos conjuntos de dados GTIN e NCM, com uma ligeira diminuição para GTIN, sugerindo que as descrições de produtos se tornam mais concisas à medida que o conjunto de dados cresce. No entanto, para NCM4 e NCM8, há apenas pequenas flutuações, refletindo a diversidade de complexidade dentro de suas categorias de itens mais amplas ao expandirem-se. O controle de 'Avg Len' é crucial para manter a integridade e a comparabilidade dos clusters em diferentes tamanhos de conjunto de dados.

3.3 Métodos de Agrupamento – Modelo Dirichlet Semântico Online (OSDM) [19]: apresenta um abordagem de agrupamento dinâmico, integrando informações semânticas de ocorrência de palavras em um modelo gráfico. Permite processamento de texto em tempo real sem a necessidade de números predeterminados de clusters ou tamanhos de lote, mostrando sua adaptabilidade a fluxos de dados variáveis.

– Modelo Gráfico Semântico Online (OSGM) [20]: utiliza um esquema de Urn Poli para agrupamento de documentos dinâmicos, se concentrando em suavização semântica e co-ocorrência de termos para resolver ambiguidade de termos e melhorar a clareza, provando sua força em agrupamento de texto baseado em semântica.

– EINDM [21]: é um modelo Dirichlet que utiliza representação de termos semânticos com base em janela para capturar a natureza evolutiva de dados de texto através de compreensão semântica aprimorada e métricas de agrupamento novas.

– EStream [22]: emprega tanto agrupamento online quanto offline para se adaptar efetivamente a várias situações de streaming de texto.

3.4 Métricas de Avaliação Para avaliar nossos resultados experimentais, recorremos a métricas amplamente utilizadas na literatura [23] para fornecer uma avaliação completa do desempenho de agrupamento e avaliação do modelo. As métricas são as seguintes:

– Homogeneidade (H) mede bem como cada cluster contém apenas membros de uma única classe. É definida como: H = 1 −H(U|V ) H(U) (1)
Aqui está a tradução do texto científico para português do Brasil:

com/JayKumarr/OSDM 6 https://github.com/JayKumarr/OSGM 7 https://github.com/JayKumarr/EINDM 8 https://github.com/rashadulrakib/short-text-stream-clustering/tree/master/OnlineClustering 8 Cesar Andrade et al. onde H(U|V ) é a entropia condicional da distribuição de classes dada as atribuições de agrupamento, e H(U) é a entropia da distribuição de classes. – Completeness (C) avalia bem como cada classe é representada dentro de um único agrupamento. É definida como: C = 1 −H(V |U) H(V ) (2) onde H(V |U) é a entropia condicional da distribuição de agrupamentos dada as atribuições de classes, e H(V ) é a entropia da distribuição de agrupamentos. – Informação Mutua Normalizada (NMI) combina homogeneidade e completude, medindo a semelhança entre as etiquetas de classes verdadeiras e as etiquetas de agrupamento atribuídas. É definida como: NMI = 2 · I(U; V ) H(U) + H(V ) (3) onde I(U; V ) é a informação mutua entre a distribuição de classes e a distribuição de agrupamentos. – Pureza (P) avalia a qualidade do agrupamento calculando a proporção da classe dominante em cada agrupamento. É definida como: P = 1 N X k max j |ck ∩tj| (4) onde N é o total de amostras, ck é o conjunto de amostras no agrupamento k, e tj é o conjunto de amostras na classe j. – Critério de Informação de Akaike (AIC) ajuda a balancear a adequação do modelo e a complexidade. É definida como: AIC = 2PTR −2 ln(L) (5) onde PTR representa a taxa de tamanho predito/tamanho real, e L é a probabilidade de observar o valor de Homogeneidade H dado a média (µ) e desvio padrão (σ) dos valores de H nos conjuntos de dados. A probabilidade é computada usando a distribuição normal: L = 1 √ 2πσ exp  −(H −µ)2 2σ2  (6) A taxa de tamanho predito/tamanho real (PTR) avalia como a otimização da NMI e AIC afeta a razão entre o número de agrupamentos preditos (ˆnc) e o número real de agrupamentos (nc) e é determinada por: PTR = ˆnc nc −1 (7) Essas métricas fornecem uma avaliação equilibrada do desempenho do agrupamento e da seleção do modelo, garantindo robustez em nossa análise.
Avaliando STSC em Dados de E-commerce de Grande Escala

4.1 Configuração Experimental

Avaliamos várias técnicas para agrupar descrições de produtos, com foco em métodos baseados na Alocação Dirichlet Latente (LDA). Para métodos como OSDM, OSGM e EINDM, ajustamos cuidadosamente os parâmetros LDA α (distribuição de tópicos-documento) e β (distribuição de palavras-tópico) por meio de uma busca em grade para otimizar o desempenho de agrupamento. Além disso, para esses métodos, o taxa de decaimento λ foi consistentemente definido como 1e−6, com todos os outros parâmetros mantidos em seus valores padrão. O ESTREAM requer apenas um parâmetro: Intervalo de Atualização (UI). Este parâmetro, definido como 500 em nossos experimentos, é essencial para manter a qualidade dos clusters ao atualizar e remover clusters obsoletos. Essas configurações de parâmetro foram críticas para alcançar resultados de agrupamento eficazes e estáveis.

4.2 Resultados

Nesta seção, apresentamos nossos achados por meio de três gráficos primários. O gráfico inicial se concentra em identificar o melhor parâmetro, ilustrando o desempenho de métricas como Homogeneidade, Completeness, NMI, Pureza e a razão cluster-rótulo. Essa investigação é crucial para determinar as condições em que o Critério de Informação de Akaike (AIC) é minimizado, como mostrado na Figura 2. Nossa objetiva é revelar como diferentes configurações afetam a qualidade do agrupamento, principalmente através da ótica da otimização do AIC. O segundo gráfico ilustra a evolução no tempo para quatro métodos em diferentes tamanhos de conjunto de dados, como mostrado na Figura 3. O tempo de processamento de cada método, representado em segundos, é plotado contra o tamanho do conjunto de dados. A escala logarítmica no eixo y facilita a comparação de mudanças relativas no tempo de processamento. Essa visualização oferece insights sobre como cada método escala com o tamanho do conjunto de dados, fornecendo informações valiosas sobre eficiência computacional e escalabilidade sem delongar em avaliações numéricas específicas.
O terceiro gráfico demonstra a evolução dos parâmetros α e β, como apresentado na Figura 4. Esta análise é essencial para compreender como o NMI e o AIC se ajustam às mudanças nos parâmetros e para identificar as configurações que levam aos melhores resultados. O estudo se concentra nos métodos EINDM, OSDM e OSGM, omitindo EStream pois não envolve técnicas paramétricas. Esta análise focalizada ajuda a identificar os parâmetros ótimos para uma eficiência de agrupamento aprimorada.

5 Discussão
A análise de AIC destaca a eficiência superior do CB-TMCOH e do TMCOH em comparação com o MSTREAM, indicando uma melhor otimização do número de clusters sem sacrificar a complexidade do modelo. Isso destaca sua capacidade de capturar dados.
Ppureza - NCM8 20000 40000 60000 80000 100000 120000 140000 10 5 0 5 10 15 Índice de Coordenamento de Akaike (AIC) - GTIN 20000 40000 60000 80000 100000 120000 140000 0 100 200 300 400 500 600 Índice de Coordenamento de Akaike (AIC) - NCM4 20000 40000 60000 80000 100000 120000 140000 0 25 50 75 100 125 150 175 Índice de Coordenamento de Akaike (AIC) - NCM8 20000 40000 60000 80000 100000 120000 140000 Tamanho 0 2 4 6 8 10 12 Taxa de Previsão/Real Tamanho - GTIN 20000 40000 60000 80000 100000 120000 140000 Tamanho 0 50 100 150 200 250 300 Taxa de Previsão/Real Tamanho - NCM4 20000 40000 60000 80000 100000 120000 140000 Tamanho 0 20 40 60 80 100 Taxa de Previsão/Real Tamanho - NCM8 Comparação entre o método BEST AIC e o método BEST NMI (Caso) EINDM (BEST AIC) EINDM (BEST NMI) EStream () OSDM (BEST AIC) OSDM (BEST NMI) OSGM (BEST AIC) OSGM (BEST NMI) Fig. 2: Resultado de homogeneidade, completude, pureza, NMI, taxa de previsão/real tamanho e AIC. Para conjuntos de dados GTIN, NCM4 e NCM8 no contexto de análise do BEST NMI. Avaliação do STSC em grandes conjuntos de dados de e-commerce 11 20000 40000 60000 80000 100000 120000 140000 Tamanho 101 102 103 104 105 Tempo de Processamento (segundos) Evolução do Tempo para Métodos Diferentes EINDM EStream OSDM OSGM Fig. 3: Evolução do tempo (tempo de processamento em segundos) versus o tamanho do conjunto de dados GTIN para quatro métodos diferentes: EINDM, OSGM, OSDM e EStream. 20000 40000 60000 80000 100000 120000 140000 0,0 0,2 0,4 0,6 0,8 1,0 Álfa - GTIN 20000 40000 60000 80000 100000 120000 140000 0,0 0,2 0,4 0,6 0,8 1,0 Álfa - NCM4 20000 40000 60000 80000 100000 120000 140000 0,0 0,2 0,4 0,6 0,8 1,0 Álfa - NCM8 Método (Caso) EINDM (BEST AIC) EINDM (BEST NMI) OSDM (BEST AIC) OSDM (BEST NMI) OSGM (BEST AIC) OSGM (BEST NMI) 20000 40000 60000 80000 100000 120000 140000 Tamanho 0,0 0,1 0,2 0,3 0,4 0,5 0,6 Beta - GTIN 20000 40000 60000 80000 100000 120000 140000 Tamanho 0,00 0,02 0,04 0,06 0,08 0,10 Beta - NCM4 20000 40000 60000 80000 100000 120000 140000 Tamanho 0,00 0,02 0,04 0,06 0,08 Beta - NCM8 Evolução de Álfa e Beta Fig. 4: Evolução de α e β para os métodos EINDM, OSDM e OSGM.
Estrutura efetivamente enquanto evita sobreajuste. Além disso, o CB-TMCOH supera métodos de LDA existentes como TMCOH e FASTSTREAM, especialmente em relação à Completeness e Pureza. Isso demonstra sua eficácia em agrupar elementos semelhantes enquanto assegura exclusividade de classe dentro dos clusters. 5.1 Avaliação de Métricas Para conjuntos de dados NCM4, NCM8 e GTIN, a Homogeneidade varia significativamente. No NCM4, com um menor número de clusters, a homogeneidade é geralmente mais alta, pois os clusters são provavelmente mais uniformes, embora possam ser menos abrangentes. Em contraste, NCM8 e GTIN, com clusters mais complexos e numerosos, mostram um potencial declínio na homogeneidade devido à variedade mais ampla de pontos de dados dentro de cada cluster. Comparativamente, entre os dois casos (por exemplo, BEST AIC vs BEST NMI), o BEST NMI prioriza alcançar uma homogeneidade mais alta, pois isso influencia diretamente a pontuação de informação mutua, levando a clusters melhor alinhados com as classes de dados reais. A Completeness do NCM4 tende a ser alta devido a estruturas de dados mais simples, onde capturar todos os membros de classe em um único cluster é mais fácil. No entanto, em NCM8 e GTIN, a complexidade crescente dos dados e o número de clusters pode reduzir a completude, pois as classes podem se espalhar por vários clusters. Entre os casos, o BEST AIC pode mostrar redução de completude em comparação ao BEST NMI, pois o AIC se concentra mais em simplicidade do modelo e ajuste de ajuste, em vez de garantir que todos os membros de classe estejam juntos, o que influencia diretamente a NMI. A Pureza é geralmente mais alta em conjuntos de dados com um menor número de clusters, como o NCM4, onde a probabilidade de misturar classes diferentes em um cluster é mais baixa. Em conjuntos de dados como NCM8 e GTIN, apesar de um maior número de clusters, a complexidade dos dados pode levar a uma pureza mais baixa, pois os clusters podem conter um conjunto mais diverso de rótulos de classe. Em termos de casos, o BEST NMI provavelmente mostra pureza melhor do que o BEST AIC, pois maximizar a informação mutua inadvertidamente alinha clusters mais limpos com rótulos de classe reais.
O NMI é particularmente insígnito para comparar desempenho de agrupamento em conjuntos de dados. O NCM4 pode mostrar valores estáveis de NMI devido à menor complexidade, enquanto o NCM8 e o GTIN podem exibir mais variabilidade em NMI devido à sua complexidade aumentada e contagem de clusters. Comparando casos, o BEST NMI é explicitamente otimizado para maximizar esse métrico, provavelmente resultando em escores NMI mais altos em todos os conjuntos de dados do que o BEST AIC, que pode sacrificar alguma informação mutua por estruturas de modelo mais simples. O PTR mede a eficiência do algoritmo de agrupamento em controlar tamanhos de clusters, idealmente aproximando-se de 1. O NCM4 geralmente apresenta um PTR mais alto, indicando sobre-agrupamento. O NCM8 e o GTIN apresentam um PTR mais baixo devido às suas estruturas complexas, levando a muitos clusters pequenos. O BEST AIC, que favorece modelos mais simples, costuma ter um PTR mais próximo de 1 do que o BEST NMI. O BEST NMI pode aumentar o número de clusters para melhorar a informação mutua, resultando em um PTR mais baixo. Os valores de AIC podem ajudar a avaliar a eficácia do agrupamento em relação à simplicidade do modelo. Valores de AIC mais baixos no NCM4 sugerem um ajuste melhor com modelos mais simples. Em contraste, valores de AIC mais altos no NCM8 e no GTIN podem indicar que os modelos, apesar de serem mais complexos, são necessários para ajustar adequadamente os dados. Comparativamente, o BEST AIC é consistente em minimizar o AIC, o que pode levar a modelos mais simples e adaptáveis em todos os conjuntos de dados do que o BEST NMI, que pode aceitar modelos mais complexos se eles fornecerem melhor compartilhamento de informações. 5.2 Avaliação dos Métodos O EINDM é provavelmente eficaz em conjuntos de dados como o GTIN, onde os dados podem ser diversificados e volumosos. O EINDM pode se adaptar a estruturas complexas combinando múltiplos modelos para melhorar a precisão de agrupamento. No NCM4, que pode ser mais simples, a abordagem de ensemble pode não superar significativamente os métodos mais simples, mas ainda pode fornecer robustez contra ruído. No BEST AIC, o EINDM pode ser configurado entre os dois casos para limitar a complexidade do modelo e evitar cálculos desnecessários.
Em contraste, no BEST NMI, o ensemble pode ser ajustado para maximizar a informação capturada dos dados, potencialmente ao custo de um aumento no carregamento computacional. O EStream tende a formar mais clusters do que existem, desempenhando-se melhor apenas que o OSGM. Ele obtém resultados piores do que os casos de BEST NMI, mas melhores do que os casos de BEST AIC. No entanto, oferece uma excelente relação custo-benefício, pois é o método mais eficiente computacionalmente, especialmente para o conjunto de dados GTIN. O ODSM atinge seu melhor desempenho com conjuntos de dados menores e mais simples, como o NCM4. À medida que a complexidade do conjunto de dados aumenta, seu desempenho degrada. O ODSM não tende a formar muitos clusters para conjuntos de dados com muitas classes, mantendo uma taxa de Predict/True próxima ao ideal. O OSGM tem o pior caso para valores de AIC devido à sua tendência a formar muitos clusters. Mesmo no melhor caso de AIC, esse método gera mais clusters do que os outros. O melhor cenário para usar o OSGM é com o conjunto de dados GTIN e com conjuntos de dados grandes. Entre os casos, o BEST AIC preferiria estabelecer critérios estritos para atualizações do modelo para evitar complexidade. Ao mesmo tempo, o BEST NMI pode explorar a flexibilidade de misturas gaussianas para refinar definições de clusters continuamente, visando a pontuações de NMI mais altas. Cada método exibe um padrão distinto de tempo de processamento à medida que o tamanho do conjunto de dados aumenta. O EINDM demonstra um aumento notável no tempo de processamento com conjuntos de dados maiores, enquanto o OSGM e o OSDM também mostram uma tendência ascendente, embora com diferentes inclinações. Em contraste, o EStream exibe tempos de processamento significativamente mais baixos em todos os tamanhos de conjunto de dados, indicando sua eficiência em lidar com conjuntos de dados maiores. 5.3 Parâmetros hiper O parâmetro α apresenta um padrão variável em relação ao tamanho do conjunto de dados para o método EINDM. Com um tamanho de 10.000, os valores de α são 0,4 e 1,0 para os casos BEST AIC e BEST NMI, respectivamente. À medida que o tamanho do conjunto de dados aumenta para 20.000 e 30.000, os valores de α permanecem consistentes em 0,4 para o caso BEST AIC.
Ainda assim, os valores se ajustam ligeiramente para 1,0 no caso de melhor desempenho NMI, indicando uma configuração estável mas distinta para o desempenho de clustering ótimo. Essa evolução sugere que o parâmetro α está bem ajustado para equilibrar, preservando a estrutura de agrupamento e melhorando a homogeneidade de agrupamento. O parâmetro β apresenta um comportamento estável, especialmente nos casos de melhor desempenho AIC, onde permanece constante em 0,200 para os tamanhos de dados iniciais de 10.000 e 20.000. Em seguida, reduz-se para 0,100 para um tamanho de dados de 30.000. Os valores de β são significativamente menores nos casos de melhor desempenho NMI, começando em 0,006 e 0,004 para os tamanhos de dados de 10.000 e 20.000, respectivamente. Essa tendência continua à medida que o tamanho do conjunto de dados aumenta, refletindo o papel do parâmetro em otimizar a qualidade do agrupamento. A redução nos valores de β nos casos de melhor desempenho NMI sugere um foco em melhorar a granularidade dos resultados de agrupamento para alcançar uma pontuação de informação mutua normalizada mais alta.

Nossas conclusões demonstram que os métodos baseados em LDA enfrentam dificuldades significativas quando aplicados a grandes conjuntos de dados. Isso é evidenciado pelo tempo de processamento crescente proporcional ao tamanho do conjunto de dados, destacando os desafios de escalabilidade inerentes às abordagens tradicionais de LDA. Foi confirmado que pontuações NMI e homogeneidade altas são frequentemente associadas à formação de clusters de um elemento único ou pequenos. Isso é evidente da taxa de Predict/True Size elevada observada. No entanto, uma exceção foi notada no conjunto de dados GTIN, onde métodos como OSDM, EINDM e EStream não se conformaram a essa premissa, indicando alguma variabilidade no desempenho em diferentes conjuntos de dados. Avaliando o agrupamento com base no melhor AIC demonstrou eficácia em controlar clusters de um elemento único. No entanto, isso veio ao custo de reduzir a NMI, homogeneidade, pureza e completude. Essa troca-sugere que, enquanto o AIC pode mitigar soluções de agrupamento simplistas demais, também pode impactar a qualidade geral dos resultados de agrupamento.
Agradecimentos Os autores desejam esclarecer que o primeiro autor recebeu apoio do Governo do Estado do Amazonas/Brasil para este projeto de pesquisa.