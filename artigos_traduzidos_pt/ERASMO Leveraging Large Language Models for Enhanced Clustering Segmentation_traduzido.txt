ERASMO: Utilizando Modelos de Linguagem Grande para Segmentação de Agrupamento Aumentada Fillipe dos Santos Silva1,2,3, Gabriel Kenzo Kakimoto1,2,4, Julio César dos Reis1,3, e Marcelo S. Reis1,2,3 1Hub de Inteligência Artificial e Arquiteturas Cognitivas (H.IAAC); 2Laboratório de Inteligência Artificial (Recod.ai); 3Instituto de Computação, Universidade Estadual de Campinas (UNICAMP), Brasil 4Faculdade de Engenharia Mecânica, Universidade Estadual de Campinas (UNICAMP), Brasil {fillipesantos, g234878, msreis, jreis}@ic.unicamp.br Resumo. A análise de agrupamento desempenha um papel crucial em vários domínios e aplicações, como a segmentação de clientes em marketing. Esses contextos frequentemente envolvem dados multimodais, incluindo conjuntos de dados tabulares e textuais, tornando difícil representar padrões ocultos para obter agrupamentos significativos. Este estudo apresenta o ERASMO, um framework projetado para fine-tuning um modelo de linguagem pré-treinado em dados tabulares codificados em texto e gerar embeddings a partir do modelo fine-tunado. O ERASMO emprega um conversor textual para transformar dados tabulares em formato textual, permitindo que o modelo de linguagem processe e entenda os dados de forma mais eficaz. Além disso, o ERASMO produz embeddings ricos em contexto e representativos estruturalmente através de técnicas como shuffling de sequência de características aleatórias e verbalização de números. Foram realizadas avaliações experimentais extensivas utilizando vários conjuntos de dados e abordagens de base. Nossos resultados demonstram que o ERASMO aproveita plenamente o contexto específico de cada conjunto de dados tabular, levando a embeddings mais precisos e nuances para agrupamentos precisos. Essa abordagem melhora o desempenho de agrupamento capturando padrões complexos de relacionamento dentro de dados tabulares diversificados. Palavras-chave: Segmentação de Agrupamento · Modelos com Base em Transformador · Embeddings de Dados Tabulares.
Introdução

Os dados tabulares são comuns em vários campos, como finanças, saúde e marketing, onde servem como fonte primária de informações para tarefas de Aprendizado de Máquina (AM) [15]. Apesar de sua ampla utilização, extraíra insígnias significativas dos dados tabulares permanece um desafio complexo, especialmente em tarefas de agrupamento [6]. Esses desafios incluem lidar com tipos de características heterogêneas, lidar com espaços de alta dimensionalidade e garantir métricas de distância significativas. Esses problemas podem impactar significativamente a eficácia dos algoritmos de agrupamento em identificar agrupamentos naturais dentro dos dados [14]. Pesquisadores recentes exploraram métodos estatísticos tradicionais e abordagens de aprendizado profundo modernas [14, 19, 21] para abordar esses desafios. Estudos existentes utilizaram Modelos de Linguagem Grande (MLG) como o GPT e o LLaMA da OpenAI para criar embeddings a partir de conjuntos de dados textuais, melhorando a representação e análise de dados [6, 14]. Além disso, um método que combina MLG e Embeddings Determinísticos, Independentes do Corpus (EDIC) foi proposto para gerar embeddings consistentes entre conjuntos de dados, melhorando a precisão de segmentação [19]. No entanto, essas abordagens frequentemente falham em aproveitar plenamente o contexto específico de cada conjunto de dados tabular, resultando em embeddings menos nuances para agrupamento preciso. Este estudo apresenta originalmente o ERASMO, nosso framework proposto para gerar embeddings de alta qualidade a partir de dados tabulares usando modelos de linguagem baseados em transformadores. Essas embeddings excel em análise de agrupamento, revelando padrões e agrupamentos ocultos. Nossa solução também pode ser usada em sistemas de Geração Augmentada por Recuperação (GAR) e outras tarefas para obter insights mais profundos da informação de contexto [7]. O ERASMO opera em duas etapas: (1) ajuste fino de um modelo de linguagem pré-treinado em dados tabulares codificados em texto; e (2) geração de embeddings a partir do modelo ajustado.
Usando técnicas como shuffling de sequência de características aleatórias e verbalização numérica, o ERASMO produz embeddings ricas em contexto e representativas estruturalmente, superando todas as estratégias de agrupamento da literatura com base em métricas internas. A avaliação experimental utilizou três métricas de qualidade de agrupamento para comparar o ERASMO com métodos de ponta: Escore de Silhouette (SS), Índice de Calinski-Harabasz (CHI) e Índice de Davies-Bouldin (DBI). Essas métricas avaliam de forma abrangente os resultados de eficácia de agrupamento, medindo coesão, separação e estrutura de cluster em geral. Avaliamos extensivamente o ERASMO em conjuntos de dados reais sem rótulos verdadeiros, incluindo Objetivos de Marketing Bancário, Conjunto de Dados Público de E-Commerce por Olist, Resenhas do Yelp, PetFinder.my e Resenhas de Roupas Femininas. Esses conjuntos de dados abrangem informações diversificadas e apresentam desafios variados, testando rigorosamente as capacidades de agrupamento do ERASMO. Este artigo apresenta as principais contribuições da seguinte forma: – Introduzimos o ERASMO, um framework inovador que utiliza modelos de linguagem baseados em transformadores para gerar embeddings de alta qualidade a partir de dados tabulares, melhorando a análise de agrupamento. – Demonstramos que nosso framework melhora significativamente o desempenho de agrupamento ao capturar as relações complexas dentro de dados tabulares por meio de técnicas de shuffling de sequência de características aleatórias e verbalização numérica. – Realizamos experimentos que alcançam resultados de agrupamento de ponta com o ERASMO, mostrando sua eficácia em identificar padrões e agrupamentos dentro de conjuntos de dados tabulares diversificados. – À nossa conhecimento, o ERASMO é o primeiro framework a integrar e fine-tune modelos de linguagem baseados em transformadores especificamente para gerar embeddings a partir de dados tabulares, resultando em resultados de agrupamento superiores. O restante do artigo está organizado da seguinte forma. A Seção 2 apresenta uma síntese de trabalho relacionado. A Seção 3 detalha o framework ERASMO.
Seção 4 descreve nossa metodologia experimental. Seção 5 apresenta os resultados de nossas avaliações. Seção 6 discute as implicações de nossos achados. Finalmente, Seção 7 fornece conclusões e direções para trabalho futuro. 2 Trabalhos Relacionados Vários estudos exploraram a aplicação de LLMs para transformar dados tabulares para tarefas de agrupamento, demonstrando o potencial de melhorar a segmentação de usuários e análise de dados [6,14,19,21,23,24]. Zhu et al. [24] propuseram um método inovador denominado Word Embedding of Dimensionality Reduction (WERD) para agrupamento de documentos. Seu método integra embeddings de palavras pré-treinadas com técnicas de redução de dimensionalidade. No trabalho deles, Sentence-BERT converte-os em vetores de alta dimensionalidade após pré-processamento de documentos, que PaCMAP reduz em seguida. O agrupamento espectral é aplicado, seguido por Fatorização de Matriz Não-Negativa para extrair palavras-chave. CLUSTERLLM [23], um framework de agrupamento de texto inovador, aproveita feedback de LLMs como ChatGPT. Este método melhora o agrupamento ao utilizar LLMs para refinar perspectivas e granularidade de agrupamento em duas etapas: uma tarefa de triplet para fine-tuning embedders com base em preferências de usuário e uma tarefa de par pares para determinar a granularidade de agrupamento. Extensos experimentos em quatorze conjuntos de dados demonstraram que CLUSTERLLM melhora consistentemente a qualidade do agrupamento e é econômico, superando métodos de agrupamento tradicionais. Ambos WERD [24] e CLUSTERLLM [23] apresentaram limitações em comparação ao framework ERASMO (nossa proposta). WERD pode não capturar plenamente as nuances contextuais de cada conjunto de dados devido ao seu foco em técnicas de redução de dimensionalidade. Ao mesmo tempo, a dependência de CLUSTERLLM em LLMs gerais para orientação pode ignorar características específicas do conjunto de dados. Um método que demonstrou que LLMs permite aprendizado a poucos exemplos aplicado a tarefas de agrupamento foi proposto em [21].
O estudo demonstrou como LLMs podem realizar tarefas de agrupamento com dados rotulados mínimos, aproveitando sua treinamento prévio extenso, reduzindo significativamente a necessidade de grandes conjuntos de dados anotados e alcançando desempenho de agrupamento razoável com aprendizado por poucas amostras. Similarmente, Tipirneni et al. [18] exploraram agrupamento contextual utilizando LLMs, destacando como esses modelos podem utilizar informações contextuais para melhorar a precisão de agrupamento. Embora ambos os métodos possam não aproveitar plenamente as nuances específicas do conjunto de dados tão eficazmente quanto o ERASMO, pois empregamos um passo de ajuste fino, permitindo que o modelo capture melhor e utilize detalhes específicos do conjunto de dados, levando a resultados de agrupamento mais precisos e confiáveis. Tissera, Asanka e Rajapakse desenvolveram [19] uma abordagem para melhorar a segmentação de clientes utilizando LLMs e DICE. Seu método combinou LLMs com DICE para gerar embeddings consistentes e determinísticos em diferentes conjuntos de dados, melhorando a precisão e robustez da segmentação. Seu método pode não aproveitar plenamente as nuances específicas do contexto de cada conjunto de dados tão eficazmente quanto o ERASMO. Nossa proposta de processo de ajuste fino permite que o modelo se adapte às características únicas dos dados de entrada, fornecendo embeddings mais ricos e detalhados contextualmente que podem resultar em clusters mais precisos e significativos. Uma análise comparativa de embeddings LLM para agrupamento eficaz foi explorada em [6]. Como extensão, o estudo sobre agrupamento de texto com embeddings LLM [14] explora modelos e conjuntos de dados adicionais para demonstrar melhorias no agrupamento de dados de texto. Embora abordagens existentes capturem eficazmente relações semânticas complexas e lidem com dados categóricos, numéricos e textuais, elas carecem da especificidade de ajuste fino do ERASMO, nosso aspecto originalidade chave.
O framework ERASMO fornece embeddings personalizados para conjuntos de dados tabulares e integra permutação de ordem de características, o que proporciona agrupamentos mais precisos e relevantes no contexto, oferecendo superior versatilidade e robustez em várias aplicações de agrupamento. Esta seção apresenta o ERASMO, nosso framework que utiliza modelos de linguagem baseados em transformers para gerar embeddings de alta qualidade a partir de dados tabulares. Essas embeddings são particularmente eficazes para análise de agrupamento, permitindo identificar padrões e agrupamentos dentro dos dados que não seriam imediatamente aparentes. O processo envolve duas etapas principais: (1) ajuste fino de um modelo pré-treinado LLM em um conjunto de dados tabulares codificados em texto; e (2) utilização do modelo ajustado para gerar embeddings, que são utilizados por um algoritmo de agrupamento. Essas etapas projetadas foram inspiradas em [2]. A subseção 3.1 detalha a fase de ajuste fino, enquanto a subseção 3.2 relata os processos de geração de embeddings.

3.1 Fase 1: Ajuste Fino

Modelos pré-treinados de linguagem gerativos padrão esperam sequências de palavras como entrada. Portanto, convertimos cada linha do nosso conjunto de dados em uma representação textual para aplicar um modelo LLM a dados tabulares, que podem conter informações categóricas, numéricas e textuais. Definição 1 (Conversor Textual). Dado um conjunto de dados tabulares com m colunas com nomes de características f1, f2, ..., fm e n linhas de amostras s1, ..., sn, seja o elemento vi,j, i ∈ {1, ..., n}, j ∈ {1, ..., m} represente o valor da j-ésima característica do i-ésimo ponto de dados. Considerando o nome da característica e o valor, cada amostra si da tabela é transformada em uma representação textual ti usando a seguinte transformação sujeito-predicado-objeto: ti,j = [fj, "é", vi,j, ","], ∀i ∈ {1, ..., n}, j ∈ {1, ..., m} (1a) ti = [ti,1, ti,2, ..., ti,m], ∀i ∈ {1, ..., n}
, n}, (1b) Título Suprimido devido ao Comprimento Excessivo 5 onde ti,j, a característica codificada textualmente, é uma cláusula com informações sobre um valor único e seu nome de característica correspondente, e [·] denota o operador de concatenação. Ao transformar um vetor de características tabulares em uma sequência utilizando o esquema de codificação de sujeito-predicado-objeto textual, informações pseudo-posicionais são artificialmente introduzidas na amostra de dados tabulares transformada. No entanto, não há relação de ordenação espacial entre características em conjuntos de dados tabulares. Permutamos aleatoriamente as sentenças curtas codificadas ti,j da representação textual completa ti para reconstruir a independência de ordem de características. Definição 2 (Baralhamento Aleatório de Sequência de Características). Seja ti, i ∈{1, . . . , n}, uma representação textual. Considere uma sequência k = (k1, . . . , km) que é uma permutação da sequência de índices (1, . . . , m). Um baralhamento aleatório de sequência de características é definido como ti(k) = [ti,k1, ti,k2, . . . , ti,km]. Treinamos finamente nosso modelo de linguagem gerativa em amostras sem dependências de ordem quando usamos ordens aleatórias das características codificadas textualmente. Além disso, essas permutações são altamente benéficas pois permitem condição arbitrária na geração de dados tabulares. Em nossos experimentos, referimo-nos ao modelo ERASMObase como modelo de base, utilizando apenas o Conversor Textual e o Baralhamento Aleatório de Sequência de Características. Além disso, há evidência de que verbalizar tokens numéricos pode melhorar a eficácia em cenários específicos [8]. Nesse sentido, exploramos essa abordagem, nomeando-a ERASMONV, da seguinte maneira. Definição 3 (Verbalizador de Números). Seja ti, i ∈{1, . . . , n}, uma representação textual, e ti,j o conjunto de palavras da j-ésima característica de ti. Um verbalizador de números é uma função v que recebe como entrada uma palavra w de ti,j e é definida como: v(w) = ( w, se w não for numérico, verbalizado w caso contrário.
(2) Ao aplicar essa transformação em todos os tokens de todas as representações textuais, garantimos que qualquer informação numérica no texto seja verbalizada. Em algumas tarefas de processamento de linguagem natural (NLP), como agrupamento com embeddings, análise de sentimento e classificação de texto, verbalizar números pode melhorar a compreensão do modelo do contexto e do significado dos valores numéricos, levando a resultados mais precisos e significativos. Essa transformação pode não ser benéfica em alguns casos, dependendo da natureza específica dos dados e da tarefa em questão [8,9]. Ajuste de um Modelo de Linguagem Auto-Regressiva Treinado: Descrevemos o procedimento de ajuste de um modelo de linguagem auto-regressiva treinado em dados tabulares codificados para tarefas de geração. Supomos um conjunto de dados tabulares codificados em texto T = {ti(k)}i=1,...,n que foi transformado em texto pelo esquema de codificação proposto. Seja k uma permutação aleatória e n o número de linhas. Com base na escolha do usuário, o pipeline pode proceder diretamente ao ajuste do modelo para gerar ERASMObase, ou pode aplicar primeiro um verbalizador de números para converter tokens numéricos em suas representações verbais antes de ajustar o modelo para gerar ERASMONV. Para ser processado com um modelo de linguagem, as sentenças de entrada t ∈T devem ser codificadas em uma sequência de tokens de um vocabulário discreto e finito W. Esses tokens podem ser codificações de caractere, palavra ou subpalavra, como as codificações Byte-Pair-Encodings (BPE). Portanto, t ∈T é representado por uma sequência de tokens (w1, ..., wj) = TOKENIZE(t) com tokens w1, ..., wj ∈W, onde j denota o número de tokens necessário para descrever a sequência de caracteres t. Comumente, a probabilidade de sequências de linguagem natural é fatorizada de forma auto-regressiva em modelos de linguagem. É representada como um produto de probabilidades de saída condicionadas a tokens observados anteriormente: p(t) = p(w1, ..., wj) = jY k=1 p(wk | w1, ..., wk−1).
(3) Como resultado, um usuário final pode escolher qualquer modelo de linguagem gerativa existente para modelagem de dados tabulares e explorar a vasta quantidade de conhecimento contextual apresentada nestes modelos. O ajuste fino permite que o modelo aproveite essa informação contextual com os nomes de características e categorias para melhorar as capacidades do modelo. A figura 1 apresenta o pipeline para o passo de ajuste fino do ERASMO.

3.2 Fase 2: Geração de Embeddings e Análise de Agrupamento

Geramos embeddings do modelo após ajuste fino do LLM no conjunto de dados tabulares codificados em texto. Essas embeddings capturam as relações contextuais e características codificadas durante a fase de treinamento. Começamos alimentando o conjunto de dados de teste, transformado em sua representação textual, no LLM ajustado. O modelo gera embeddings para cada sequência de entrada, fornecendo uma representação de alta dimensionalidade para cada amostra. Esse processo garante que as embeddings preservem as relações contextuais e de características aprendidas durante o ajuste fino. Dependendo da escolha do usuário no pipeline, as embeddings são geradas a partir de modelos ERASMObase ou ERASMONV, refletindo se o passo de verbalização foi aplicado. Para gerar essas embeddings, as sentenças de entrada t ∈Ttest são codificadas em sequências de tokens e processadas pelo LLM ajustado. As embeddings são obtidas dos estados finais ocultos do modelo, resultando em representações ricas e informativas dos dados. Essas embeddings podem então ser utilizadas para várias tarefas downstream, incluindo análise de agrupamento, para obter insights mais profundas na estrutura dos dados (cf. Figura 2).

4 Metodologia Experimental

Nossos experimentos avaliaram a qualidade da avaliação para os melhores algoritmos de agrupamento para cada conjunto de dados e combinação de modelo (cf. Tabela 1 para os resultados obtidos). A subseção 4.1 descreve os conjuntos de dados utilizados para treinamento e teste. A subseção 4.2 apresenta uma visão geral dos algoritmos de agrupamento.
Título Suprimido devido à Extensão Excessiva

7 Idade 30 34 29 COMENTÁRIO Produto incrível, altamente recomendado! Qualidade terrível, muito desapontado. Grande valor pelo preço!

0 1 2 EMPREGO desempregado serviços gerenciamento TREINAMENTO DE DADOS "Idade é 30, Emprego é desempregado, Comentário é Produto incrível, altamente recomendado!", "Idade é 34, Emprego é serviços, Comentário é Qualidade terrível, muito desapontado.", "Idade é 29, Emprego é gerenciamento, Comentário é Grande valor pelo preço!"

Conversor de Texto Sequência de Características Aleatórias Embaralhamento Modelo de Linguagem Gerativa Grande de Linguagem Treinada ... [EOS] ... [EOS] Tokenizador Fine-tunning "Emprego é desempregado, Idade é 30, Comentário é Produto incrível, altamente recomendado!", Comentário é Qualidade terrível, muito desapontado, Idade é 34, Emprego é serviços", "Comentário é Grande valor pelo preço!, Idade é 29, Emprego é gerenciamento"

Verbalizador de Números "Emprego é desempregado, Idade é trinta, Comentário é Produto incrível, altamente recomendado!", Comentário é Qualidade terrível, muito desapontado, Idade é trinta e quatro, Emprego é serviços", "Comentário é Grande valor pelo preço!, Idade é vinte e nove, Emprego é gerenciamento"

(2) (1) (3) (3a) (3b) (4b) Fluxo B gera ERASMONV Fluxo A gera ERASMObase Fig. 1: O pipeline de dados ERASMO para a fase de fine-tunning. Primeiramente, um passo de conversor de texto transforma dados tabulares em texto significativo (1). Em seguida, uma permutação aleatória de ordem de características é aplicada (2). Em seguida, com base na escolha do usuário, o pipeline diverge: pode prosseguir diretamente para fine-tunning um LLM (3a) para gerar ERASMObase, ou aplicar um verbalizador de números (3b) antes de fine-tunning o LLM (4b) para gerar ERASMONV.

Idade 29 23 41 COMENTÁRIO Excelente, altamente recomendado! Grande negócio, vale a pena! Qualidade terrível, muito desapontado.

0 1 2 EMPREGO empregada empreendedor desempregado DADOS DE TESTE (1) Fine-tunned Pretrained Generative Large Language Model ... [EOS] ... [EOS] Tokenizador Embeddings Aumentados Segmentação (6) Algoritmo de Agrupamento (5) (2) Conversor de Texto (3) Fig. 2: O pipeline ERASMO para geração de embeddings e análise de agrupamento.
O dado de entrada em forma de tabela é transformado em sequências de texto (1). Em seguida, um passo de permutação aleatória da ordem de características é aplicado (2). Para o ERASMONV, um passo de verbalização numérica segue (3) antes da processamento pelo LLM fine-tunado para gerar embeddings (4). Para o ERASMObase, a pipeline segue diretamente de (2) para (4). Os embeddings são subsequentemente utilizados para análise de agrupamento. 

8 Autores Suprimidos devido à Excessiva Longevidade Subseção 4.3 descreve as abordagens utilizadas como baseline em nossos experimentos. Subseção 4.4 relata sobre os métricas de avaliação. Subseção 4.5 apresenta os detalhes de implementação. Cada configuração experimental para um dado conjunto de dados avaliou diferentes modelos de linguagem fine-tunados e pré-treinados. Cada modelo considera vários algoritmos de agrupamento e sua configuração.

4.1 Conjuntos de dados

Selecionamos um conjunto diversificado de conjuntos de dados para abranger uma variedade de desafios relacionados à categorização e agrupamento de texto, e os utilizamos para avaliar algoritmos de agrupamento de texto.

– Marketing de Banco: Composto por dados de campanhas de marketing direto de uma instituição bancária, que incluem atributos do cliente como idade e ocupação, além da resposta à campanha [10].

– Dados públicos de E-commerce da Olist: Um conjunto de dados de e-commerce brasileiro com mais de 100.000 pedidos de 2016 a 2018 em múltiplos mercados [11]. Inclui 72.794 amostras de treinamento e 18.199 amostras de teste. O modelo RFM (Recency, Frequency, Monetary) foi utilizado para segmentação de clientes, como descrito em [19].

– Yelp: Compreende resenhas de negócios do Yelp, incluindo resenhas de texto, classificações de estrelas e atributos de negócios, oferecendo uma fonte rica para análise de sentimento e classificação de resenhas [4].

– PetFinder.my: Caracteriza registros de adoção do site PetFinder.my, abrangendo atributos de animais, descrições e status de adoção, valioso para classificação e agrupamento de texto relacionados ao bem-estar animal [5].
Aqui está a tradução do texto científico para português do Brasil:

– Avaliações de Roupas Femininas: Contém avaliações de roupas femininas, com cada avaliação detalhando feedback de texto, classificações e informações do cliente, adequadas para análise de sentimento e pesquisa de sistema de recomendação [3]. Cada conjunto de dados não rotulado foi processado pela pipeline proposta, que envolve treinar um LLM pré-treinado. Essa abordagem garante que os algoritmos de agrupamento possam realizar otimamente em entradas textuais diversificadas, melhorando sua capacidade de identificar e agrupar pontos de dados relacionados de forma eficaz.

4.2 Algoritmos de Agrupamento

Os algoritmos de agrupamento escolhidos são adequados para lidar com padrões complexos em dados estruturados e textuais, garantindo categorização eficiente. Utilizamos o algoritmo k-means por sua simplicidade e eficácia com grandes conjuntos de dados e k-means++ por sua inicialização estratégica de centroides para melhorar a eficiência e qualidade do agrupamento [12]. Diferentemente do k-means, que atribui cada ponto de dados a um único cluster, o Fuzzy C-Means (FuzzyCM) emprega uma abordagem de membro probabilístico, capturando eficazmente as nuances e polissémia típicas de dados textuais. Utilizamos Aglomerativo Hierárquico de Clustering (AHC) para descobrir estruturas hierárquicas e clustering espectral por sua habilidade em reconhecer clusters baseados na estrutura de grafo dos dados, identificando eficazmente formas não convexas. Para o k-means, os parâmetros foram: método de inicialização definido como aleatório, número de inicializações (ninit) definido como 10 e semente aleatória definida como 0. O algoritmo k-means++ utilizou k-means++ para inicialização, ninit foi 1 e a semente foi 0. O Aglomerativo Hierárquico de Clustering (AHC) empregou métrica Euclidiana com ligação Ward. Para o Fuzzy C-means (FuzzyCM), não foi especificado método de inicialização, o parâmetro de fuzziness (m) foi 2, tolerância de erro foi definida como 0,005 e o número máximo de iterações (maxiter) foi 1000. O clustering espectral utilizou ’discretize’ para atribuição de rótulo e semente aleatória de 10.
Implementações desses algoritmos foram fontes da biblioteca scikit-learn [13], exceto pelo FuzzyCM, que utilizou o pacote scikit-fuzzy [22]. Para k-means e k-means++, init especifica o método de inicialização do centroide de cluster, ninit indica o número de execuções do algoritmo com sementes diferentes e seed define o número aleatório para inicialização do centroide. Em AHC, metric é o métrica utilizada para cálculo de ligação e linkage é o critério que mede a distância entre conjuntos de observações. Utilizamos distância euclidiana para medir semelhanças entre pontos e abordagem de centroide mais próximo para associar clusters. Para FuzzyCM, init é a matriz de partição fuzzy inicial (aleatória se None), m é o grau de fuzziness, error é o critério de parada e maxiter é o limite de iterações. Em clustering espectral, assign_labels especifica a estratégia de rotulação no espaço de embedding e seed é o número pseudorandom para inicializar a decomposição dos vetores de autovalor. Para todos os conjuntos de dados, o número de clusters (k) foi determinado utilizando a pontuação de silhouette para otimizar a coesão e separação dos clusters. 4.3 Abordagens (Bases) Utilizamos várias técnicas de embedding de estado-da-arte de LLMs, incluindo OpenAI, Falcon, Llama 2, GPT-2 Médio e um modelo baseado em MPNet, cada um melhorando a representação de texto capturando nuances contextuais. Para o modelo baseado em MPNet, utilizamos sentence-transformers/all-mpnet-base-v2 (MPNet-v2) [17]. Para o modelo OpenAI, utilizamos text-embedding-3-large e para o modelo Falcon, utilizamos tiiuae/falcon-7b [1]. Além disso, empregamos Llama-2-7b-chat-hf [20] para aplicações de chat e gpt2-medium [16] para representações textuais mais rápidas. Utilizamos as embeddings da última camada de todos os modelos para as representações de texto mais ricas no contexto. Integramos uma base adicional de um estudo recente que explora segmentação de clientes usando LLMs combinados com DICE [19].
Eles utilizaram o modelo paraphrase-multilingual-mpnet-base-v2 da Sentence Transformers para gerar embeddings de sentenças de 768 dimensões. Esse modelo, baseado na arquitetura MPNet, tem cerca de 278 milhões de parâmetros e é projetado para agrupamento e busca semântica. 10 Autores Suprimidos devido à Excessiva Duração 4.4 Métricas de Avaliação Utilizamos um conjunto de métricas para avaliar nosso framework proposto e linhas de base de forma minuciosa. Especificamente, empregamos as métricas SS, CHI e DBI para avaliar a coesão, compactação e separação dos clusters, garantindo uma análise robusta de sua integridade estrutural. A métrica SS, que avalia a separação e coesão dos clusters, é calculada para cada ponto de dados i como: s(i) = b(i)−a(i) max{a(i),b(i)}, onde a(i) mede a distância média intra-cluster e b(i) é a distância mínima inter-cluster para o ponto i. A métrica CHI mede a razão da dispersão entre-clusters para a dispersão dentro-clusters, fornecendo insights sobre a estrutura de agrupamento geral. O índice é formulado como: CHI = Tr(Bk)/(k−1) Tr(Wk)/(N−k), onde Tr(Bk) é a traço da matriz de dispersão entre-grupos e Tr(Wk) é a traço da matriz de dispersão dentro-grupos, avaliando tanto a separação quanto a compactação dos clusters. A métrica DBI avalia a razão de similaridade média de cada cluster com o mais semelhante, oferecendo uma medida de separação dos clusters. O índice é calculado como: DBI = 1 k Pk i=1 maxj̸=i  σi+σj dij  , onde σi e σj representam a distância média de todos os elementos nos clusters i e j para seus respectivos centroides, e dij é a distância entre centroides dos clusters i e j. Valores mais baixos de DBI indicam melhor separação dos clusters. 4.5 Nossa Implementação Configurada Comparamos as linhas de base descritas (cf. Subseção 4.3) usando um modelo de transformador-decodificador pré-treinado LLM, GPT-2 médio [16], que tem 355 milhões de parâmetros treináveis, 24 camadas, 16 cabeças de atenção, um tamanho de embedding de 1024 e um tamanho de contexto de 1024.
Para facilitar essa comparação, convertemos o conjunto de dados tabular em texto para todos os baseline, aplicando a função de sequência de características aleatórias e comparando os resultados com ERASMObase e ERASMONV. Ambos os modelos foram treinados com um tamanho de batch de 8 em 60 épocas. Aplicamos uma taxa de dropout de 0,1 e utilizamos 500 passos de aquecimento. Os modelos incorporaram uma taxa de decaimento de peso de 0,01 e utilizaram o otimizador Adam com ϵ definido como 1e-8 e valores de β de [0,7, 0,9]. A taxa de aprendizado inicial foi definida como 5e-5, com um cronograma começando em 1e-8, variando de um mínimo de 1e-5 a um máximo de 4e-5. O modelo foi desenvolvido usando PyTorch 1 e está disponível em um repositório do GitHub 2. Ele executou em um sistema equipado com cinco unidades NVIDIA RTX A6000, cada com 48 GB de Memória de Acesso Aleatório (RAM). 1 pytorch.org. 2 ERASMO - GitHub. Título Suprimido devido à Extensão Excessiva 11 5 Resultados Experimentais Presentamos resultados-chave obtidos organizados por conjuntos de dados. A Tabela 1 apresenta os resultados de métricas SS, CHI e DBI para o conjunto de dados de teste para todos os abordagens avaliadas; os valores em negrito indicam os melhores resultados. O melhor algoritmo foi determinado escolhendo o algoritmo com a maior SS. Bancário. No conjunto de dados Bancário, a estratégia ERASMObase superou todas as outras estratégias, alcançando a maior SS de 0,75, a maior CHI de 12.038,44 e a menor DBI de 0,37. Isso indica clusters bem definidos e compactos. ERASMONV também performou fortemente com uma SS de 0,71 e uma CHI de 7.570,38, embora tenha tido uma DBI ligeiramente mais alta de 0,43 em comparação com ERASMObase. Outras estratégias, como MPNet-v2 e Falcon, mostraram desempenho moderado com valores de SS de 0,27 e 0,23, respectivamente, enquanto a OpenAI teve a menor SS de 0,11 e a maior DBI de 2,73, indicando clustering ruim. Olist. Para o conjunto de dados Olist, ERASMONV alcançou a maior SS de 0,77, indicando a melhor qualidade de agrupamento. Ela alcançou a maior CHI de 62.036,87 e uma DBI baixa de 0,32. ERASMObase seguiu-se de perto com uma SS de 0,75 e uma CHI de 54.236.
31, juntamente com o menor valor de DBI de 0,30. Outras estratégias, como LLaMA-2 e Falcon, desempenharam-se razoavelmente bem, com valores de SS de 0,71 e 0,66, respectivamente. No entanto, OpenAI e MPNet-v2 apresentaram valores de SS mais baixos, com OpenAI alcançando um valor de SS de 0,19 e MPNet-v2 um valor de SS de 0,24. Yelp. No conjunto de dados Yelp, ERASMONV e ERASMObase ambos demonstraram desempenho superior, com valores de SS de 0,79 e 0,78, respectivamente. ERASMONV também alcançou o maior valor de CHI de 8.410,94 e empatou com ERASMObase pelo menor valor de DBI de 0,28. Outras estratégias, como GPT2 Medium e LLaMA-2, mostraram desempenho de clustering moderado com valores de SS de 0,39 e 0,29, respectivamente. OpenAI, com um valor de SS de 0,07, e MPNet-v2, com um valor de SS de 0,23, indicaram um clustering menos eficaz. PetFinder.my. No conjunto de dados PetFinder.my, ERASMONV ligeiramente superou ERASMObase com um valor de SS de 0,73 em comparação a 0,72. ERASMObase teve o maior valor de CHI de 3.351,95 e um DBI baixo de 0,40, enquanto ERASMONV teve um valor de CHI de 3.063,55 e o menor DBI de 0,34. Outras estratégias, como GPT2 Medium e Falcon, mostraram resultados moderados com valores de SS de 0,55 e 0,20, respectivamente. MPNet-v2 teve o menor valor de SS de 0,14, indicando um desempenho de clustering ruim. Roupas. Para o conjunto de dados Roupas, ERASMObase alcançou o maior valor de SS de 0,72 e o maior valor de CHI de 6.208,52, juntamente com o menor valor de DBI de 0,39. ERASMONV também desempenhou-se bem com um valor de SS de 0,71 e um valor de CHI de 5.916,57, igualando o menor valor de DBI de 0,39. Outras estratégias, como GPT2 Medium e LLaMA-2, mostraram desempenho moderado, com valores de SS de 0,52 e 0,37, respectivamente. OpenAI e MPNet-v2 tiveram os menores valores de SS de 0,07 e 0,12, respectivamente, indicando qualidade de clustering ruim. A figura 3 apresenta uma visualização em 2D de t-Distributed Stochastic Neighbor Embedding (t-SNE) para o conjunto de dados Yelp em todas as estratégias. O conjunto de dados Yelp foi escolhido por sua riqueza e diversidade de avaliações de usuários, tornando-o ideal para avaliação de clustering.
Nossos modelos, ERASMObase e ERASMONV, apresentam resultados de avaliação de qualidade de agrupamento distinctos e bem separados (Tabela 1). Esta tabela mostra os resultados de avaliação de qualidade de agrupamento para os algoritmos mais performantes em cada conjunto de dados e combinação de abordagem. O melhor algoritmo foi escolhido com base no maior valor de SS. Fornece-se o número ótimo de clusters (k) e os resultados para SS, CHI e DBI. Os valores em negrito indicam os melhores resultados para cada métrica.

Tabela 1: Avaliação de qualidade de agrupamento para os algoritmos mais performantes em cada conjunto de dados e combinação de abordagem.

Conjunto de dados Abordagem Algoritmo melhor Melhor k SS CHI DBI
Bancos MPNet-v2 k-means 2 0,27 1.981,53 1,46
OpenAI k-means 9 0,11 212,96 2,73
LLaMA-2 k-means++ 8 0,22 593,66 1,66
Falcon k-means 2 0,23 1.776,67 1,56
GPT2 Médio k-means 2 0,40 4.764,08 0,90
PMV2 + DICE k-means 2 0,31 2.389,25 1,33
ERASMObase k-means 2 0,75 12.038,44 0,37
ERASMONV AHC 2 0,71 7.570,38 0,43
Olist MPNet-v2 k-means 2 0,24 5.927,77 1,59
OpenAI k-means 3 0,19 3.946,14 1,83
LLaMA-2 k-means 4 0,71 43.306,34 0,45
Falcon k-means 6 0,66 45.512,63 0,55
GPT2 Médio k-means 2 0,48 26.471,54 0,75
PMV2 + DICE SC 2 0,61 27.578,16 0,67
ERASMObase SC 2 0,75 54.236,31 0,30
ERASMONV k-means 2 0,77 62.036,87 0,32
Yelp MPNet-v2 AHC 2 0,23 36,61 2,25
OpenAI AHC 2 0,07 38,78 3,86
LLaMA-2 k-means 10 0,29 445,87 1,42
Falcon k-means++ 14 0,32 442,83 1,22
GPT2 Médio k-means 2 0,39 1.898,25 1,00
PMV2 + DICE AHC 2 0,53 32,86 1,08
ERASMObase SC 2 0,78 7.702,89 0,28
ERASMONV AHC 2 0,79 8.410,94 0,28
PetFinder.my MPNet-v2 k-means 2 0,14 236,58 2,28
OpenAI AHC 2 0,16 3,29 1,75
LLaMA-2 k-means++ 17 0,35 179,00 1,38
Falcon k-means++ 2 0,20 397,65 1,86
GPT2 Médio AHC 2 0,55 636,2 0,70
PMV2 + DICE k-means 5 0,18 242,83 1,85
ERASMObase k-means 2 0,72 3.351,95 0,40
ERASMONV AHC 2 0,73 3.063,55 0,34
Clothings MPNet-v2 k-means 3 0,12 195,01 2,47
OpenAI SC 5 0,07 70,17 2,90
LLaMA-2 k-means++ 9 0,37 435,45 1,53
Falcon k-means 12 0,24 326,64 1,54
GPT2 Médio k-means 2 0,52 3.541,87 0,68
PMV2 + DICE AHC 2 0,17 72,74 1,97
ERASMObase k-means 2 0,72 6.208,52 0,39
ERASMONV k-means++ 2 0,
71 5,916.57 0,39 Título Suprimido devido à Extensão Excessiva 13 clusters, refletindo seus escores DBI mais baixos. Isso destaca o desempenho de agrupamento superior de nossos modelos. -10 0 10 -5 0 5 (a) MPNet-v2 -10 0 10 -10 0 10 (b) OpenAI -25 0 25 -25 0 25 (c) LLaMA-2 -25 0 25 -20 0 (d) Falcon -20 0 20 -10 0 10 (e) GPT2 Medium -20 0 20 -10 0 10 (f) PMV2 + DICE -25 0 25 -5 0 5 (g) ERASMObase -25 0 25 -5 0 5 (h) ERASMONV Fig. 3: Visualização t-SNE de representações de embeddings no conjunto de dados Yelp para diferentes modelos: (a) MPNet-v2, (b) OpenAI, (c) LLaMA-2, (d) Falcon, (e) GPT2 Medium, (f) PMV2 + DICE, (g) ERASMObase e (h) ERASMONV. 6 Discussão Os resultados de SS consistentemente destacam a eficácia superior de estratégias de agrupamento do ERASMObase e ERASMONV em todos os conjuntos de dados. O ERASMObase alcançou os maiores valores de SS nos conjuntos de dados de Bancos e Roupas, enquanto o ERASMONV liderou nos conjuntos de dados Olist, Yelp e PetFinder.my. Isso indica que ambas as estratégias ajudam a formar clusters bem definidos, com o ERASMObase tendo uma leve vantagem em alguns conjuntos de dados. Os valores de SS mais altos para esses modelos sugerem que eles são melhores para criar clusters distintos do que estratégias como MPNet-v2, OpenAI e Falcon, que mostraram valores de SS significativamente mais baixos, indicando menor relevância para a qualidade de agrupamento. Os resultados de DBI também apoiam a eficácia de ERASMObase e ERASMONV. Ambas as estratégias alcançaram consistentemente os valores de DBI mais baixos, especialmente excelentes nos conjuntos de dados de Bancos, Olist e Yelp. Um valor de DBI mais baixo indica clusters mais compactos e bem separados, confirmado que nossos modelos propostos formam clusters apertados e distintos. O ERASMObase geralmente mostrou escores DBI ligeiramente melhores, sugerindo que produz clusters mais compactos do que o ERASMONV. Em contraste, abordagens como OpenAI e MPNet-v2 tiveram valores de DBI significativamente mais altos, refletindo menos adequação para a compactidade e separação de clusters. Os resultados de CHI corroboram as tendências observadas em SS e DBI.
ERASMObase e ERASMONV obtiveram os maiores escores de CHI em relação a muitos conjuntos de dados, com 14 autores suprimidos devido ao excesso de comprimento. ERASMObase liderou nos conjuntos de dados de Bancos e Roupas, enquanto ERASMONV nos conjuntos de dados Olist e Yelp. Escores de CHI altos indicam que os modelos propostos criam agrupamentos que não apenas são bem separados, mas também são altamente densos. Esses resultados superiores em múltiplas métricas sublinham a robustez e eficácia do abordagem ERASMO. Outros modelos, como MPNet-v2, OpenAI e Falcon, demonstraram escores de CHI mais baixos, indicando uma eficácia de agrupamento menos eficaz. ERASMO tem limitações, incluindo a dependência de dados de alta qualidade, desafios com conjuntos de dados ambíguos e demandas computacionais significativas para fine-tuning. A shuffling de sequências aleatórias pode afetar a reproducibilidade, e a verbalização de tokens numéricos não melhora consistentemente os resultados, justificando uma investigação adicional. Além disso, aplicar métricas tradicionais como SS, CHI e DBI para analisar agrupamentos de espaços de representação variados parece ser um desafio de pesquisa aberto ainda não resolvido na literatura. Embora essas métricas sejam projetadas para espaços de representação uniformes, são frequentemente aplicadas a espaços de representação diferentes, como demonstrado por estudos anteriores [6,14]. Reconhecemos essas limitações e estresse a relevância de investigar e desenvolver métricas refinadas capazes de avaliar corretamente embeddings de espaços dimensionais variados. Apesar desses desafios, ERASMO significativamente avança as técnicas de agrupamento ao melhorar a representação de dados. Essa inovação estabelece o palco para a potencial padronização de métricas e melhora a qualidade de agrupamento. ERASMO é um desenvolvimento crucial na busca por estratégias de agrupamento mais robustas. 7 Conclusão Explorar dados estruturados e textuais simultaneamente para análise de agrupamento é um problema desafiador.
Este estudo apresentou e avaliou as abordagens de agrupamento ERASMObase e ERASMONV, demonstrando sua superioridade em termos de eficácia empírica em múltiplos conjuntos de dados. Os resultados, baseados em SS, DBI e CHI, revelaram consistentemente que os modelos propostos ajudam a criar agrupamentos bem definidos, compactos e densos, superando todas as estratégias. Apesar de suas altas demandas computacionais e dependência da qualidade dos dados, encontramos que os modelos ERASMO se adequam a ferramentas de agrupamento práticas. O futuro trabalho pode se concentrar em otimizar a eficiência computacional e melhorar a robustez para conjuntos de dados diversificados e ruidosos. Agradecimentos Este projeto foi apoiado pelo Ministério da Ciência, Tecnologia e Inovações do Brasil, com recursos da Lei nº 8.248, de 23 de outubro de 1991, dentro do âmbito do PPI-SOFTEX, coordenado pela Softex e publicado pela Arquitetura Cognitiva (Fase 3), DOU 01245.003479/2024 -10.