GovBERT-BR: Modelo de Linguagem Baseado em BERT para Dados Governamentais do Português Brasileiro

Mariana O. Silva1[0000−0003−0110−9924], Gabriel P. Oliveira1[0000−0002−7210−6408], Lucas G. L. Costa1[0009−0002−8898−4237], e Gisele L. Pappa1[0000−0002−0349−4494] Universidade Federal de Minas Gerais (UFMG) – Belo Horizonte, MG, Brasil {mariana.santos,gabrielpoliveira}@dcc.ufmg.br lucas-lage@ufmg.br, glpappa@dcc.ufmg.br Resumo. Dado o crescente interesse em processamento de linguagem natural (NLP) para aplicações governamentais, especialmente no Brasil, onde grandes quantidades de dados governamentais são processados diariamente, a necessidade de modelos de NLP especializados adaptados às nuances do português brasileiro e aos domínios jurídico e administrativo tornou-se cada vez mais aparente. No entanto, modelos existentes podem lutar para interpretar corretamente as complexidades de textos governamentais, frequentemente levando a desempenhos subótimos em tarefas de classificação e análise de documentos. Para abordar esses desafios, apresentamos o GovBERT-BR, um modelo de linguagem pré-treinado adaptado ao contexto governamental brasileiro, abrangendo domínios jurídico e administrativo. Através de insights de textos governamentais diversificados, o GovBERT-BR aborda os desafios de interpretar corretamente o português brasileiro e a terminologia jurídica e burocrática única presente em documentos governamentais. Presentamos o processo de pré-treinamento e avaliação experimental do GovBERT-BR, comparando seu desempenho contra modelos baseline em várias tarefas de classificação de texto relevantes para o setor público brasileiro. Nossos achados demonstram que o GovBERT-BR supera modelos existentes em tarefas de classificação de documentos e texto curto, mostrando sua eficácia em analisar corretamente dados de texto governamental. Além disso, nossa análise revela insights sobre o comportamento de convergência do GovBERT-BR durante o ajuste fino, destacando sua rápida adaptação a tarefas downstream.
Palavras-chave: Processamento de Linguagem Natural · Dados Governamentais Brasileiros · Textos Legais · BERT · Modelos de Linguagem

1 Introdução Nos últimos anos, a aplicação de ferramentas de processamento de linguagem natural (NLP) nos dados governamentais tem aumentado significativamente. Esta tendência é majoritariamente impulsionada pela promessa da NLP de melhorar a eficiência, a transparência e a responsabilidade da administração pública. No Brasil, onde um volume vasto de dados governamentais é gerado e processado diariamente [4], as ferramentas de NLP podem otimizar várias processos administrativos ao automatizar a análise e interpretação de dados textuais, facilitando assim melhorias na tomada de decisão [10,20,8]. No entanto, a utilização eficaz desses dados é frequentemente limitada pela necessidade de modelos de NLP especializados capazes de interpretar corretamente as especificidades do português brasileiro e a terminologia legal e burocrática única. Os modelos de NLP existentes são predominantemente genéricos [19], treinados em conjuntos de dados que não refletem adequadamente as particularidades dos documentos governamentais brasileiros. Esta falta de adequação geralmente leva a desempenhos subótimos quando esses modelos são aplicados ao setor público brasileiro [20]. Nesse contexto, alguns esforços têm sido feitos para desenvolver modelos específicos para domínios, focalizados em tarefas legais [20,18,8] e administrativas [10]. Embora esses esforços representem importantes passos em frente, eles são frequentemente limitados em escopo, abordando apenas sub-contextos específicos dos dados governamentais. A natureza interdisciplinar dos documentos governamentais exige modelos capazes de integrar insights de múltiplos domínios de forma contínua. Por exemplo, documentos legais frequentemente se intersectam com procedimentos administrativos, e compreender essas inter-relações é crucial para a tomada de decisão eficaz na administração pública. Portanto, introduzimos o GovBERT-BR, um modelo de linguagem pré-treinado especificamente projetado para o contexto governamental brasileiro.
Ele integra tanto domínios administrativos quanto jurídicos, fornecendo uma perspectiva multifacetada para melhor se alinhar com a natureza diversa de dados de texto governamentais. Neste artigo, apresentamos o processo de treinamento prévio e o setup experimental do GovBERT-BR. Nossa avaliação envolve uma série de tarefas de classificação de texto relevantes ao contexto governamental brasileiro, comparando o desempenho do GovBERT-BR com vários modelos de base. Nossas principais contribuições são resumidas abaixo. – Introduzimos um modelo de linguagem pré-treinado inédito projetado explicitamente para o domínio governamental brasileiro, incorporando insights de ambos os domínios administrativos e jurídicos para melhorar sua adaptabilidade e eficácia. – Fornecemos um quadro de avaliação abrangente, incluindo um conjunto diverso de tarefas de classificação de texto pertinentes ao contexto governamental brasileiro. Isso permite uma avaliação minuciosa do desempenho do GovBERT-BR em diferentes tipos de dados de texto governamentais. – Nossos resultados experimentais demonstram o desempenho superior ou competitivo do GovBERT-BR em relação a modelos de base em vários conjuntos de dados. Isso destaca sua eficácia em classificar corretamente texto governamental, realçando seu potencial para melhorar a compreensão de texto e tomada de decisão no setor público brasileiro.

2 Trabalhos Relacionados O uso de modelos de linguagem em aplicações governamentais mudou como os governos interagem com cidadãos e gerenciam informações. De fato, esses modelos oferecem capacidades avançadas em Processamento de Linguagem Natural (NLP), permitindo automação no entendimento de perguntas públicas, análise de políticas e outras aplicações utilizando dados governamentais abertos (OGD) [7,14]. Eles podem ser aplicados em várias áreas, incluindo serviços de consultoria [9], modelagem de tópicos [10] e análise de sentimento relacionada a políticas governamentais [23].
Além disso, a linguagem é crucial nestes modelos, pois a linguagem do modelo deve se alinhar com as linguagens utilizadas no domínio alvo para garantir uma adaptação mais eficiente. Portanto, trabalhos recentes propuseram modelos distintos para abordar tarefas relacionadas ao governo em várias línguas [1, 3, 11, 15, 22]. No contexto brasileiro, a maioria dos modelos que abordam tarefas do governo são construídos a partir do BERTimbau, um modelo geral de propósito pré-treinado em um grande corpus de textos em português raspados da Web [19]. Esses modelos relacionados ao governo podem ser divididos em duas categorias distintas de acordo com seu propósito: modelos do domínio jurídico e modelos do domínio administrativo. O primeiro grupo inclui modelos que se concentram principalmente em tarefas jurídicas e legislativas, incluindo textos do sistema jurídico brasileiro em sua fase de pré-treinamento para lidar com a linguagem e conceitos jurídicos de forma eficaz. Por exemplo, o LegalBERTPT-br [18] é um modelo para minar tópicos em comentários sobre projetos de leis brasileiras. O LegalBert-pt [20], o JurisBERT [21] e o CLSJUR.BR [12] utilizam textos exclusivamente da área judiciária brasileira para tarefas como reconhecimento de entidades nomeadas (NER), similaridade textual semântica (STS) e resumo de documentos. Finalmente, o RoBERTaLexPT [8] utiliza um grande corpus da área judiciária e legislativa sobre NER e tarefas de classificação. A principal diferença entre esses modelos é que o corpus do RoBERTaLexPT contém textos em ambas as variedades do português, europeu e brasileiro, enquanto os outros consideram apenas textos em português brasileiro. Por outro lado, os modelos do domínio administrativo são projetados para apoiar funções governamentais variadas fora da esfera jurídica, como gerenciamento de processos de licitação e processamento de informações das gazetas oficiais. O desenvolvimento de soluções para este domínio específico é relativamente recente, com poucos modelos dedicados exclusivamente a este contexto.
Um exemplo notável é o modelo LiBERT-SE [10], desenvolvido a partir de um corpus de segmentos de gazeta oficial brasileira e avaliado em tarefas de detecção de tópicos em documentos de licitação. Considerando o trabalho relacionado mencionado anteriormente, nosso objetivo é propor um modelo que aborde os domínios jurídico e administrativo no português brasileiro. GovBERT-BR pontua o gap entre esses dois domínios, fornecendo uma solução abrangente para lidar com dados de texto governamental diversificados. Ao integrar insights de ambos os contextos jurídico e administrativo, o GovBERT-BR visa melhorar a eficiência e a eficácia das aplicações de processamento de linguagem natural no setor público brasileiro, contribuindo, ao final, para tomada de decisões melhoradas.

3 O dados governamentais é uma fonte rica e diversificada de informações que contém muitos documentos, incluindo documentos de licitação pública, textos legais, projetos de lei, relatórios administrativos e mais. No entanto, a complexidade e a natureza especializada desse dados apresentam desafios significativos para modelos de processamento de linguagem natural genéricos, que frequentemente falham em capturar as nuances e o vocabulário específico utilizado em textos governamentais. Além disso, modelos específicos de domínio tendem a se concentrar em contextos sub-narrativos estreitos, falhando em abordar a natureza interdisciplinar inerente nos documentos governamentais de forma integral. Para superar esses desafios, apresentamos o GovBERT-BR, um modelo de linguagem treinado especificamente para o contexto governamental brasileiro. Ele considera ambos os domínios jurídico e administrativo, fornecendo uma perspectiva multifacetada que pode melhor se alinhar com a natureza diversificada dos dados de texto governamental. Nesta seção, descrevemos o modelo de linguagem treinado utilizado como base para o GovBERT-BR (Seção 3.1) e detalhamos as metodologias empregadas em seu desenvolvimento (Seção 3.2).
1 Modelo pré-treinado GovBERT-BR é construído sobre a arquitetura do BERTimbau [19], o primeiro modelo de linguagem de grande escala em português. O BERTimbau, baseado na arquitetura BERT (Representações de Codificadores Bidirecionais a partir de Transformadores) [6], foi fine-tunado em várias tarefas para melhorar seu desempenho em entender texto em português. O GovBERT-BR herda essa arquitetura e a estende para se concentrar especificamente nas nuances dos documentos governamentais e legais brasileiros. 3.2 Treinamento prévio O processo de treinamento prévio do GovBERT-BR envolve treinar o BERTimbau com dois corpora distintos, cada um projetado para capturar as complexidades dos textos governamentais e legais em português brasileiro. Acreditamos que essa abordagem multi-domínio permite ao GovBERT-BR fornecer uma perspectiva compreensiva que capture a interação entre a linguagem legal e administrativa, oferecendo um recurso poderoso para interpretar documentos governamentais brasileiros. A figura 1 mostra o resumo da metodologia de treinamento prévio do GovBERT-BR, que envolve uma abordagem em duas fases. Inicialmente, o modelo é treinado com dados do domínio administrativo para equipá-lo com uma compreensão de termos técnicos e procedimentos administrativos comuns encontrados em textos governamentais. Em seguida, o modelo é submetido a treinamento prévio adicional com um conjunto de dados composto por documentos legais relacionados a recursos extraordinários recebidos pelo Supremo Tribunal Federal (STF). Dados Administrativos. O corpus de treinamento inicial inclui documentos de licitação pública e segmentos do diário oficial, que contêm textos resumidos publicados para fornecer informações sobre o processo de licitação [5]. Ele compreende 1.578.107 sentenças e abrange vários tipos de documentos e dados administrativos, incluindo anúncios, avisos e termos de licitação. Dados Legais.
O segundo corpus de treinamento inclui documentos legais relacionados a recursos extraordinários recebidos pelo STF. Ele contém um subconjunto de 1.760.862 páginas originadas do conjunto de dados VICTOR [13]. Tarefa. A tarefa de treinamento prévio empregada para o GovBERT-BR é a tarefa de Modelo de Linguagem Mascada (MLM). Nessa tarefa, uma porcentagem de palavras em uma sequência (15%) são mascadas, e o modelo é treinado para prever esses tokens mascados com base no contexto circundante. Esse método permite que o modelo aprenda relações contextuais e desenvolva uma compreensão profunda dos padrões linguísticos específicos ao domínio. Configuração. Cada sessão de treinamento prévio é limitada a 10 épocas, com checkpoints salvos ao final de cada época. Utilizamos um tamanho de batch de 64 sequências, cada uma contendo um máximo de 300 tokens. Ambos os passos de treinamento prévio envolveram mais de 245.000 passos, garantindo exposição diversa ao conjunto de dados.

4 Desenho Experimental Para avaliar a eficácia do modelo de linguagem pré-treinado GovBERT-BR, realizamos uma série de experimentos em tarefas de classificação de texto relevantes ao contexto governamental brasileiro. Esses experimentos visam avaliar o desempenho do GovBERT-BR em relação a modelos de base e abordagens NLP existentes, demonstrando sua capacidade de analisar e interpretar documentos governamentais com precisão. Nessa seção, descrevemos os modelos de base considerados (Seção 4.1), as tarefas downstream (Seção 4.2) e conjuntos de dados (Seção 4.3), e os métricas de avaliação utilizadas (Seção 4.4).

4.1 Modelos de Base Nossa principal objetiva é avaliar se a integração de dados de treinamento prévio legais e administrativos no GovBERT-BR leva a um desempenho melhor em tarefas de classificação de texto governamental. Portanto, comparamos nosso modelo com vários modelos de base, incluindo modelos gerais e específicos ao domínio (Tabela 1).
Relativamente ao domínio geral, consideramos o modelo de linguagem geral BERTimbau-Base, amplamente utilizado e treinado em um grande conjunto de dados em português e utilizado como base para o modelo GovBERT-BR. Além de BERTimbau, incluímos modelos específicos para domínios treinados em dados legais e administrativos separadamente. Para o domínio legal, consideramos o modelo LegalBERT-PT [20], que também é construído sobre BERTimbau e treinado em um vasto conjunto de documentos legais, permitindo capturar as nuances do linguagem e termos legais. Como GovBERT-BR se baseia em BERTimbau, comparando ambos os modelos permite avaliar o impacto do treinamento adicional em textos legais e administrativos. Para o domínio administrativo, consideramos o modelo LiBERT-SE [10], um modelo de linguagem treinado para o contexto de licitações públicas. LiBERT-SE é construído sobre BERTimbau usando a tarefa MLM e um conjunto de dados de 300.000 segmentos de gazeta oficial provenientes de vários municípios em Minas Gerais, como previamente extraído em [5]. Como se concentra em linguagem e procedimentos administrativos, um modelo como esse é um benchmark relevante para avaliar o desempenho do GovBERT-BR em tarefas administrativas. 4.2 Tarefas Downstream Como tarefas downstream, nos concentramos em dois classificações de texto distintas dentro do domínio governamental: classificação de documentos e classificação de texto curto. Classificação de Documentos. Esta tarefa envolve categorizar documentos, como textos legais, projetos de lei, relatórios administrativos e documentos de licitação pública, em classes pré-definidas.
Classificação de documentos fornece uma compreensão de alto nível do conteúdo e do propósito de cada documento, facilitando a recuperação e a organização eficientes de documentos dentro de sistemas governamentais. Classificação de Texto Breve. Diferente da classificação de documentos, essa tarefa se concentra em classificar segmentos de texto mais curtos, como descrições de itens, resumos ou motivações. A classificação de texto breve é particularmente útil para extrair informações relevantes de grandes volumes de dados textuais, permitindo tomada de decisões rápidas e análise em processos governamentais.

4.3 Conjuntos de Dados

Para cada domínio, três conjuntos de dados são selecionados para avaliar o desempenho do GovBERT-BR e dos modelos de base. A tabela 2 resume as características chave de cada conjunto de dados, descritas abaixo.

Tabela 2. Conjuntos de dados utilizados para as tarefas downstream.

Ref. Conjunto de Dados Ano Domínio Tarefa Downstream Tamanho
[17] LiPSet 2022 Administrativo Classificação de Documentos 9,761 -
[13] NaPEx 2024 Administrativo Classificação de Texto Breve 583,174 -
[13] NaPEx 2024 Administrativo Classificação de Texto Breve 583,174
[16] SVic 2020 Jurídico Classificação de Documentos 339,478
[2] Motions 2021 Jurídico Classificação de Texto Breve 6,449
[2] RRIoP 2021 Jurídico Classificação de Texto Breve 10,784
LiPSet [17]. Contém 9,761 documentos públicos de licitação rotulados do estado de Minas Gerais, Brasil. Esses documentos são classificados em 12 classes: Ata Registro de Preços, Ata de Dispensa, Ata de Pregão Presencial, Outras Atas, Edital, Contrato, Aditamento, Aviso, Ratificação, Errata, Homologação e Outros.
NaPEx. Contém 583,174 itens de despesa pública rotulados do estado de Minas Gerais, Brasil.
2 Cada item apresenta uma descrição de texto curta e é classificado em cinco classes de natureza de despesa: Obras (construção), Serviços (serviços), Material de Consumo (materiais consumíveis), Material Permanente (materiais permanentes) e Locação (aluguel). ProdServ. Representa os mesmos itens de despesa pública da NaPEx, mas, nesse conjunto de dados, cada item de descrição é classificado como produtos ou serviços. SVic [13]. É um subconjunto do conjunto de dados VICTOR, contendo 94.267 documentos legais com 339.478 páginas rotuladas. Os casos são rotulados como Acórdão (decisões de tribunal inferior sob revisão), Recurso Extraordinário (petições de apelo), Agravo de Recurso Extraordinário (motions contra a petição de apelo), Sentença (sentenças), Despacho (ordens do tribunal) e Outros. Motions [16]. Contém 6.449 processos legais, cada um com um número individual e variável de motions, rotulados por advogados. Processos legais se referem a ações legais formais ou casos apresentados perante um tribunal de justiça. As motions, por sua vez, são solicitações formais feitas a um juiz durante os processos legais, tipicamente buscando uma decisão ou sentença sobre um aspecto específico do caso. Os casos nesse conjunto de dados são rotulados como Arquivado (arquivado), Ativo (ativo) ou Suspenso (suspensos), indicando o status dos processos legais. RRIoP [2]. Contém anotações retóricas dentro do domínio jurídico, focalizando sentenças extraídas de sentenças judiciais da Justiça do Estado de Mato Grosso do Sul (TJMS), Brasil. Ele compreende 10.784 petições de 70 processos civis apresentados perante o tribunal TJMS e foi rotulado manualmente com papéis retóricos específicos para petições. Os casos nesse conjunto de dados são rotulados como Identificação das partes (identificação), Fatos (fatos), Argumentos (argumentos), Fundamentação jurídica (fundamentação jurídica), Jurisprudência (precedentes), Pedidos (pedidos), Valor da causa (remédio) e Outros.
4 Configuração de Avaliação

Em nossa configuração experimental, cada conjunto de dados é partitionado em subconjuntos distintos para treinamento, validação e teste, mantendo a distribuição de valores de rótulo em todas as partições. Dado que todos os conjuntos de dados apresentam desbalanceamento de classes, realizamos a partição de forma estratificada por classe. Esse esquema de partição estratificada aloca 70% dos dados para treinamento, 20% para validação e o restante 10% para teste. No entanto, é importante notar que não utilizamos validação cruzada nesse estudo, o que pode introduzir bias nos resultados, pois o desempenho do modelo é avaliado em uma única partição em vez de múltiplas folds. Essa escolha limita a capacidade de generalizar os achados em diferentes partições de dados. Além disso, o desbalanceamento de classes presente em todos os conjuntos de dados representa um desafio. Embora não utilizemos técnicas de oversampling ou undersampling para refletir cenários reais, técnicas de balanceamento poderiam ser aplicadas durante o treinamento sem comprometer a integridade do cenário de teste imbalanciado. Essas técnicas poderiam ajudar a mitigar o impacto do desbalanceamento de classes no desempenho do modelo, levando a resultados mais confiáveis e interpretáveis. Deixamos a exploração dessas estratégias de balanceamento para o trabalho futuro, pois poderiam melhorar ainda mais a robustez dos modelos no manejo de distribuições de dados desbalanceadas. Todos os modelos de linguagem avaliados são treinados por um número fixo de cinco épocas sem busca extensa de hiperparâmetros. Os modelos são treinados até que a perda de validação seja alcançada, garantindo desempenho estável. Após a convergência, ou na última época, o desempenho do modelo é avaliado usando o métrica F1-Macro. Para garantir a robustez de nossas avaliações, conduzimos cinco experimentos para cada modelo, variando os sementes aleatórias. Em seguida, os resultados são médios para produzir uma estimativa mais confiável do desempenho do modelo.
5 Resultados Experimentais

Nesta seção, apresentamos os resultados experimentais obtidos ao avaliar o GovBERT-BR em várias tarefas de classificação de texto relevantes para o domínio governamental brasileiro. Analisamos o desempenho do GovBERT-BR em termos de eficácia global (Seção 5.1), o impacto do treinamento prévio em múltiplos domínios (Seção 5.2) e sua convergência em diferentes domínios governamentais (Seção 5.3).

5.1 Desempenho Global

Primeiramente, avaliamos como o desempenho do GovBERT-BR se compara com outros modelos de ponta da área de processamento de linguagem natural (NLP). As tabelas 3 e 4 apresentam os resultados das tarefas de classificação de documentos e textos curtos nos domínios administrativo e jurídico, respectivamente. A significância estatística é relatada usando o teste de Wilcoxon de rank-sum para comparar as distribuições dos scores F1-Macro. No classificação de documentos, o GovBERT-BR apresenta o melhor score F1-Macro no conjunto de dados LiPSet, com uma média de 0,948, superando significativamente o modelo geral-purpose BERTimbau (W = 25, p < 0,05) e os modelos específicos do domínio LiBERT-SE (W = 22, p ≤ 0,05).

Tabela 3. Comparação de desempenho em tarefas de classificação de documentos e textos curtos no domínio administrativo. Os scores F1-Macro são relatados com desvios-padrão.

Documentos Textos Curtos Modelo LiPSet NaPEx ProdServ BERTimbau 0,902 ± 0,026 0,839 ± 0,003 0,816 ± 0,003 LiBERT-SE 0,937 ± 0,006 0,836 ± 0,002 0,815 ± 0,003 LegalBERT-PT 0,945 ± 0,009 0,831 ± 0,008 0,814 ± 0,004 GovBERT-BR 0,948 ± 0,008 0,839 ± 0,003 0,814 ± 0,004

Tabela 4. Comparação de desempenho em tarefas de classificação de documentos e textos curtos no domínio jurídico. Os scores F1-Macro são relatados com desvios-padrão.

Documentos Textos Curtos Modelo SVic Motions RRIoP BERTimbau 0,779 ± 0,008 0,782 ± 0,004 0,825 ± 0,010 LiBERT-SE 0,774 ± 0,010 0,777 ± 0,005 0,814 ± 0,006 LegalBERT-PT 0,787 ± 0,007 0,781 ± 0,002 0,839 ± 0,005 GovBERT-BR 0,794 ± 0,012 0,784 ± 0,003 0,838 ± 0,005
No entanto, quanto ao LegalBERT-PT, a diferença no desempenho não é estatisticamente significativa (W = 15, p > 0,05). Similarmente, no conjunto de dados SVic, o GovBERT-BR alcança uma pontuação F1-Macro de 0,794, demonstrando seu desempenho competitivo. Ele supera significativamente o LiBERT-SE (W = 23, p < 0,05), mas a diferença no desempenho em relação ao BERTimbau (W = 21, p > 0,05) e ao LegalBERT-PT (W = 20, p > 0,05) não é estatisticamente significativa. Esses resultados demonstram que a pré-treinamento em dados legais e administrativos fornece ao GovBERT-BR uma compreensão sólida das nuances do texto governamental brasileiro, permitindo que ele realize bem em conjuntos de dados e domínios diversificados. Quanto à classificação de texto curto, o GovBERT-BR apresenta desempenho competitivo em todos os conjuntos de dados. Ele alcança a pontuação F1-Macro mais alta no conjunto de dados NaPEx, empatando com o BERTimbau em 0,839, e realiza bem nos conjuntos de dados Motions e RRIoP, indicando sua robustez em lidar com dados de texto curto variados em contextos governamentais. Embora o LegalBERT-PT superie ligeiramente o GovBERT-BR no conjunto de dados RRIoP, o desempenho balanceado do GovBERT-BR em todos os conjuntos de dados destaca sua versatilidade. Finalmente, nossos resultados revelam não haver diferença estatística entre todos os modelos no conjunto de dados ProdServ. Em geral, o GovBERT-BR demonstra desempenho superior ou competitivo em relação a modelos de base em múltiplos conjuntos de dados, realçando sua eficácia em classificar corretamente tanto dados de nível de documento quanto dados de texto curto dentro do contexto governamental.
(Domínios) Administrativos e (B) Legais. A linha horizontal tracejada representa a média do score F1-Macro para cada conjunto de dados. O desempenho robusto destaca sua versatilidade e eficácia no manejo de dados textuais governamentais variados. 5.2 Treinamento de Pré-ensino Multi-Domínio Para avaliar o impacto da incorporação de dados de treinamento de pré-ensino em domínios administrativos e legais, comparamos o desempenho do GovBERT-BR com modelos treinados em domínios únicos. A figura 2 mostra a distribuição dos scores F1-Macro para modelos treinados em um domínio único apenas (LiBERT-SE e LegalBERT-PT) e multi-domínios (GovBERT-BR), para tarefas de classificação de texto em (A) domínio administrativo e (B) domínio legal. A linha horizontal tracejada representa a média do score F1-Macro para cada conjunto de dados. No domínio administrativo (Figura 2A), para a maioria dos conjuntos de dados, o GovBERT-BR atinge um score F1-Macro médio alto em comparação ao modelo de LiBERT-SE treinado em um domínio único. A exceção é o conjunto de dados ProdServ, onde a diferença de desempenho entre GovBERT-BR e LiBERT-SE é mínima, indicando que o benefício do treinamento de pré-ensino multi-domínio pode variar dependendo do conjunto de dados. Isso sugere que, enquanto o treinamento de pré-ensino multi-domínio geralmente melhora o desempenho, seu impacto pode ser menos pronunciado em certos contextos administrativos. Da mesma forma, no domínio legal (Figura 2B), o GovBERT-BR supera o modelo de LegalBERT-PT treinado em um domínio único em quase todos os conjuntos de dados, exceto pelo RRIoP. Nesse conjunto de dados particular, o LegalBERT-PT apresenta uma leve vantagem, possivelmente devido a...
Seu treinamento especializado em textos legais, que estão mais alinhados com o conteúdo do RRIoP. No entanto, a diferença na performance não é estatisticamente significativa, indicando que o treinamento do GovBERT-BR em dados de domínio administrativo não prejudica suas capacidades de domínio legal. Em geral, os resultados destaquem os benefícios do treinamento prévio em múltiplos domínios. A performance consistente do GovBERT-BR em vários conjuntos de dados, abrangendo tanto textos administrativos quanto legais, demonstra a robustez e versatilidade do treinamento prévio em múltiplos domínios. Essa abordagem aproveita uma compreensão contextual mais ampla, tornando o modelo mais adaptável a diferentes tipos de tarefas de classificação de texto em contextos governamentais. Essa versatilidade destaca o potencial do GovBERT-BR como um recurso valioso para interpretar documentos governamentais diversificados, apoiando assim processamento de informações mais eficiente e precisa em operações governamentais.

5.3 Análise de Convergência

Para avaliar ainda mais o desempenho e a estabilidade dos modelos, analisamos as pontuações F1-Macro ao longo das épocas durante o ajuste fino em todas as tarefas downstream. A figura 3A apresenta o desempenho médio, em termos de F1-Macro, de cada modelo em todos os seis conjuntos de dados, destacando como cada modelo converge ao longo do tempo. A figura 3B mostra as linhas de regressão para o desempenho médio de cada modelo em todos os conjuntos de dados durante as sessões de ajuste fino. As linhas de regressão linear fornecem insights sobre a tendência geral de melhoria ou degradação do desempenho ao longo do processo de ajuste fino ao longo das épocas. Na figura 3A, observamos que o BERTimbau inicialmente apresenta um desempenho médio inferior ao dos modelos específicos de domínio, indicando uma taxa de convergência mais lenta nos primeiros epochs. Um resultado assim é esperado, pois o modelo sofre ajustes significativos nos primeiros epochs, transitando de treinamento amplo para tarefas mais especializadas.
À medida que o treinamento avança, o desempenho do BERTimbau aumenta gradualmente, alcançando níveis comparáveis aos modelos específicos do domínio, embora com uma taxa de melhoria mais lenta. Isso sugere que o BERTimbau pode precisar de mais épocas para alcançar uma adaptação completa. Em geral, todos os modelos específicos do domínio demonstram convergência rápida em comparação ao baseline do BERTimbau, com o GovBERT-BR notavelmente alcançando os maiores escores F1-Macro inicialmente no processo de treinamento. O LiBERT-SE e o LegalBERT-PT também convergem rapidamente, demonstrando a eficácia do pré-treinamento específico do domínio. Isso permite que os modelos ajustem rapidamente às nuances das tarefas alvo e alcancem níveis de desempenho elevados inicialmente no processo de treinamento. No entanto, o GovBERT-BR mantém consistentemente um escore F1-Macro mais alto, sugerindo que o pré-treinamento multi-domínio fornece um vantagem significativa em várias tarefas de classificação de texto governamental. A figura 3B confirma essas observações, fornecendo uma representação visual direta da trajetória de melhoria do desempenho ao longo das épocas. A inclinação mais acentuada da linha indica uma melhoria mais rápida do desempenho durante o ajuste fino. Por outro lado, uma inclinação mais suave indica uma taxa de melhoria mais lenta. Embora o BERTimbau apresente a inclinação mais acentuada entre os modelos, indicando uma melhoria relativamente rápida, começa a partir de um nível de desempenho mais baixo em comparação aos modelos específicos do domínio. Por outro lado, o GovBERT-BR, o LiBERT-SE e o LegalBERT-PT, embora exibam inclinações ligeiramente mais suaves, começam a partir de níveis de desempenho mais altos, refletindo os benefícios do pré-treinamento específico do domínio.

Conclusões e Trabalho Futuro

Este artigo apresenta o GovBERT-BR, um modelo de linguagem treinado pré-ativamente especializado para o contexto governamental brasileiro, abrangendo domínios jurídico e administrativo.
Através do pré-treinamento em textos governamentais diversificados, o GovBERT-BR se destaca em superar os desafios de interpretação do português brasileiro e do vocabulário jurídico-burocrático complexo em documentos governamentais. A avaliação experimental demonstra que o GovBERT-BR apresenta desempenho superior em relação a modelos existentes em várias tarefas de classificação de documentos e textos curtos relevantes para o setor público brasileiro, destacando sua eficácia em analisar com precisão dados de texto governamental. Além disso, a análise do comportamento de convergência do GovBERT-BR durante a fine-tuning revela sua rápida adaptação a tarefas downstream, destacando sua versatilidade e eficácia em lidar com desafios de classificação de textos diversificados em contextos governamentais. Ao oferecer uma solução integral para processar dados de texto governamental, o GovBERT-BR melhoria significativamente a eficiência e a eficácia de aplicações de processamento de linguagem natural no setor público brasileiro, contribuindo diretamente para tomadas de decisão mais informadas e processos de governança. Em resumo, o GovBERT-BR representa um avanço significativo na aplicação do processamento de linguagem natural no contexto governamental brasileiro. Nossa modelo pontua a lacuna deixada por modelos mais gerais ao abordar as nuances linguísticas e terminológicas específicas do português brasileiro e os domínios distintos de documentos legais e administrativos. Nossa abordagem de pré-treinamento integral, que inclui textos governamentais diversificados, garante que o GovBERT-BR possa lidar com as complexidades inerentes às tarefas de administração pública de forma mais eficaz do que modelos disponíveis anteriormente. Olhando para o futuro, pesquisas futuras podem explorar as extensões e aplicações potenciais do GovBERT-BR em outros domínios no cenário governamental brasileiro. Além disso, esforços contínuos para refinar e otimizar o desempenho do GovBERT-BR podem melhorar ainda mais sua utilidade e impacto em aplicações governamentais reais.
Finalmente, explorar maneiras de integrar o GovBERT-BR com outros modelos ou frameworks de processamento de linguagem natural existentes pode levar a efeitos sinérgicos, potencialmente melhorando seu desempenho global e ampliando suas capacidades para abordar desafios governamentais complexos. Agradecimentos. Esta obra foi financiada pelo Ministério Público do Estado de Minas Gerais, por meio do Projeto de Capacidades Analíticas, e pelo CNPq, CAPES, FAPEMIG e pelo projeto de parceria entre Amazon Web Services (AWS) e CNPq.