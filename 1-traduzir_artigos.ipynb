{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-AMpT5LyHGjN",
    "outputId": "8dccc0e4-bc77-4c72-8b80-c204365588f2",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade --force-reinstall pymupdf\n",
    "!pip install langdetect\n",
    "!pip install PyPDF2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V2nnTX7r5Qwt"
   },
   "source": [
    "Traduz e salva artigo traduzido sem as refer√™ncias (pula artigo caso arquivo da tradu√ß√£o exista)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "-AEeF5xXFRZ5",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Digite sua chave API da Groq (ou deixe em branco para pular tradu√ß√µes):  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\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "artigos_traduzidos/A Large Dataset of Spontaneous Speech with the Accent Spoken in S√£o Paulo for Automatic Speech Recognition Evaluation_traduzido.txt\n",
      "PDF: ./articles/A Large Dataset of Spontaneous Speech with the Accent Spoken in S√£o Paulo for Automatic Speech Recognition Evaluation.pdf j√° traduzido, pulando..\n",
      "artigos_traduzidos/A Transformer-Based Tabular Approach to Detect Toxic Comments_traduzido.txt\n",
      "PDF: ./articles/A Transformer-Based Tabular Approach to Detect Toxic Comments.pdf j√° traduzido, pulando..\n",
      "artigos_traduzidos/An Ensemble of LLMs Finetuned with LoRA for NER in Portuguese Legal Documents_traduzido.txt\n",
      "PDF: ./articles/An Ensemble of LLMs Finetuned with LoRA for NER in Portuguese Legal Documents.pdf j√° traduzido, pulando..\n",
      "artigos_traduzidos/Aroeira A Curated Corpus for the Portuguese Language with a Large Number of Tokens_traduzido.txt\n",
      "PDF: ./articles/Aroeira A Curated Corpus for the Portuguese Language with a Large Number of Tokens.pdf j√° traduzido, pulando..\n",
      "artigos_traduzidos/Assessing European and Brazilian Portuguese LLMs for NER in Specialised Domains_traduzido.txt\n",
      "PDF: ./articles/Assessing European and Brazilian Portuguese LLMs for NER in Specialised Domains.pdf j√° traduzido, pulando..\n",
      "artigos_traduzidos/Automatic Text Simplification for the Legal Domain in Brazilian Portuguese_traduzido.txt\n",
      "PDF: ./articles/Automatic Text Simplification for the Legal Domain in Brazilian Portuguese.pdf j√° traduzido, pulando..\n",
      "artigos_traduzidos/Developing Resource-Efficient Clinical LLMs for Brazilian Portuguese_traduzido.txt\n",
      "PDF: ./articles/Developing Resource-Efficient Clinical LLMs for Brazilian Portuguese.pdf j√° traduzido, pulando..\n",
      "artigos_traduzidos/Diversity in Data for Speech Processing in Brazilian Portuguese_traduzido.txt\n",
      "PDF: ./articles/Diversity in Data for Speech Processing in Brazilian Portuguese.pdf j√° traduzido, pulando..\n",
      "artigos_traduzidos/ERASMO Leveraging Large Language Models for Enhanced Clustering Segmentation_traduzido.txt\n",
      "PDF: ./articles/ERASMO Leveraging Large Language Models for Enhanced Clustering Segmentation.pdf j√° traduzido, pulando..\n",
      "artigos_traduzidos/Evaluating Large Language Models for Tax Law Reasoning_traduzido.txt\n",
      "PDF: ./articles/Evaluating Large Language Models for Tax Law Reasoning.pdf j√° traduzido, pulando..\n",
      "artigos_traduzidos/Evaluating Sentiment Quantification Methods in Brazilian Portuguese Corpora_traduzido.txt\n",
      "PDF: ./articles/Evaluating Sentiment Quantification Methods in Brazilian Portuguese Corpora.pdf j√° traduzido, pulando..\n",
      "artigos_traduzidos/Evaluating Short Text Stream Clustering on Large E-commerce Datasets_traduzido.txt\n",
      "PDF: ./articles/Evaluating Short Text Stream Clustering on Large E-commerce Datasets.pdf j√° traduzido, pulando..\n",
      "artigos_traduzidos/Gender-Neutral English to Portuguese Machine Translator Promoting Inclusive Language_traduzido.txt\n",
      "PDF: ./articles/Gender-Neutral English to Portuguese Machine Translator Promoting Inclusive Language.pdf j√° traduzido, pulando..\n",
      "artigos_traduzidos/GovBERT-BR A BERT-Based Language Model for Brazilian Portuguese Governmental Data_traduzido.txt\n",
      "PDF: ./articles/GovBERT-BR A BERT-Based Language Model for Brazilian Portuguese Governmental Data.pdf j√° traduzido, pulando..\n",
      "artigos_traduzidos/InRanker Distilled Rankers for Zero-Shot Information Retrieval_traduzido.txt\n",
      "PDF: ./articles/InRanker Distilled Rankers for Zero-Shot Information Retrieval.pdf j√° traduzido, pulando..\n",
      "artigos_traduzidos/LLM-Driven Chest X-Ray Report Generation With a Modular, Reduced-Size Architecture_traduzido.txt\n",
      "PDF: ./articles/LLM-Driven Chest X-Ray Report Generation With a Modular, Reduced-Size Architecture.pdf j√° traduzido, pulando..\n",
      "artigos_traduzidos/Optimizing CleanUNet Architecture Parameters for Enhancing Speech Denoising_traduzido.txt\n",
      "PDF: ./articles/Optimizing CleanUNet Architecture Parameters for Enhancing Speech Denoising.pdf j√° traduzido, pulando..\n",
      "artigos_traduzidos/Portuguese Emotion Detection Model Using BERTimbau Applied to COVID-19 News and Replies_traduzido.txt\n",
      "PDF: ./articles/Portuguese Emotion Detection Model Using BERTimbau Applied to COVID-19 News and Replies.pdf j√° traduzido, pulando..\n",
      "artigos_traduzidos/Pseudonymization in Legal Texts According to the LGPD A Named Entity Recognition Approach_traduzido.txt\n",
      "PDF: ./articles/Pseudonymization in Legal Texts According to the LGPD A Named Entity Recognition Approach.pdf j√° traduzido, pulando..\n",
      "artigos_traduzidos/Question Answering with Texts and Tables Through Deep Reinforcement Learning_traduzido.txt\n",
      "PDF: ./articles/Question Answering with Texts and Tables Through Deep Reinforcement Learning.pdf j√° traduzido, pulando..\n",
      "artigos_traduzidos/SARA - A Generative AI for Legal Process Summarization Based on Chain of Density Prompt Engineering_traduzido.txt\n",
      "PDF: ./articles/SARA - A Generative AI for Legal Process Summarization Based on Chain of Density Prompt Engineering.pdf j√° traduzido, pulando..\n",
      "artigos_traduzidos/Scaling and Adapting Large Language Models for Portuguese Open Information Extraction A Comparative Study of Fine-Tuning and LoRA_traduzido.txt\n",
      "PDF: ./articles/Scaling and Adapting Large Language Models for Portuguese Open Information Extraction A Comparative Study of Fine-Tuning and LoRA.pdf j√° traduzido, pulando..\n",
      "artigos_traduzidos/Tuning Hypothesis Creation Combining Discrete and Continuous Spaces for Zero-Shot Hate Speech Detection_traduzido.txt\n",
      "PDF: ./articles/Tuning Hypothesis Creation Combining Discrete and Continuous Spaces for Zero-Shot Hate Speech Detection.pdf j√° traduzido, pulando..\n",
      "artigos_traduzidos/Unsupervised Statistical Keyword Extraction Pipeline Is LLM All You Need_traduzido.txt\n",
      "PDF: ./articles/Unsupervised Statistical Keyword Extraction Pipeline Is LLM All You Need.pdf j√° traduzido, pulando..\n",
      "artigos_traduzidos/Using Complex Networks to Improve Legal Text Hierarchical Classification_traduzido.txt\n",
      "üîÑ24 Dividido em 16 partes para tradu√ß√£o\n",
      "üåç Traduzindo parte 1/16...\n",
      "Usando Redes Complexas para Melhorar a Classifica√ß√£o Hier√°rquica de Textos Legais\n",
      "\n",
      "Rilder S. Pires1,2, Raquel Silveira3, Carlos G. O. Fernandes2,4, Jo√£o A. Monteiro Neto5 e Vasco Furtado1,2,6\n",
      "\n",
      "1 Laborat√≥rio de Ci√™ncia de Dados e Intelig√™ncia Artificial, Universidade de Fortaleza, Fortaleza, Cear√°, Brasil\n",
      "2 Programa de P√≥s Gradua√ß√£o em Inform√°tica Aplicada, Universidade de Fortaleza, Fortaleza, Cear√°, Brasil\n",
      "3 Instituto Federal de Educa√ß√£o, Ci√™ncia e Tecnologia do Cear√°, Tiangu√°, Cear√°, Brasil\n",
      "4 BNB - Banco do Nordeste do Brasil S.A., Fortaleza, Cear√°, Brasil\n",
      "5 Centro de Ci√™ncias Jur√≠dicas, Universidade de Fortaleza, Fortaleza, Cear√°, Brasil\n",
      "6 ETICE - Empresa de Tecnologia da Informa√ß√£o do Cear√°, Fortaleza, Cear√°, Brasil\n",
      "\n",
      "Resumo. Temas legais s√£o tipicamente organizados em √°rvores de r√≥tulos, onde cada ramifica√ß√£o, desde a raiz (t√≥picos gerais) at√© a folha (t√≥picos espec√≠ficos), categoriza a vocabul√°ria que descreve processos judiciais. Neste artigo, descrevemos uma abordagem, inovadora no Sistema de Justi√ßa Brasileiro, de classifica√ß√£o hier√°rquica autom√°tica de um t√≥pico de peti√ß√£o. A abordagem integra m√©todos baseados em transformers e redes complexas para capturar, al√©m das caracter√≠sticas do texto, a rela√ß√£o entre as cita√ß√µes legais presentes nas peti√ß√µes e o t√≥pico ao qual a peti√ß√£o se refere. A valida√ß√£o desta abordagem √© feita atrav√©s de um benchmark que mostra ganhos de precis√£o, bem como um cen√°rio pr√°tico com a implementa√ß√£o de um microservi√ßo em uma Plataforma Nacional de Justi√ßa cuja implementa√ß√£o de front-end j√° est√° sendo utilizada por um Tribunal Estadual para sugerir automaticamente a classifica√ß√£o do t√≥pico de peti√ß√£o no Sistema Procedimental Nacional.\n",
      "\n",
      "Palavras-chave: Classifica√ß√£o de Texto ¬∑ Sistema Legislativo Brasileiro ¬∑ Redes Complexas.\n",
      "‚úÖ Parte traduzida.\n",
      "üåç Traduzindo parte 2/16...\n",
      "T√≥picos legais s√£o tipicamente organizados em √°rvores hier√°rquicas, onde cada ramifica√ß√£o, desde a raiz (por exemplo, direito do consumidor) at√© a folha (por exemplo, danos morais ou materiais), categoriza a vocabul√°ria que descreve processos judiciais. A classifica√ß√£o de t√≥picos ocorre geralmente nos est√°gios iniciais do processo judicial quando uma peti√ß√£o √© apresentada ao tribunal. Nesse ponto, o autor da peti√ß√£o √© obrigado a indicar o assunto relevante da demanda. No contexto brasileiro, o autor da peti√ß√£o deve escolher o t√≥pico de uma hierarquia que abrange mais de 4.000 assuntos, que fazem parte do Sistema de Tabelas Procedimentais Unificadas (TPU) mantido pelo Conselho Nacional de Justi√ßa (CNJ) [9]. Fazer a associa√ß√£o correta dentro dessa hierarquia n√£o √© uma tarefa trivial e √© frequentemente feita incorretamente pelo autor da peti√ß√£o. Essa desclassifica√ß√£o gera atrasos no processo judicial, levando a impactos negativos tanto financeiramente, devido ao rework, quanto socialmente, ao fomentar um sentimento de impunidade. A literatura cient√≠fica apresenta v√°rias metodologias para a classifica√ß√£o autom√°tica de documentos judiciais [21, 29, 4, 14, 2, 1]. O advento da classifica√ß√£o de texto via aprendizado profundo, particularmente com modelos de transformador, avan√ßou significativamente o campo de classifica√ß√£o de texto [10, 17, 28, 31]. No entanto, a estrutura hier√°rquica intrincada e extensa de t√≥picos, juntamente com a natureza especializada de textos legais, apresenta desafios significativos para os m√©todos tradicionais. Ao examinar mais de perto nosso problema, vemos que √© um problema de classifica√ß√£o de texto hier√°rquica, onde geralmente buscamos categorizar um texto em um conjunto de r√≥tulos organizados em uma estrutura de classe hier√°rquica. O grande desafio com esse tipo de tarefa √© modelar adequadamente a hierarquia de r√≥tulos, que √© usualmente grande, desbalanceada e altamente estruturada [34]. Esses desafios nos motivaram a desenvolver uma abordagem inovadora.\n",
      "‚úÖ Parte traduzida.\n",
      "üåç Traduzindo parte 3/16...\n",
      "Nosso abordagem pressup√µe que as numerosas cita√ß√µes legais presentes nas peti√ß√µes s√£o fundamentais para compreender o conte√∫do do documento e definir seu assunto relevante. Essas cita√ß√µes legais n√£o apenas ajudam a formalizar os argumentos apresentados por ambos os peticion√°rios e os tomadores de decis√£o, mas tamb√©m servem como um ponte conectando a peti√ß√£o √†s disposi√ß√µes legais aplic√°veis, como leis, decretos, precedentes e artigos. Ao examinar as cita√ß√µes dentro de cada peti√ß√£o, podemos construir uma rede que ligue as disposi√ß√µes legais aos t√≥picos da peti√ß√£o. Essa rede oferece informa√ß√µes suplementares para melhorar o processo de classifica√ß√£o autom√°tica, o que resulta em uma melhoria significativa na precis√£o. Usando essa abordagem baseada em rede, desenvolvemos um classificador com base no BERT que aproveita n√£o apenas o texto da peti√ß√£o, mas tamb√©m informa√ß√µes de vetor geradas pelas conex√µes de rede entre t√≥picos e disposi√ß√µes legais. Validei nossa metodologia com um conjunto de dados composto por 300.000 peti√ß√µes de v√°rios tribunais brasileiros, mantido pelo sistema Codex do CNJ. Os resultados demonstram a validade da nossa abordagem, mostrando ganhos significativos na precis√£o em alguns casos, quando comparados a um m√©todo de classifica√ß√£o hier√°rquica que n√£o utiliza informa√ß√µes de rede. Al√©m disso, mostramos um exemplo de aplica√ß√£o da abordagem proposta em uma vers√£o de um modelo de classifica√ß√£o hier√°rquica dispon√≠vel na plataforma SINAPSE do Conselho e atualmente utilizada por um Tribunal Estadual para sugerir automaticamente classifica√ß√µes de t√≥picos para peti√ß√µes inscritas no Sistema Nacional de Processo.\n",
      "\n",
      "2 Trabalhos Relacionados O modelo de redes complexas baseado nas caracter√≠sticas de um processo judicial tem seu potencial comprovado em v√°rias obras, como descrito em [27, 11, 5, 13, 25, 24]. A classifica√ß√£o de documentos legais tem sido utilizada no contexto forense e de aplica√ß√£o da lei (por exemplo,\n",
      "‚úÖ Parte traduzida.\n",
      "üåç Traduzindo parte 4/16...\n",
      "Identificando potenciais criminosos [32], predizendo crimes [22, 23] ou descobrindo comportamento antisocial [7]). Mariana et al. [21] investigaram, no contexto brasileiro, diferentes m√©todos de classifica√ß√£o e representa√ß√£o de dados para concluir que a aprendizagem profunda (mais especificamente) com Word2Vec treinada em um corpus espec√≠fico do dom√≠nio, s√£o m√©todos promissores, mas ainda limitados, para classificar muitas classes. Luz de Araujo et al. [4] apresentaram um novo conjunto de dados constru√≠do a partir de documentos legais do Supremo Tribunal Federal do Brasil, contendo dados de texto rotulados para dois tipos de tarefas: classifica√ß√£o do tipo de documento e atribui√ß√£o de temas. Os autores exploraram e compararam diferentes m√©todos de classifica√ß√£o, como modelos de bag-of-words, CNN, RNN, algoritmos de boosting e campos aleat√≥rios condicionais em cadeia linear. A CNN com embedding de palavras tamb√©m provou ser mais performante. Silva et al. [30] propuseram um modelo estruturado em CNN para classificar tipos de documentos recebidos pelo Supremo Tribunal Federal do Brasil. Aguiar et al. [1] investigaram a aplica√ß√£o do modelo de t√≥picos para identificar o assunto de documentos legais e avaliaram a aplicabilidade em classificar processos legais brasileiros. O modelo de classifica√ß√£o foi treinado em documentos do Tribunal de Justi√ßa do Cear√°, no Brasil, e os casos foram classificados nas cinco classes mais representativas do Conselho Nacional de Justi√ßa (CNJ) do Brasil. Recentemente, modelos pr√©-treinados com base em BERT mostraram ser mais performantes para classificar t√≥picos. Importante, a efic√°cia do BERT √© principalmente devido √† capacidade de transfer√™ncia de aprendizado que aproveita conhecimento sem√¢ntico e sint√°tico de pr√©-treinamento em um grande corpus n√£o rotulado [10]. Aguiar et al. [2] investigaram diferentes m√©todos de classifica√ß√£o de texto e diferentes combina√ß√µes de embeddings, extra√≠dos de modelos de linguagem portuguesa, e informa√ß√µes sobre legisla√ß√£o citada nos documentos iniciais para a tarefa de classifica√ß√£o de processos.\n",
      "‚úÖ Parte traduzida.\n",
      "üåç Traduzindo parte 5/16...\n",
      "Os modelos foram treinados com uma Cole√ß√£o Ouro da Justi√ßa do Estado do Cear√°, no Brasil, cujos processos foram classificados nas cinco classes mais representativas do CNJ. O melhor resultado foi obtido pelo modelo BERT. Shaheen et al. [29] estudaram o desempenho de v√°rios modelos baseados em transformadores (nomeadamente BERT [10], RoBERTa [17], DistilBERT [28] e XLNet [36]) em combina√ß√£o com estrat√©gias como treinamento pr√©-generativo, desbloqueio gradual e taxas de aprendizado discriminantes para alcan√ßar desempenho de ranking competitivo. Chalkidis et al. [6] desenvolveram um conjunto de dados de previs√£o de senten√ßa jur√≠dica em ingl√™s, contendo casos da Corte Europeia dos Direitos Humanos. Uma variedade ampla de modelos neurais √© avaliada nesse conjunto de dados, estabelecendo fortes bases que superam modelos baseados em caracter√≠sticas anteriores. Wang et al. [34] apresentaram o m√©todo de Ajuste de Prompt Hier√°rquico (HPT), destinado a abordar a classifica√ß√£o de texto hier√°rquica do ponto de vista de um modelo de linguagem mascarado com m√∫ltiplos r√≥tulos. O m√©todo envolve criar um template virtual din√¢mico e usar palavras de r√≥tulo que atuam como prompts suaves, integrando conhecimento da hierarquia de r√≥tulos. Al√©m disso, uma perda de cruz-entropia multi-r√≥tulo sem limites √© introduzida para alinhar os processos de classifica√ß√£o de texto hier√°rquica com modelos de linguagem mascarada. Os autores conduziram experimentos que demonstraram que o HPT alcan√ßa um bom desempenho em v√°rios conjuntos de dados de classifica√ß√£o de texto hier√°rquica populares.\n",
      "\n",
      "A Abordagem Proposta\n",
      "\n",
      "Na abordagem proposta, supomos que a fonte prim√°ria de dados √© um conjunto de peti√ß√µes textuais P que comp√µem a pe√ßa inicial do caso judicial. Cada peti√ß√£o inicial est√° associada a um tema jur√≠dico que o caso aborda. No texto dessas peti√ß√µes, h√° refer√™ncias a provis√µes jur√≠dicas que apoiam os argumentos apresentados pelo requerente.\n",
      "‚úÖ Parte traduzida.\n",
      "üåç Traduzindo parte 6/16...\n",
      "A hip√≥tese √© que a rela√ß√£o entre um tema jur√≠dico e um ou mais dispositivos legais √© relevante para classificar automaticamente a mat√©ria de uma peti√ß√£o. A figura 1 mostra o pipeline do m√©todo proposto, que depende dos textos das peti√ß√µes e das cita√ß√µes √† legisla√ß√£o feitas nelas. Conhecimento adicional sobre a estrutura hier√°rquica dos temas e dispositivos legais √© utilizado. Essa informa√ß√£o adicional e as cita√ß√µes dos dispositivos legais no texto formam uma rede complexa de temas e dispositivos legais que modelaremos aqui por meio de um grafo ponderado. Em seguida, a embedagem dos v√©rtices nesse grafo permite gerar uma representa√ß√£o vetorial das peti√ß√µes. As se√ß√µes subsequentes fornecer√£o a formaliza√ß√£o desses conceitos.\n",
      "\n",
      "3.1 Grafo Bipartido de Dispositivos Legais e Temas\n",
      "\n",
      "Dado um conjunto de peti√ß√µes P, definimos GB como o grafo que representa a rela√ß√£o de co-ocorr√™ncia entre os temas jur√≠dicos das peti√ß√µes de P e os dispositivos legais citados nelas. Aqui, definimos GB = (A, D, EB, wB), onde:\n",
      "\n",
      "‚Äì A = {a1, a2, ..., an}, n ‚àà N, √© um conjunto finito de v√©rtices relacionados a temas jur√≠dicos.\n",
      "‚Äì D = {d1, d2, ..., dm}, m ‚àà N, √© um conjunto finito de v√©rtices relacionados aos dispositivos legais.\n",
      "‚Äì EB ‚äÇ A √ó D √© um conjunto finito de arestas conectando subconjuntos de v√©rtices de A e D.\n",
      "‚Äì wB : EB ‚Üí R √© uma fun√ß√£o de peso de aresta definida nas arestas de GB.\n",
      "‚úÖ Parte traduzida.\n",
      "üåç Traduzindo parte 7/16...\n",
      "Nesse gr√°fico, h√° uma aresta entre os v√©rtices ai e dj se h√°, pelo menos, um pedido em P cujo tema jur√≠dico corresponde a ai e que faz, pelo menos, uma refer√™ncia √† disposi√ß√£o jur√≠dica dj. Geralmente, supomos que o peso wBi,j dessa aresta seja uma fun√ß√£o do n√∫mero de vezes qi,j que a disposi√ß√£o jur√≠dica dj √© referenciada pelos pedidos do tema ai em P. O gr√°fico GB apresenta semelhan√ßas com outros gr√°ficos j√° estudados na literatura, como o gr√°fico de cita√ß√µes bibliogr√°ficas [19]. L√°, os v√©rtices representam documentos que fazem refer√™ncias a outros documentos. Uma caracter√≠stica importante desse tipo de gr√°fico √© a exist√™ncia de documentos com um alto n√∫mero de cita√ß√µes [19]. Esses v√©rtices com muitas liga√ß√µes acabam tornando dif√≠cil identificar os padr√µes de agrupamento existentes no gr√°fico [3]. Da mesma forma que ocorre em gr√°ficos bipartidos de usu√°rios e objetos, definimos uma fun√ß√£o de peso que utiliza uma estrat√©gia baseada em uma t√©cnica popular na recupera√ß√£o de informa√ß√µes [3] chamada tfidf, wBi,j ‚â°wB(ai, dj) = f(ai, dj) √ó log \u0012 n deg(dj) \u0013 (1) onde f(ai, dj) √© semelhante a ‚Äútf‚Äù e representa a frequ√™ncia com que a disposi√ß√£o jur√≠dica dj √© citada em pedidos de um certo tema ai, f(ai, dj) = qi,j P‚ü®ai‚ü© k qi,k , e ‚ü®¬∑‚ü© significa que a soma em k √© feita no bairro de ai. O termo log (n/deg(dj)) da Eq. (1) √© semelhante a ‚Äúidf‚Äù, medindo quanto a disposi√ß√£o jur√≠dica √© rara ou comum entre todos os temas jur√≠dicos.\n",
      "\n",
      "3.2 Florestas de Temas Jur√≠dicos e Disposi√ß√µes Jur√≠dicas\n",
      "\n",
      "Os temas jur√≠dicos t√™m rela√ß√µes hier√°rquicas taxon√¥micas e s√£o pr√©-definidos no sistema de Tabelas Procedimentais Unificadas [9]. O gr√°fico GA = (A, EA) representa a taxonomia de temas jur√≠dicos, onde:\n",
      "\n",
      "‚Äì A = {a1, a2, ..., an}, n ‚àà N, √© um conjunto finito de v√©rtices relacionados a temas jur√≠dicos.\n",
      "‚Äì EA ‚äÇ A √ó A √© um conjunto finito de arestas direcionadas que conectam os v√©rtices do GA.\n",
      "‚úÖ Parte traduzida.\n",
      "üåç Traduzindo parte 8/16...\n",
      "A assimetria intr√≠nseca das rela√ß√µes entre os v√©rtices da GA faz com que ela caia na classe de florestas direcionadas raizadas. Esses grafos t√™m propriedades importantes do ponto de vista topol√≥gico. Nessas grafos, podemos definir dois tipos de v√©rtices especiais, os v√©rtices raiz e os v√©rtices folha. Considerando que as conex√µes entre dois v√©rtices sempre ocorrem desde o assunto jur√≠dico mais geral para o assunto mais espec√≠fico, um v√©rtice raiz √© definido como um v√©rtice que apenas tem conex√µes \"saindo\" dele. Complementarmente, um v√©rtice folha pode ser definido como um v√©rtice que apenas tem links \"entrando\" nele. Do ponto de vista de t√≥picos jur√≠dicos, podemos interpretar os v√©rtices folha como os t√≥picos mais espec√≠ficos existentes na GA e os v√©rtices raiz como os mais gen√©ricos na GA. Al√©m disso, a estrutura topol√≥gica das √°rvores direcionadas raizadas permite que definamos, para cada v√©rtice folha ai, um v√©rtice raiz √∫nico correspondente root(ai), ou seja, para cada assunto espec√≠fico, um assunto jur√≠dico √∫nico correspondente. Da mesma forma que ocorre com os t√≥picos, as disposi√ß√µes jur√≠dicas t√™m rela√ß√µes hier√°rquicas que permitem que definamos um grafo GD = (D, ED), onde ‚Äì D = {d1, d2, ..., dn}, m ‚àà N, √© um conjunto finito de v√©rtices que descrevem disposi√ß√µes jur√≠dicas. ‚Äì ED ‚äÇ D √ó D √© um conjunto finito de arestas direcionadas que conectam os v√©rtices de GD representando a rela√ß√£o \"parte de\" entre as pe√ßas que comp√µem uma lei. Embora semanticamente diferente da taxonomia descrita anteriormente, a assimetria das rela√ß√µes entre os v√©rtices de GD tamb√©m a classifica como uma floresta direcionada raizada. As disposi√ß√µes jur√≠dicas est√£o organizadas hierarquicamente como uma partonomia, onde os v√©rtices do tipo raiz representam disposi√ß√µes jur√≠dicas completas, como Leis, Decretos e Precedentes, compostas de partes como se√ß√µes, artigos, par√°grafos e itens. Para cada v√©rtice folha di, h√° tamb√©m um v√©rtice raiz √∫nico correspondente root(di).\n",
      "‚úÖ Parte traduzida.\n",
      "üåç Traduzindo parte 9/16...\n",
      "3 Gr√°fico Pesoado de T√≥picos e Provid√™ncias Legais Dado um conjunto de peti√ß√µes iniciais P, podemos definir um gr√°fico bipartido de t√≥picos e provid√™ncias legais GB = (A, D, EB, w) como mostrado na Sec. 3.1. Al√©m disso, o conhecimento de fundo sobre t√≥picos legais permite construir uma floresta de t√≥picos legais GA = (A, EA) como mostrado na Sec. 3.2. Assim, podemos definir um novo gr√°fico bipartido G‚Ä≤ B = (Aleaf, D, E‚Ä≤ B, w‚Ä≤ B) como subgr√°fico de GB, onde: ‚Äì Aleaf √© o conjunto de v√©rtices que s√£o do tipo folha em GA representando t√≥picos espec√≠ficos. ‚Äì D √© o conjunto de v√©rtices de GB representando as provid√™ncias legais. ‚Äì E‚Ä≤ B √© o conjunto de arestas de GB onde wi,j ‚â• œÑ. ‚Äì w‚Ä≤ B : E‚Ä≤ ‚ÜíR √© uma fun√ß√£o de peso de aresta definida em E‚Ä≤ como w‚Ä≤ Bi,j = wBi,j. Aqui, œÑ corresponde a um limiar de tfidf abaixo do qual consideramos que uma aresta n√£o justifica ser criada em G‚Ä≤ B. √â importante notar que, ao contr√°rio do que ocorre em GB, em G‚Ä≤ B h√° apenas v√©rtices relacionados a t√≥picos legais do tipo folha. Agora, podemos definir o gr√°fico pesoado de t√≥picos e provid√™ncias legais G = (V, E, w), pela jun√ß√£o de G‚Ä≤ B e as vers√µes n√£o direcionadas das florestas G‚Ä≤ A = (A, E‚Ä≤ A) e G‚Ä≤ D = (D, E‚Ä≤ D), onde: ‚Äì V = A ‚à™D = {v1, v2, ..., vn+m} √© o conjunto de v√©rtices de G‚Ä≤, definido como a uni√£o dos v√©rtices relacionados a t√≥picos e provid√™ncias legais. ‚Äì E = E‚Ä≤ B ‚à™E‚Ä≤ A ‚à™E‚Ä≤ D √© o conjunto de arestas conectando os v√©rtices em V. ‚Äì w : E ‚ÜíR √© uma fun√ß√£o de peso de aresta definida em E como: wi,j = {w‚Ä≤ B(vi, vj) se a aresta (vi, vj) ‚ààE‚Ä≤ B œÑ caso contr√°rio Em ordem para que a condi√ß√£o (vi, vj) ‚ààE‚Ä≤ B seja satisfeita, √© necess√°rio que as condi√ß√µes vi ‚ààA e vj ‚ààD tamb√©m sejam satisfeitas, pois G‚Ä≤ B √© um gr√°fico bipartido. Como definido anteriormente, o gr√°fico G √© um gr√°fico simples pesoado. Isso permite gerar representa√ß√µes vetoriais para os v√©rtices desse gr√°fico, como veremos na pr√≥xima subse√ß√£o.\n",
      "‚úÖ Parte traduzida.\n",
      "üåç Traduzindo parte 10/16...\n",
      "4 Gera√ß√£o de Embeddings Nesta se√ß√£o, descrevemos o processo de gera√ß√£o da representa√ß√£o vetorial de cita√ß√µes legais a partir de um grafo ponderado de t√≥picos e disposi√ß√µes legais e as embeddings de peti√ß√µes que, por sua vez, utilizam essas representa√ß√µes. Gera√ß√£o de embeddings de v√©rtices de G. Nesse passo, utilizamos o grafo apresentado na se√ß√£o anterior para gerar as embeddings de seus v√©rtices. Para isso, definimos a fun√ß√£o de mapeamento g[G] : V ‚Üí Rd, que associa a cada v√©rtice vi ‚àà V um vetor vi de d dimens√µes. A intui√ß√£o desse abordagem √© que, nesse espa√ßo, o vetor vi estar√° pr√≥ximo dos v√©rtices que pertencem ao vizinhan√ßa de vi. Em seguida, t√≥picos legais ser√£o \"colocados\" pr√≥ximos √†s disposi√ß√µes legais que ocorrem simultaneamente em peti√ß√µes e/ou ao lado de t√≥picos mais gerais na hierarquia de t√≥picos. As embeddings de cita√ß√µes mencionadas anteriormente podem ser vistas como uma forma alternativa, al√©m do texto natural de linguagem, de representar os argumentos utilizados pelo requerente. Nesse sentido, disposi√ß√µes legais s√£o citadas para representar e apoiar o objeto de uma peti√ß√£o e s√£o relevantes para determinar o t√≥pico legal √† qual a peti√ß√£o se refere. Para gerar a embedding para G, utilizamos o algoritmo node2vec+ implementado na biblioteca pecanpy [16], que foi escolhida por sua capacidade de capturar comunidades conformadas [15]. Gera√ß√£o de embeddings de uma peti√ß√£o. A partir da representa√ß√£o vetorial de cada cita√ß√£o legal feita em uma peti√ß√£o dada, a embedding da peti√ß√£o pode ser calculada. A representa√ß√£o pj para uma peti√ß√£o a partir das disposi√ß√µes legais que cita √© definida como pj = P‚Ñ¶j k vk L(‚Ñ¶j) , onde a soma √© realizada sobre o conjunto ‚Ñ¶j de todas as representa√ß√µes correspondentes √†s disposi√ß√µes legais mencionadas na peti√ß√£o do processo j e L(‚Ñ¶j) √© o n√∫mero total de elementos em ‚Ñ¶j.\n",
      "‚úÖ Parte traduzida.\n",
      "üåç Traduzindo parte 11/16...\n",
      "O texto da peti√ß√£o inicial passa por uma fase de padroniza√ß√£o textual com o objetivo de padronizar termos legais (por exemplo, art. 1 da Lei n¬∫ 11.419, de 19 de dezembro de 2006, at√© art. 1 da Lei 11.419/2006), removendo espa√ßos excessivos, linhas repetidas e caracteres especiais e estendendo abreviaturas de ag√™ncias e estados da federa√ß√£o. Em seguida, as disposi√ß√µes legais citadas na peti√ß√£o s√£o identificadas usando express√µes regulares e, em seguida, procedemos como descrito na se√ß√£o anterior para gerar a peti√ß√£o de embedding. A classifica√ß√£o autom√°tica √© feita com base em uma arquitetura de Prompt Tuning hier√°rquica [34]. Em n√≠vel alto, o texto padronizado da aplica√ß√£o √© enviado para o m√≥dulo BERT, cuja arquitetura √© estruturada em um encoder de codificador bidirecional em camadas m√∫ltiplas [10]. O texto de entrada √© codificado em uma sequ√™ncia de tokens gerada usando embeddings de WordPiece [35]. As caracter√≠sticas textuais s√£o ent√£o passadas para uma pilha de camadas de encoder, ap√≥s a augmenta√ß√£o com codifica√ß√£o de posi√ß√£o. Embeddings de posi√ß√£o s√£o adicionados a cada camada do encoder do transformador para ajudar o transformador a aprender depend√™ncias entre tokens. Ap√≥s a aplica√ß√£o das camadas de codifica√ß√£o do transformador, o m√≥dulo BERT resulta em uma camada de pooling linear. O m√≥dulo de combina√ß√£o recebe como entrada as recursos de texto emitidas do modelo de transformador BERT e as recursos num√©ricas vindas da \"representa√ß√£o vetorial de cita√ß√µes legais\". Dali, o m√≥dulo gera uma representa√ß√£o multimodal combinada. Utilizamos o m√≥dulo de combina√ß√£o proposto por [34], que recebe como entrada as caracter√≠sticas textuais geradas a partir de um modelo de transformador e caracter√≠sticas num√©ricas e gera uma representa√ß√£o combinada, atrav√©s de m√©todos que combinam as representa√ß√µes em seus respectivos espa√ßos de caracter√≠sticas. Para incorporar a hierarquia de r√≥tulos, propomos uma camada de prompt hier√°rquica (conforme [34]).\n",
      "‚úÖ Parte traduzida.\n",
      "üåç Traduzindo parte 12/16...\n",
      "Desde que a hierarquia de r√≥tulos √© uma √°rvore, constru√≠mos templates com base na profundidade da hierarquia de r√≥tulos. A restri√ß√£o de hierarquia apenas introduz a profundidade dos r√≥tulos, mas falta sua conectividade. Para fazer pleno uso da hierarquia de r√≥tulos de forma MLM, injetamos adicionalmente o conhecimento da hierarquia de r√≥tulos por camada no embedding de template. Uma rede de aten√ß√£o gr√°fica empilhada de K camadas (GAT) [12] √© adotada para modelar a hierarquia de r√≥tulos. Como a classifica√ß√£o de texto hier√°rquica √© um problema de classifica√ß√£o multi-r√≥tulo, em vez de calcular a pontua√ß√£o de cada r√≥tulo separadamente, esperamos que as pontua√ß√µes de todos os r√≥tulos alvo sejam maiores do que as de todos os r√≥tulos n√£o-alvo. Utilizamos uma perda de entropia multi-r√≥tulo (MLCE) [33], introduzindo um r√≥tulo √¢ncora com uma pontua√ß√£o constante de 0 na MLCE e esperando que as pontua√ß√µes dos r√≥tulos alvo e n√£o-alvo sejam todas maiores e menores do que 0, respectivamente. Assim, formamos uma perda de entropia multi-r√≥tulo com zero como limite (ZMLCE). Para ser consistente com a restri√ß√£o de hierarquia, adotamos a ZMLCE em cada camada de hierarquia de r√≥tulos para a previs√£o por camada. Fig. 2. Arquitetura do nosso modelo. A arquitetura √© dividida em duas etapas: (i) pr√©-processamento de dados: o texto da peti√ß√£o inicial √© pr√©-processado para padronizar termos legais e identificar os artigos e leis citados no texto, e (ii) classifica√ß√£o: combina os dados de entrada (texto e rede bipartida de t√≥picos de cita√ß√£o) e utiliza a arquitetura do Prompt Tuning Hier√°rquico (HPT) [32] durante o treinamento. O HPT transforma a classifica√ß√£o de texto hier√°rquica (HTC) em um problema de modelo de linguagem mascarada multi-r√≥tulo hier√°rquico (MLM) com conhecimento de hierarquia de r√≥tulos, incorporando o conhecimento da hierarquia de r√≥tulos. O HPT transforma a HTC em um problema de MLM multi-r√≥tulo com perda de entropia multi-r√≥tulo com zero como limite.\n",
      "‚úÖ Parte traduzida.\n",
      "üåç Traduzindo parte 13/16...\n",
      "4 O Classificador em Uso A avalia√ß√£o do desempenho do modelo foi feita a partir de sua aplica√ß√£o em dados reais de 300.000 peti√ß√µes de processos legais oriundas de Tribunais do Trabalho, Tribunais Regionais Federais e Tribunais de Justi√ßa dos estados brasileiros.\n",
      "\n",
      "10 Rilder S. Pires et al.\n",
      "\n",
      "4.1 Conjunto de Dados de Peti√ß√µes Como j√° foi mencionado na se√ß√£o 3.2, os temas legais s√£o categorizados de acordo com uma tabela espec√≠fica de temas chamada Tabela Procedimental Unificada TPU [9] desenvolvida pelo Conselho Nacional de Justi√ßa CNJ. A hierarquia presente nestas tabelas permite que agreguemos temas espec√≠ficos em temas gen√©ricos. Utilizamos essa estrat√©gia para separar nosso conjunto de dados em grupos de temas muito distintos, o que nos permitiu testar nossa abordagem em diferentes n√≠veis de complexidade. Na tabela 1, mostramos a distribui√ß√£o percentual de peti√ß√µes iniciais para cada tema gen√©rico no conjunto de dados de 300.000 peti√ß√µes.\n",
      "\n",
      "Tema Gen√©rico Lei Processual (%) 14 - Direito Tribut√°rio 4,4 195 - Direito Previdenci√°rio 4,7 287 - Direito Penal 5,7 864 - Direito do Trabalho 11,1 899 - Direito Civil 29,0 1156 - Direitos do Consumidor 25,2 1209 - Direito Processual Penal 0,4 8826 - Direito Processual Civil e do Trabalho 13,0 9985 - Direito Administrativo e outros assuntos de Direito P√∫blico 6,3\n",
      "\n",
      "Tabela 1. Distribui√ß√£o percentual de processos por temas legais. Os c√≥digos utilizados nesta tabela s√£o definidos pela TPU e s√£o os mesmos que ser√£o utilizados na se√ß√£o de resultados. O conjunto de 300.000 peti√ß√µes foi ent√£o dividido seguindo uma raz√£o de 80% para treinamento e 20% para teste. Fizemos quest√£o de que o conjunto de dados apenas contenha peti√ß√µes com pelo menos 50 palavras e que mais de 80% das palavras v√°lidas fossem v√°lidas7.\n",
      "\n",
      "4.2 Processo de Treinamento A gr√°fica G foi criada a partir das disposi√ß√µes legais identificadas no conjunto de peti√ß√µes P dos dados de treinamento. Em seguida, a representa√ß√£o vetorial das cita√ß√µes de peti√ß√µes foi gerada, como descrito na Sec. 3.4. O valor œÑ ‚âà 8,48 ¬∑ 10‚àí3 foi ajustado empiricamente identificando o valor que melhor separava os temas da GB.\n",
      "‚úÖ Parte traduzida.\n",
      "üåç Traduzindo parte 14/16...\n",
      "Foi feito isso ao analisar o coeficiente de assortatividade [20] da proje√ß√£o de um modo [19] relativamente √† parti√ß√£o de t√≥picos jur√≠dicos. Foi feita uma fine-tuning do modelo pr√©-treinado BERTimbau [31], onde todos os par√¢metros foram ajustados usando os t√≥picos espec√≠ficos das peti√ß√µes utilizadas no treinamento. No m√≥dulo mesun_etal_2020rge, utilizamos o m√©todo de soma gatada de merge na sa√≠da do transformador para o texto da peti√ß√£o e o vetor 7. A verifica√ß√£o de palavras v√°lidas foi realizada usando os l√©xicos propostos por [18]. A representa√ß√£o de cita√ß√£o foi feita usando Complex Networks antes da camada de classifica√ß√£o final [8]. O modelo foi treinado com tamanho de batch de 16 exemplos, 30 √©pocas m√°ximas e parada precoce de 5 √©pocas. O otimizador Adam foi escolhido com taxa de aprendizado de 10‚àí5 e 5-fold cross-validation. Foi aplicada amostragem aleat√≥ria para igualar o n√∫mero de exemplos de cada classe.\n",
      "\n",
      "4.3 Avalia√ß√£o Comparativa e Implementa√ß√£o\n",
      "\n",
      "Para uma avalia√ß√£o detalhada da nossa abordagem, comparamos nosso modelo (descrito na Sec. 3.5) com o m√©todo de classifica√ß√£o hier√°rquica original [34] (que utiliza apenas o texto como entrada). Os resultados para cada t√≥pico espec√≠fico foram calculados em termos de Precis√£o, Recall e F1-score, obtidos das etiquetas reais e preditas no conjunto de dados de teste. Na Tab. 2, mostramos os resultados dos classificadores para os diferentes t√≥picos gen√©ricos apresentados na se√ß√£o anterior.\n",
      "\n",
      "Tabela 2. Resultados de precis√£o, recall e F1-score para diferentes t√≥picos gen√©ricos.\n",
      "‚úÖ Parte traduzida.\n",
      "üåç Traduzindo parte 15/16...\n",
      "Aqui, N √© o n√∫mero de t√≥picos espec√≠ficos presentes em cada t√≥pico gen√©rico. Os m√©tricos mostram a compara√ß√£o entre o classificador que utiliza apenas o texto das peti√ß√µes e o que utiliza o texto e a representa√ß√£o vetorial definida pela nossa abordagem. Os resultados apresentados nesta tabela mostram que o classificador que utiliza informa√ß√µes das cita√ß√µes apresenta melhor desempenho em algumas situa√ß√µes. Precisamente, apresenta melhor desempenho nos t√≥picos gen√©ricos ‚Äú864 - Direito do Trabalho‚Äù, ‚Äú899 - Direito Civil‚Äù e ‚Äú1209 - Direito Processual Penal‚Äù. Acreditamos que, nestes casos, nossa abordagem √© capaz de capturar melhor as rela√ß√µes que existem entre as disposi√ß√µes legais e os t√≥picos espec√≠ficos devido √† exist√™ncia de disposi√ß√µes legais que detalham v√°rias situa√ß√µes espec√≠ficas nestas ramifica√ß√µes do Direito. Um exemplo de aplica√ß√£o onde essa abordagem √© muito √∫til ocorre quando um petidor apenas informa um t√≥pico gen√©rico ao submeter a peti√ß√£o. Nesse caso, um meta-modelo seria capaz de identificar qual abordagem √© mais apropriada para classificar o assunto espec√≠fico daquela peti√ß√£o com base no t√≥pico gen√©rico informado. De fato, incorporamos uma vers√£o de um modelo de classifica√ß√£o hier√°rquica na plataforma SINAPSES do CNJ [8] na forma de um micro-servi√ßo. Essa plataforma visa compartilhar, entre institui√ß√µes judiciais brasileiras, modelos de intelig√™ncia artificial desenvolvidos pelo setor p√∫blico e privado. Na Figura 3, mostramos a interface do sistema de registro do processo judicial, PJe, ap√≥s a implementa√ß√£o da funcionalidade de previs√£o de t√≥pico folha com a chamada do micro-servi√ßo de classifica√ß√£o implementado na plataforma SINAPSES. Fig. 3. Captura de tela do sistema PJe com a caracter√≠stica de prever o t√≥pico de uma peti√ß√£o. A captura de tela √© numerada para mostrar: 1) √© o t√≥pico principal informado pelo usu√°rio, 2) √© o t√≥pico espec√≠fico predito e 3) √© o texto da peti√ß√£o.\n",
      "‚úÖ Parte traduzida.\n",
      "üåç Traduzindo parte 16/16...\n",
      "5 Conclus√µes\n",
      "\n",
      "A cita√ß√£o a disposi√ß√µes legais existentes em processos √© uma particularidade importante desse tipo de documento. Elas adicionam informa√ß√µes adicionais ao texto e podem ser utilizadas por m√©todos de processamento de linguagem natural autom√°tica para uma variedade de tarefas. Neste artigo, descrevemos como a classifica√ß√£o autom√°tica de t√≥picos de uma peti√ß√£o pode ser aprimorada com base nessas cita√ß√µes. O abordagem integra m√©todos baseados em transformadores com uma rede complexa para capturar, al√©m de caracter√≠sticas de texto, a rela√ß√£o entre cita√ß√µes legais presentes nas peti√ß√µes e o t√≥pico a que a peti√ß√£o se refere. Este trabalho de pesquisa caracteriza-se pela proposta de um m√©todo inovador baseado na combina√ß√£o de Aprendizado Profundo e Redes Complexas, e na aplica√ß√£o dessas ideias no mundo real. A implementa√ß√£o de um micro-servi√ßo na Plataforma Nacional de Justi√ßa, bem como a implementa√ß√£o de uma interface de usu√°rio que utiliza esse servi√ßo, constitui um ferramenta inovadora a ser utilizada em todo o pa√≠s por diferentes institui√ß√µes da Justi√ßa Brasileira. √â esperado que isso traga aumento de produtividade, redu√ß√£o de custos e mais agilidade √†s senten√ßas judiciais. O futuro trabalho envolve melhorar a precis√£o do m√©todo via fine-tuning de par√¢metros e t√©cnicas utilizadas para manipular a rede. Por exemplo, investiga√ß√µes de m√©todos alternativos para gera√ß√£o de embeddings de grafo para capturar rela√ß√µes temporais podem melhorar os resultados finais. Al√©m disso, monitorar o uso do classificador pelas diferentes institui√ß√µes pode esclarecer a experi√™ncia do usu√°rio e os benef√≠cios reais que a abordagem traz ao cidad√£o. Agradecimentos. Agradecemos calorosamente ao CNPq, CAPES, FUNCAP, BNB e √† Funda√ß√£o Edson Queiroz pelo apoio financeiro.\n",
      "‚úÖ Parte traduzida.\n",
      "üìù Tradu√ß√£o salva em: Using Complex Networks to Improve Legal Text Hierarchical Classification_traduzido.txt\n",
      "‚úÖ Tradu√ß√£o conclu√≠da: 30090 caracteres\n",
      "artigos_traduzidos/ptt5-v2 A Closer Look at Continued Pretraining of T5 Models for the Portuguese Language_traduzido.txt\n",
      "üîÑ25 Dividido em 16 partes para tradu√ß√£o\n",
      "üåç Traduzindo parte 1/16...\n",
      "ptt5-v2: Um Olhar Mais Pr√≥ximo ao Treinamento Continuado de Modelos T5 para a L√≠ngua Portuguesa\n",
      "\n",
      "Marcos Piau1[0009‚àí0001‚àí1490‚àí3476], Roberto Lotufo1,2[0000‚àí0002‚àí5652‚àí0852], e Rodrigo Nogueira1,3[0000‚àí0002‚àí2600‚àí6035]\n",
      "\n",
      "1 Escola de Engenharia El√©trica e de Computa√ß√£o, Universidade Estadual de Campinas (UNICAMP), Campinas, Brasil\n",
      "2 NeuralMind, Brasil\n",
      "3 Maritaca AI, Brasil\n",
      "\n",
      "Resumo. Apesar dos avan√ßos na Processamento de Linguagem Natural (PLN) e da crescente disponibilidade de modelos pr√©-treinados, a l√≠ngua inglesa permanece o foco prim√°rio do desenvolvimento de modelos. O treinamento continuado em corpora espec√≠ficas da l√≠ngua fornece uma solu√ß√£o pr√°tica para adaptar modelos a outras l√≠nguas. No entanto, o impacto de diferentes configura√ß√µes de treinamento sobre tarefas downstream permanece pouco explorado. Este trabalho apresenta ptt5-v2, investigando o treinamento continuado de modelos T5 para o portugu√™s. Primeiramente, desenvolvemos um conjunto de configura√ß√µes de base e treinamos modelos com tamanhos at√© 3 bilh√µes de par√¢metros. A finetuning em tr√™s tarefas downstream portuguesas (ASSIN2 STS, ASSIN2 RTE e TweetSentBR) produz resultados SOTA nos dois √∫ltimos. Em seguida, exploramos os efeitos de diferentes configura√ß√µes de treinamento, incluindo filtros de qualidade, estrat√©gias de otimiza√ß√£o e treinamento em m√∫ltiplos epochs. Surpreendentemente, seu impacto permanece subt√≠lio em compara√ß√£o com nossa configura√ß√£o de base. Lan√ßamos checkpoints pr√©-treinados ptt5-v2 e rerankers MonoT5 finetunados em HuggingFace em suas respectivas cole√ß√µes em https://huggingface.co/unicamp-dl.\n",
      "\n",
      "Palavras-chave: T5 portugu√™s ¬∑ Treinamento continuado ¬∑ Recupera√ß√£o de Informa√ß√£o\n",
      "‚úÖ Parte traduzida.\n",
      "üåç Traduzindo parte 2/16...\n",
      "A din√¢mica do processo de pr√©-treinamento foi estudada em profundidade por muitos trabalhos, como Raffel et al. [34], que introduziram o T5 e escalaram modelos para bilh√µes de par√¢metros e estabeleceram novos recordes em muitas tarefas. A tend√™ncia em aumentar o tamanho dos modelos e dos conjuntos de dados para melhorar o desempenho motivou estudos como Kaplan et al. [23] sobre leis de escala e Hoffmann et al. [18], que demonstraram a import√¢ncia do tamanho do conjunto de dados de treinamento em rela√ß√£o ao tamanho do modelo para regimes de treinamento √≥timos em termos de computa√ß√£o; mais recentemente, trabalho de Gadre et al. [14] examinou especificamente a influ√™ncia do pr√©-treinamento prolongado no desempenho de tarefas downstream. Embora a estudo da din√¢mica do pr√©-treinamento tenha sido extensa, o foco tem sido predominantemente em ingl√™s, deixando l√≠nguas n√£o-ingl√™s menos exploradas. O pr√©-treinamento cont√≠nuo apresenta uma abordagem estrat√©gica para adaptar esses modelos a l√≠nguas e dom√≠nios adicionais usando significativamente menos dados e recursos computacionais do que treinar desde o in√≠cio. Este m√©todo envolve pr√©-treinar adicionalmente em corpora espec√≠ficas da l√≠ngua, o que foi mostrado para melhorar substancialmente o desempenho do modelo em tarefas downstream na l√≠ngua-alvo [32,6,25,5,42,11]. No entanto, h√° uma falta de investiga√ß√µes detalhadas sobre como diferentes configura√ß√µes durante a fase de pr√©-treinamento cont√≠nuo influenciam o desempenho de tarefas downstream, com a maioria dos estudos apenas buscando resultados l√≠deres em benchmark sem uma an√°lise minuciosa dos fatores subjacentes. Neste trabalho, estudamos o pr√©-treinamento cont√≠nuo de modelos T5 para a l√≠ngua portuguesa, analisando o impacto de v√°rias configura√ß√µes no desempenho de tarefas downstream. Em vez de apenas focar em alcan√ßar resultados de ponta, nosso estudo tamb√©m investiga como fatores como tamanho do modelo, escalas de otimiza√ß√£o e aplica√ß√£o de filtros de qualidade no conjunto de dados de pr√©-treinamento afetam o desempenho. Continuamos o pr√©-treinamento do modelo T5 da Google com at√© 3 bilh√µes de par√¢metros em textos portugueses.\n",
      "‚úÖ Parte traduzida.\n",
      "üåç Traduzindo parte 3/16...\n",
      "Ao experimentar com diferentes configura√ß√µes na etapa de pr√©-treinamento, observamos efeitos nuances nos tarefas downstream, com alguns ajustes apenas marginalmente superando os baseline. Nossos achados tamb√©m sugerem que, embora o pr√©-treinamento cont√≠nuo melhore as capacidades do modelo, os incrementos no desempenho diminuem √† medida que o tamanho do modelo aumenta. Os modelos T5 [34] demonstram adaptabilidade em v√°rias tarefas de processamento de linguagem natural (NLP) devido √† sua arquitetura encoder-decoder. Esta estrutura permite que eles processem texto tanto para compreens√£o quanto para gera√ß√£o, fornecendo um advantage sobre modelos apenas encoder como BERT. Embora n√£o seja o foco desse trabalho, a adaptabilidade do T5 para fins-tuning com base em instru√ß√µes, como visto em FLAN-T5 [8], tamb√©m permite aplica√ß√µes zero-shot e few-shot eficazes. Esses fatores, combinados com a escassez de modelos de encoder-decoder pr√©-treinados em portugu√™s, motivam nossa escolha de continuar a investiga√ß√£o da arquitetura T5 nesse estudo.\n",
      "\n",
      "2 Trabalhos Relacionados\n",
      "\n",
      "O modelo T5 [34] √© um transformador encoder-decoder, e uma de suas principais inova√ß√µes foi transformar todas as tarefas em um formato texto-para-texto, permitindo uma abordagem unificada; escalando os modelos para 11 bilh√µes de par√¢metros, eles consolidaram a abordagem de transfer√™ncia de aprendizado, estabelecendo novos recordes de desempenho para GLUE [46], SuperGLUE [45], CNN/Daily Mail [17] benchmarks. Foi pr√©-treinado usando o objetivo de \"corrup√ß√£o de span\" sobre o conjunto de dados C4 (\"Colossal Clean Crawled Corpus\"), onde sequ√™ncias consecutivas aleat√≥rias no input s√£o substitu√≠das por tokens de m√°scara especial, e o modelo √© treinado para prever esses tokens corrompidos (modelos com at√© 11 bilh√µes de par√¢metros). Com base nessa funda√ß√£o, mT5 [48] estendeu o framework T5 para configura√ß√µes multil√≠ngues, tendo sido pr√©-treinado no conjunto de dados multil√≠ngue mC4, que cobre 101 l√≠nguas (modelos com at√© 13 bilh√µes de par√¢metros). PTT5 [6] adaptou ainda mais o T5 para o portugu√™s, continuando o pr√©-treinamento de modelos T5 no conjunto de dados BrWac [44].\n",
      "‚úÖ Parte traduzida.\n",
      "üåç Traduzindo parte 4/16...\n",
      "Este abordagem levou a melhorias significativas em tarefas de linguagem portuguesa downstream, que foram ainda mais melhoradas por um tokenizador de linguagem portuguesa. Para clareza, faremos refer√™ncia ao trabalho de Carmo et al. como ptt5-v1. Outras adapta√ß√µes internacionais not√°veis do T5/mT5 incluem it5 [40] (italiano), AfriTeVa [22] (l√≠nguas africanas de baixa recursos), AraT5 [29] (√°rabe) e plT5 [7] (polon√™s). Bertimbau [42], uma adapta√ß√£o popular do modelo de encoder BERT, permanece influente no modelo de linguagem portuguesa. Outros que exploram arquiteturas de encoder incluem Albertina [37], DeBERTinha [5], o trabalho de Gomes et al. [16] (que pr√©-treina um modelo de Roberta), e de Morais et al. [28]. Refletindo uma tend√™ncia mais ampla, v√°rios modelos portugueses recentes priorizam arquiteturas de decoder apenas, como Sabi√° [32], Gl√≥ria [27], Bode [15], Cabrita [25] e Gerv√°sio [39]. No espa√ßo encoder-decoder, o trabalho de Carmo et al. (ptt5-v1) explorou a adapta√ß√£o de modelos T5 para o portugu√™s. Al√©m de modelos portugueses gen√©ricos, v√°rios trabalhos se especializam em dom√≠nios customizados: de Barros et al. [2] e BERTabaporu [10] foram projetados para dados de m√≠dia social portuguesa, enquanto Berta√∫ [13] se concentra em linguagem financeira.\n",
      "\n",
      "3 Metodologia\n",
      "\n",
      "Esta se√ß√£o descreve a metodologia para pr√©-treinar e avaliar nossos principais experimentos, cobrindo o conjunto de dados de pr√©-treinamento, vocabul√°rio de linguagem espec√≠fica, arquiteturas de modelo, estrat√©gias de otimiza√ß√£o, processos de fine-tuning e valida√ß√£o para tarefas downstream.\n",
      "\n",
      "3.1 Prepara√ß√£o cont√≠nua sem supervis√£o\n",
      "\n",
      "Como dados de pr√©-treinamento, utilizamos a segmenta√ß√£o portuguesa do conjunto de dados mC4 (a partir de agora referido como mC4-pt), compreendendo aproximadamente 524 GB de texto n√£o comprimido em 169 milh√µes de documentos. Este conjunto de dados √© significativamente maior do que o utilizado para pr√©-treinar modelos ptt5-v1, que originou-se do conjunto de dados BrWac [44] e consistiu em cerca de 15 GB de texto de 7,4 milh√µes de documentos ap√≥s pr√©-processamento. Adotamos o vocabul√°rio de linguagem portuguesa do ptt5-v1.\n",
      "‚úÖ Parte traduzida.\n",
      "üåç Traduzindo parte 5/16...\n",
      "Este tokenizer de senten√ßa Unigram [24], composto por 32.000 tokens, foi treinado sobre um corpus de 2 milh√µes de documentos da Wikipedia em portugu√™s. Essa vocabul√°ria compartilha o mesmo n√∫mero de tokens e tokens de controle que o T5, facilitando o uso direto dos checkpoints do modelo da Google. Como objetivo de pr√©-treinamento, foi empregada a tarefa de corrup√ß√£o de span, utilizando batches de 128 sequ√™ncias de 512 tokens (65.536 tokens) - uma metodologia consistente com o experimento de base de Raffel et al. [34]. O otimizador Adafactor [41] com uma taxa de aprendizado constante de 0,001 e cross-entropia como perda foi utilizado durante todo o processo de pr√©-treinamento. Usando esses ajustes experimentais, come√ßamos a partir dos checkpoints originais da Google com tamanhos que variam desde t5-pequeno (60M par√¢metros) at√© t5-3B (3B par√¢metros), e realizamos uma √©poca completa de pr√©-treinamento sobre o conjunto de dados mC4-pt. Considerando esses ajustes, uma √©poca completa sobre o conjunto de dados mC4-pt compreende aproximadamente 1.764.515 passos de treinamento e 116 bilh√µes de tokens de treinamento. Experimentos de pr√©-treinamento adicionais est√£o detalhados na Se√ß√£o 5.1. Ambos os experimentos de pr√©-treinamento e fine-tuning utilizaram dispositivos TPUv2-8 e TPUv3-8, aproveitando os frameworks t5 [34] e seqio [36].\n",
      "\n",
      "3.2 Ajuste supervisionado para tarefas downstream\n",
      "\n",
      "Avaliamos o impacto do nosso pr√©-treinamento em tr√™s tarefas de linguagem portuguesa downstream: ASSIN2 RTE, ASSIN2 STS e TweetSentBR. O conjunto de dados ASSIN2 [31] fornece duas tarefas: RTE (Reconhecimento de Entailment Textual), que envolve determinar se uma senten√ßa implica outra, e STS (Sem√¢ntica de Similaridade Textual), que quantifica a similaridade sem√¢ntica entre pares de senten√ßas em uma escala de 1 a 5. O conjunto de dados TweetSentBR [4] √© uma tarefa de an√°lise de sentimento para tweets em portugu√™s brasileiro, classificando-os como positivos, negativos ou neutros. As Tabelas 1 e 2 mostram detalhes e exemplos adicionais para cada tarefa.\n",
      "‚úÖ Parte traduzida.\n",
      "üåç Traduzindo parte 6/16...\n",
      "Conjunto de tarefas Preferido m√©trica Treinamento/valida√ß√£o/teste Pontua√ß√£o aleat√≥ria Sa√≠das poss√≠veis ASSIN2 RTE Classifica√ß√£o bin√°ria F1-macro 6.500/500/2.448 50 {Entailment, None} ASSIN2 STS Regress√£o Pearson 6.500/500/2.448 0 [1, 5] TweetSentBR Classifica√ß√£o multiclass (3) F1-macro 11.525/1.281/1.982 32,4 {negativo, positivo, neutro} Tabela 1: Conjuntos de tarefas downstream. Conjunto de dados Exemplos de entrada Exemplos de alvo ASSIN2 RTE assin2_rte senten√ßa1: Uma pessoa est√° escovando um gato senten√ßa2: O pelo de um gato est√° sendo penteado por uma pessoa Entailment ASSIN2 STS assin2_stsb senten√ßa1: Uma mulher est√° cortando vegetais senten√ßa2: Uma mulher est√° cortando br√≥colis 4,2 TweetSentBR ttsbr_neg_pos_neu_sentiment_pt: adorando esse com dr dr√°uzio varela positivo Tabela 2: Conjuntos de tarefas de entrada e alvo Finetunamos os modelos pr√©-treinados por 100 √©pocas com batches de 128 sequ√™ncias e um comprimento m√°ximo de 512 tokens, usando Adafactor como otimizador com uma taxa de aprendizado constante de 0,001. O checkpoint do modelo que apresentou o melhor desempenho no conjunto de valida√ß√£o foi selecionado para testes, e a decodifica√ß√£o greedy foi utilizada como m√©todo de decodifica√ß√£o. Porque TweetSentBR n√£o tem um conjunto de valida√ß√£o, reservamos 10% dos dados de treinamento para valida√ß√£o e usamos o restante de 90% para treinamento. Todas as tarefas foram abordadas usando um formato de texto-para-texto. Especificamente para a tarefa ASSIN2 STS, que envolve a previs√£o de valores cont√≠nuos no intervalo entre 1 e 5, adotamos a estrat√©gia de Raffel et al. [34], arredondando os scores de alvo para o incremento mais pr√≥ximo de 0,2 e convertendo esses para strings, o que a configura como um problema de classifica√ß√£o multiclass compat√≠vel com o formato de texto-para-texto. ptt5-v2 5 Para comparar a qualidade dos novos checkpoints com alternativas existentes, tamb√©m utilizamos o mesmo procedimento de finetuning nos modelos Google T5 e mT5. 3.\n",
      "‚úÖ Parte traduzida.\n",
      "üåç Traduzindo parte 7/16...\n",
      "3 MonoPTT5 Rerankers Para avaliar a adapta√ß√£o dos modelos ptt5-v2 para tarefas de recupera√ß√£o de informa√ß√£o, especificamente para reranking de passagens, treinamos rerankers MonoT5 [30] utilizando checkpoints gerados como descrito na Se√ß√£o 3.1. Chamamos esses modelos de MonoPTT5. Os rerankers MonoT5 s√£o usados para reranking de passagens, um processo em duas etapas: primeiro, um m√©todo menos computacionalmente oneroso como BM25 gera um conjunto inicial de documentos relevantes para uma dada consulta; o modelo de reranker ent√£o reranka um subconjunto desses documentos para melhorar a ordena√ß√£o de relev√¢ncia. Durante o treinamento, o modelo aprende de forma supervisionada em texto para texto para gerar tokens correspondentes a r√≥tulos relevantes e n√£o relevantes. Para infer√™ncia, decodamos de forma avarice um token √∫nico e calculamos o softmax sobre os logits dos dois tokens poss√≠veis, usando a probabilidade da classe positiva como a pontua√ß√£o de relev√¢ncia. Adaptamos o formato de entrada e alvo para o idioma portugu√™s √† estrutura \"Pergunta: {query} Documento: {document} Relevante:\", atribuindo os tokens \"Sim\" (relevante) e \"N√£o\" (n√£o relevante). Esse formato √© aplicado durante tanto o treinamento quanto a infer√™ncia, independentemente do idioma de entrada. O conjunto de treinamento originou-se do conjunto de dados mMARCO [3], uma vers√£o traduzida do conjunto de dados de recupera√ß√£o de passagens MS MARCO [1], originalmente em ingl√™s, para 13 idiomas, incluindo o portugu√™s. O conjunto de treinamento consiste em tr√≠plices (consulta, passagem relevante, passagem n√£o relevante), que dividimos em pares de exemplos de treinamento, com cada par contendo a consulta associada a uma passagem ‚Äì seja relevante ou n√£o relevante ‚Äì o que cria um exemplo para cada r√≥tulo. Criamos um conjunto de treinamento bilingue portugu√™s-ingl√™s atribuindo aleatoriamente um dos dois idiomas a cada tripla de treinamento. Essa abordagem \"translate-train\" [9,48,20] aproveita a amplia√ß√£o de dados sint√©ticos por meio da integra√ß√£o de tradu√ß√µes de m√°quina com dados de texto originais para expandir substancialmente o material de treinamento dispon√≠vel na l√≠ngua-alvo.\n",
      "‚úÖ Parte traduzida.\n",
      "üåç Traduzindo parte 8/16...\n",
      "Pesquisas anteriores [3, 38, 9] demonstraram a efic√°cia dessa estrat√©gia de treinamento bilingue, o que motivou nossa ado√ß√£o desse m√©todo. Os modelos foram treinados por 100k passos com tamanhos de lote de 128 sequ√™ncias e comprimento m√°ximo de 512 tokens, utilizando Adafactor com uma taxa de aprendizado constante de 0,001 como otimizador. Inst√¢ncias que excediam o comprimento de token m√°ximo foram exclu√≠das do conjunto de treinamento; essas constitu√≠ram aproximadamente 0,01% do conjunto de treinamento e foram predominantemente atribu√≠das a dados de tradu√ß√£o ru√≠dos. Dado os recursos computacionais significativos necess√°rios para treinar esses rerankers, nos concentramos exclusivamente em modelos baseados nos principais checkpoints do ptt5-v2. Para avaliar os rerankers, primeiro usamos BM25 para gerar um conjunto inicial de documentos relevantes e, em seguida, rerankamos os documentos mais relevantes. As m√©tricas de recupera√ß√£o s√£o calculadas comparando essa lista ordenada com os julgamentos de relev√¢ncia de 4 Todos os aplicativos de BM25 nessa obra utilizam a implementa√ß√£o do Pyserini [26] com par√¢metros padr√£o k1 = 0,9 e b = 0,4 6 M. Piau et al. em cada conjunto de dados. Consideramos dois cen√°rios de recupera√ß√£o: in-dom√≠nio (usando o conjunto \"pequeno dev\" de 6.980 consultas do mMARCO-pt) e zero-shot (usando o conjunto portugu√™s de 249 consultas anotadas do mRobust [21]). Devido ao comprimento de documento mais longo no mRobust, segmentamos documentos em janelas de janela de senten√ßa mov√≠vel usando um pipeline de sentencizador Spacy [19], com comprimento m√°ximo de 8 e passo de 4 senten√ßas para mitigar a truncagem durante a reranking. 4 Resultados Principais A Tabela 3 mostra os resultados nas tarefas downstream consideradas. No task de ASSIN2 RTE, nosso modelo 3B estabelece um novo SOTA, superando o atual por 0,61 pontos de F1-macro. Para o conjunto de dados TweetSentBR, alcan√ßamos desempenho melhor do que os SOTAs finetunados atuais com ptt5-v2-large e ptt5-v2-3B, por 0,52 e 1,54 pontos de F1-macro, respectivamente, mas nossos resultados s√£o piores quando comparados ao GPT-4.\n",
      "‚úÖ Parte traduzida.\n",
      "üåç Traduzindo parte 9/16...\n",
      "Destacamos que nossos ptt5-v2 foram treinados exclusivamente em dados de treinamento para cada tarefa utilizando o framework de texto para texto sem qualquer amplia√ß√£o de dados ou adapta√ß√£o √† arquitetura do modelo, ao contr√°rio dos trabalhos de [2] e [38], que detinham o SOTA para TweetSentBR e ASSIN2 RTE. No entanto, nossos modelos n√£o superaram o SOTA atual no task ASSIN2 STS; no entanto, ptt5-v2 ainda apresenta desempenho melhor que os modelos mT5 e T5 com tamanhos aproximados, e isso tamb√©m √© o √∫nico task em que um modelo ptt5-v2 menor (ptt5-v2-large) apresenta melhor desempenho que um modelo grande ptt5-v2-3B.\n",
      "\n",
      "Binary classification Regression Multiclass classification ‚Üê Retrieval ASSIN2 RTE ASSIN2 STS TweetSentBR ‚Üê mMARCO-pt mRobust-pt Par√¢metros do Modelo F1-macro Pearson F1-macro NPM RR@10 nDCG@20 T5 t5-small 60M 83,66 0,738 62,14 61,71 - - t5-base 220M 85,80 0,764 65,43 65,63 - - t5-large 770M 88,91 0,790 68,22 69,95 - - t5-3B 3B 90,78 0,827 72,58 74,56 - - mT5 mt5-small 300M 75,36 0,688 61,81 54,35 - - mt5-base 580M 79,39 0,749 70,76 63,46 - - mt5-large 1,2B 88,25 0,753 61,11 64,76 - - mt5-xl 3,7B 91,81 0,827 77,05 77,45 - - ptt5-v2 ptt5-v2-small 60M 87,14 0,782 70,99 69,86 0,273 0,344 ptt5-v2-base 220M 88,36 0,814 73,20 72,82 0,311 0,384 ptt5-v2-large 770M 91,73 0,839 76,78 77,68 0,315 0,462 ptt5-v2-3B 3B 92,68 0,829 77,80 78,48 0,332 0,512 SOTA supervisionado - 92,07 [38] 0,868 [37] 76,26 [2] - 0,306 [38] 0,391 [21] Baselines de poucas itera√ß√µes de [32] GPT-4 - 90,96 0,776 82,40 - - - GPT-3.5-turbo - 88,28 0,664 74,39 - - - Tabela 3: Principais resultados ap√≥s fine-tuning. Para SOTAs supervisionadas, tamanhos de modelo s√£o os seguintes: [38] (335M), [37] (900M), [2] (110M), [38] e [21] (580M). Resultados NPM excluem tarefas de recupera√ß√£o. ptt5-v2\n",
      "\n",
      "Al√©m disso, tamb√©m incorporamos o Metrico Normalizado Preferencial (NPM) [43] para facilitar a avalia√ß√£o do desempenho geral de um modelo treinado pr√©vio em m√∫ltiplas tarefas. O NPM normaliza o m√©trico preferencial de uma tarefa (por exemplo,\n",
      "‚úÖ Parte traduzida.\n",
      "üåç Traduzindo parte 10/16...\n",
      ", F1-macro para ASSIN2 RTE), atribuindo um valor de 0 para representar desempenho aleat√≥rio e 100 para denotar desempenho m√°ximo. A seguir est√° a equa√ß√£o utilizada para calcular o NPM para um modelo dado e um conjunto N de tarefas: NPM = 100 N N X i=1 [m√©trica preferida bruta]i ‚àí[pontua√ß√£o aleat√≥ria]i [pontua√ß√£o m√°xima]i ‚àí[pontua√ß√£o aleat√≥ria]i (1) Dado que os rerankers MonoPTT5 foram treinados exclusivamente a partir de checkpoints pr√©-treinados ptt5-v2, as tarefas de recupera√ß√£o foram exclu√≠das desta avalia√ß√£o. Portanto, apenas consideramos tarefas ASSIN2 RTE, ASSIN2 STS e TweetSentBR. Para cada modelo, calculamos seu desempenho agregado primeiro determinando o NPM para cada tarefa e em seguida computando a m√©dia desses valores. Nossos modelos ptt5-v2 t√™m valores de NPM mais altos do que os modelos T5 e mT5 com consideravelmente mais par√¢metros: por exemplo, ptt5-v2-base √© apenas ultrapassado por t5-3B (‚àº13,6x maior) e t5-xl (‚àº16,81x maior); essa diferen√ßa de desempenho, no entanto, √© mais pronunciada em modelos menores, se estreitando √† medida que o tamanho do modelo aumenta. Um resultado semelhante tamb√©m foi observado por Xue et al. [48], que analisou o desempenho dos modelos T5 e mT5 em rela√ß√£o ao benchmark SQuAD [35], observando uma diferen√ßa de desempenho entre t5-small e t5-base vs modelos mT5 de tamanhos equivalentes, que se diminui a partir de t5-large. Essa diferen√ßa de desempenho observada em tamanhos de modelo menores √© vantajosa quando consideramos ambientes limitados por recursos computacionais, aumentando o n√≠vel m√°ximo ating√≠vel de desempenho; adicionalmente, um tokenizador espec√≠fico para l√≠ngua reduz a divis√£o do texto em tokens menores, levando a uma lat√™ncia mais baixa e ao potencial de acomodar mais texto no mesmo contexto de janela de tokens m√°xima. Interessantemente, os modelos mT5 tendem a mostrar valores de NPM mais baixos, exceto na faixa de 3 bilh√µes de par√¢metros, onde eles ligeiramente superam os modelos T5. Para as tarefas de recupera√ß√£o, nossos rerankers MonoPTT5 foram capazes de estabelecer novos recordes de SOTA para ambos mMARCO-pt e mRobust-pt.\n",
      "‚úÖ Parte traduzida.\n",
      "üåç Traduzindo parte 11/16...\n",
      "Para o conjunto de dados mMARCO-pt, os modelos que come√ßaram com o tamanho t5-base foram capazes de superar o SOTA atual; o reranker com 3 bilh√µes de par√¢metros obteve um ganho de +0,026 pontos em MRR@10. No mRobust-pt, nossos rerankers grandes e de 3B superaram o SOTA atual em +0,071 e +0,121 em termos de nDGC@20, respectivamente. Uma an√°lise mais aprofundada das tarefas de recupera√ß√£o √© realizada na se√ß√£o 5.2.\n",
      "\n",
      "5 Abla√ß√µes\n",
      "5.1 Experimentos de pr√©-treinamento adicionais\n",
      "Essa se√ß√£o inclui experimentos de pr√©-treinamento adicionais aos descritos na se√ß√£o 3.1.\n",
      "\n",
      "8 M. Piau et al.\n",
      "Compara√ß√£o com ptt5-v1:\n",
      "Dada a t√≠tulo do nosso trabalho, uma pergunta pertinente surge: como os modelos ptt5-v2 se comparam com o trabalho em ptt5-v1? Algumas diferen√ßas-chave existem no pr√©-treinamento do ptt5-v1. Notavelmente, ele utilizou BrWac, um conjunto de dados significativamente menor, e um objetivo de pr√©-treinamento ligeiramente diferente (denoising, onde alguns tokens de entrada s√£o mascarados e o modelo √© treinado para prever o texto original, em vez de corrup√ß√£o de spans). Al√©m disso, o ptt5-v1 empregou modelos variando de t5-pequeno a t5-grande com um otimizador Adafactor e uma taxa de aprendizado de 0,003 (tr√™s vezes maior do que nosso setting). O ptt5-v1 tamb√©m explorou tanto a vocabul√°ria original do T5 quanto um tokenizador de linguagem portuguesa espec√≠fica. Em contraste, o ptt5-v2 exclusivamente utiliza o √∫ltimo. Para garantir uma compara√ß√£o justa, finetunamos os checkpoints do ptt5-v1 seguindo a metodologia descrita na se√ß√£o 3.2. A figura 1 apresenta os valores de NPM para ambos ptt5-v1 e ptt5-v2, ao lado de compara√ß√µes com os modelos mT5 e T5. Os dados corroboram as melhorias alcan√ß√°veis atrav√©s do pr√©-treinamento monol√≠ngue na l√≠ngua-alvo, o que √© ainda mais amplificado pelo emprego de um tokenizador dedicado. Em compara√ß√£o entre as duas itera√ß√µes do ptt5, uma disparidade de desempenho favor√°vel ao ptt5-v2 √© aparente para os tamanhos pequeno e grande, com o maior gap observado para o grande; no entanto, os modelos do tamanho base apresentam desempenho marginalmente superior na variante ptt5-v1.\n",
      "‚úÖ Parte traduzida.\n",
      "üåç Traduzindo parte 12/16...\n",
      "Surpreendentemente, o desempenho do mT5 atr√°s de todos os outros modelos, incluindo o T5 monol√≠ngue ingl√™s, exceto na faixa de par√¢metros de 3B, onde se aproxima do ptt5-v2 e supera o T5. 10 8 10 9 Par√¢metros n√£o de embedding 55 60 65 70 75 Base pequena grande 3B T5 mT5 ptt5-v2 ptt5-v1 (vocabul√°rio T5) ptt5-v1 (vocabul√°rio PTT5) Fig. 1: Par√¢metros vs NPM para configura√ß√µes de T5 vari√°veis. Filtros de qualidade: Em nossos experimentos prim√°rios, utilizamos todo o conjunto de dados mC4-pt, contendo aproximadamente 116 bilh√µes de tokens de treinamento, na fase de pr√©-treinamento. Nesse experimento adicional, consideramos os filtros de qualidade MassiveText [33] para investigar o impacto desse processo de filtragem em tarefas downstream. Aplicando esses filtros ao mC4-pt reduz o n√∫mero de tokens de treinamento para aproximadamente 82 bilh√µes, uma redu√ß√£o de cerca de 30%. Esse experimento foi restrito a modelos de tamanho t5-base, mantendo o mesmo tamanho de lote e estrat√©gia de otimiza√ß√£o utilizados nos experimentos principais. A Figura 2 mostra o efeito da aplica√ß√£o dos filtros de qualidade MassiveText ptt5-v2 na performance de tarefas downstream, medida em termos de NPM. O pr√©-treinamento com o conjunto de dados filtrado apresenta uma tend√™ncia ascendente na performance, que continua sem satura√ß√£o at√© o final de um epoch de mC4-pt, que √© o √∫ltimo ponto na plotagem. √â importante notar que um epoch no conjunto de dados filtrado tem menos passos do que o conjunto de dados completo, ent√£o, no final do conjunto de dados completo, os dados s√£o repetidos no conjunto de dados filtrado. Apesar da tend√™ncia ascendente favor√°vel ao pr√©-treinamento com o conjunto de dados filtrado, a diferen√ßa em termos de NPM √© pequena no marco de um epoch de mC4-pt. 0 20 40 60 80 100 120 Tokens de pr√©-treinamento portugu√™s (B) 67 68 69 70 71 72 73 74 NPM um epoch de mC4-pt um epoch de mC4-pt com filtros de qualidade mC4-pt mC4-pt com filtros de qualidade Fig. 2: Efeito da aplica√ß√£o de filtros de qualidade no mC4-pt. Linhas verticais indicam o n√∫mero de tokens de pr√©-treinamento para cada conjunto de dados considerado.\n",
      "‚úÖ Parte traduzida.\n",
      "üåç Traduzindo parte 13/16...\n",
      "T√°tica de otimiza√ß√£o pr√©-treinamento: Em nossa explora√ß√£o de estrat√©gias de otimiza√ß√£o, inicialmente utilizamos Adafactor com uma taxa de aprendizado constante. Esta abla√ß√£o estende nossa investiga√ß√£o √† \"taxa de aprendizado inversa do quadrado\" agendada, utilizada por [34] em seus experimentos de pr√©-treinamento finais. Esta taxa de aprendizado computa a taxa como 1 ‚àö max(n,k), onde n representa o passo atual e k √© o n√∫mero de passos de aquecimento. Raffel et al. [34] utilizaram k = 10.000, o que estabelece a taxa de aprendizado de 0,01 para os primeiros 10k passos, subsequentemente diminuindo exponencialmente. A taxa de aprendizado no final do pr√©-treinamento, que consistiu em cerca de 1 milh√£o de passos, estava pr√≥xima de 0,001, a mesma utilizada durante a fine-tuning. A figura 3 ilustra a diferen√ßa entre essas estrat√©gias de otimiza√ß√£o. Tentando refletir de forma pr√≥xima a receita de pr√©-treinamento do T5, aplicamos essa mesma agenda em nossos experimentos iniciais. No entanto, observamos um overshoot r√°pido nos perdas de treinamento para t5-large e t5-3B dentro de horas; ajustar n apenas atrasou o overshoot sem evit√°-lo. Mudando para uma taxa de aprendizado constante de 0,001 resolveu o problema de overshoot, levando a perdas de treinamento est√°veis em todos os tamanhos de modelo e simplificando nosso setup experimental. Como o overshoot foi observado apenas nos modelos maiores e tamb√©m considerando os custos computacionais associados ao pr√©-treinamento dos modelos maiores, realizamos experimentos adicionais com 10 milh√µes de tokens de pr√©-treinamento. Figura 3: Agendamentos de taxa de aprendizado: constante vs. agendador de taxa de aprendizado inversa como fun√ß√£o de passos de treinamento. Figura 4: Efeito do agendador utilizado durante o pr√©-treinamento. √âpocas s√£o relativas ao mC4-pt.\n",
      "‚úÖ Parte traduzida.\n",
      "üåç Traduzindo parte 14/16...\n",
      "Experimentos de pr√©-treinamento com agendador \"raiz quadrada inversa\" para modelos t5-small e t5-base apenas. N√∫mero de √©pocas de pr√©-treinamento: No conjunto prim√°rio de experimentos, o conjunto de dados mC4-pt foi utilizado integralmente para pr√©-treinamento durante uma √©poca. Para explorar a influ√™ncia do n√∫mero de √©pocas de pr√©-treinamento no desempenho de tarefas downstream, realizamos experimentos em √©pocas variadas, incluindo √©pocas parciais (0,25, 0,5 e 0,75 de uma √©poca). Considerando o tempo e recursos computacionais significativos requeridos para pr√©-treinamento estendido, especialmente com modelos maiores, limitamos o pr√©-treinamento do modelo t5-large a duas √©pocas e do modelo t5-3B a uma √©poca. A dura√ß√£o reduzida da √©poca para os modelos t5-small e t5-base permitiu per√≠odos de pr√©-treinamento mais extensos para essas configura√ß√µes. Na Figura 4, os valores de NPM para o modelo t5-base s√£o mostrados com o agendador constante e o agendador da raiz quadrada inversa, em uma variedade de √©pocas de pr√©-treinamento. Observa-se que h√° uma diferen√ßa entre essas duas estrat√©gias de otimiza√ß√£o: o agendador da raiz quadrada inversa tem o advantage at√© dois epis√≥dios; ap√≥s isso, a taxa de aprendizado constante assume o comando, e at√© o √∫ltimo epis√≥dio considerado, alcan√ßam o mesmo valor. Al√©m disso, √© notado um aumento na tend√™ncia dos valores de NPM para mais √©pocas.\n",
      "\n",
      "5.2 Rerankers MonoPTT5\n",
      "\n",
      "As tarefas de recupera√ß√£o de informa√ß√µes relatadas em 3 representam o desempenho de nossos experimentos MonoPTT5, desenvolvidos com a metodologia descrita em 3.3; nessa se√ß√£o, tamb√©m relatamos os resultados para outras abordagens, incluindo BM25, e recupera√ß√£o densa usando modelos multilingues-e5 [47]. Os modelos densos s√£o usados como sistema de recupera√ß√£o em uma √∫nica etapa sem reranking; √≠ndice e recupera√ß√£o densa s√£o realizados com GPUs A100 e V100 no Google Colab, aproveitando o framework Pyserini. Para o mRobust-pt, que cont√©m documentos mais longos, mitigamos a truncagem de documentos usando a mesma estrat√©gia de divis√£o descrita na se√ß√£o 3.\n",
      "‚úÖ Parte traduzida.\n",
      "üåç Traduzindo parte 15/16...\n",
      "3, utilizando a pontua√ß√£o m√°xima entre os segmentos do documento como a pontua√ß√£o do documento. Figuras 5 e 6 s√£o utilizadas para ilustrar a discuss√£o apresentada nesta se√ß√£o. Os resultados apresentados na Tabela 3 apenas mostram a efic√°cia em cada tarefa de recupera√ß√£o de nossos modelos MonoPTT5 e os competidores SOTA. Para a tarefa de recupera√ß√£o em dom√≠nio, o conjunto de dados mMarco-pt, observamos que o BM25 √© facilmente superado por todas as alternativas consideradas, e as figuras de efic√°cia para os rerankers MonoPTT5 e os modelos multilingue-e5 s√£o semelhantes quando consideramos o tamanho comum, e os rerankers MonoPTT5 apresentam efic√°cia acima da SOTA a partir de modelos de tamanho t5-base. Para o mRobust-pt, representando um setting zero-shot, o BM25 √© apenas superado pelo reranker mT5 de Jeronymo et al. [21], e os modelos MonoPTT5 a partir do tamanho t5-base. \n",
      "\n",
      "8 10 10 9 Par√¢metros n√£o de embedding 0,150 0,175 0,200 0,225 0,250 0,275 0,300 0,325 RR@10 pequeno base grande 3B MonoPTT5 multilingue-e5 mColBert mT5 BM25 Fig. 5: Resultados de recupera√ß√£o no mMarco-pt. Os valores de mColbert e mT5 s√£o da Bonif√°cio et al. [3]. O tamanho total exclui par√¢metros de embedding.\n",
      "\n",
      "12 M. Piau et al. 10 8 10 9 Par√¢metros n√£o de embedding 0,25 0,30 0,35 0,40 0,45 0,50 pequeno base grande 3B MonoPTT5 multilingue-e5 mColBert mT5 BM25 Fig. 6: Resultados de recupera√ß√£o no mRobust-pt. Os valores de mColbert e mT5 s√£o da Jeronymo et al. [21]. O tamanho total exclui par√¢metros de embedding.\n",
      "\n",
      "6 Conclus√£o Nesta pesquisa, introduzimos o ptt5-v2, explorando a pr√©-treinamento cont√≠nua de modelos T5 para a l√≠ngua portuguesa. Pre-treinamos modelos T5 usando um tokenizador de l√≠ngua portuguesa, sobre um corpus de l√≠ngua portuguesa. Os modelos fine-tuned alcan√ßaram a SOTA nos conjuntos de dados ASSIN2 RTE e TweetSentBr, dois dos tr√™s tarefas downstream consideradas. Al√©m disso, aplicamos esses checkpoints pr√©-treinados para desenvolver rerankers MonoT5 personalizados para a l√≠ngua portuguesa, alcan√ßando desempenho top nos conjuntos de dados mMARCO-pt e mRobust-pt.\n",
      "‚úÖ Parte traduzida.\n",
      "üåç Traduzindo parte 16/16...\n",
      "Nossos principais resultados corroboram a evid√™ncia de um gap de desempenho a favor de modelos monol√≠ngues em rela√ß√£o a modelos focalizados em ingl√™s e multil√≠ngues, um gap que se estreita √† medida que aumenta a capacidade do modelo. Isso destaca a import√¢ncia do pr√©-treinamento espec√≠fico para l√≠ngua e nossa an√°lise de configura√ß√µes de pr√©-treinamento sugere que, embora o filtro de dados, estrat√©gias de otimiza√ß√£o e dura√ß√£o do pr√©-treinamento possam oferecer melhorias incrementais, os efeitos globais foram limitados em compara√ß√£o com nossos padr√µes de base e a receita de pr√©-treinamento b√°sica permaneceu robusta. Agradecimentos Obrigado √† Google pelo apoio financeiro atrav√©s do programa TRC.\n",
      "‚úÖ Parte traduzida.\n",
      "üìù Tradu√ß√£o salva em: ptt5-v2 A Closer Look at Continued Pretraining of T5 Models for the Portuguese Language_traduzido.txt\n",
      "‚úÖ Tradu√ß√£o conclu√≠da: 31554 caracteres\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import fitz  # PyMuPDF\n",
    "import json\n",
    "import requests\n",
    "import sys\n",
    "import os\n",
    "\n",
    "GROQ_API_URL = \"https://api.groq.com/openai/v1/chat/completions\"\n",
    "\n",
    "API_KEY = input(\"Digite sua chave API da Groq (ou deixe em branco para pular tradu√ß√µes): \")\n",
    "if not API_KEY:\n",
    "  print(\"‚ö†Ô∏è ATEN√á√ÉO: API_KEY n√£o definida.\")\n",
    "  sys.exit()\n",
    "\n",
    "with open('artigos_info.json', 'r', encoding='utf-8') as f:\n",
    "  artigos_info = json.load(f)\n",
    "\n",
    "try:\n",
    "  for idx, artigo in enumerate(artigos_info):\n",
    "\n",
    "    caminho_pdf = artigo['pdf']\n",
    "      \n",
    "    caminho_artigo_traduzido = 'artigos_traduzidos_pt/'+ os.path.basename(caminho_pdf).replace('.pdf', '_traduzido.txt')\n",
    "    print(caminho_artigo_traduzido)\n",
    "\n",
    "    if not os.path.isfile(caminho_artigo_traduzido):\n",
    "        try:\n",
    "            with fitz.open(caminho_pdf) as doc:\n",
    "                texto = \"\"\n",
    "                for pagina in doc:\n",
    "                    texto += pagina.get_text()\n",
    "            texto = texto.strip()\n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao extrair PDF {caminho_pdf}: {e}\")\n",
    "            sys.exit()\n",
    "    \n",
    "        # Remove referencias\n",
    "        referencias = texto.split(\"References\")\n",
    "        if len(referencias) > 1:\n",
    "          texto = \"References\".join(texto.split(\"References\")[:-1]);\n",
    "    \n",
    "        referencias = texto.split(\"Bibliography\")\n",
    "        if len(referencias) > 1:\n",
    "          texto = \"Bibliography\".join(texto.split(\"Bibliography\")[:-1]);\n",
    "    \n",
    "        tamanho_maximo = 2000\n",
    "        \n",
    "        # Divide o texto em partes menores\n",
    "        palavras = texto.split()\n",
    "        partes = []\n",
    "        parte_atual = \"\"\n",
    "          \n",
    "        for palavra in palavras:\n",
    "            if len(parte_atual) + len(palavra) + 1 <= tamanho_maximo:\n",
    "                parte_atual += (\" \" if parte_atual else \"\") + palavra\n",
    "            else:\n",
    "                if '.' in parte_atual:\n",
    "                  # Divide a parte atual nas frases com ponto\n",
    "                  lastCaracter = parte_atual[-1]\n",
    "                  frases = parte_atual.split('.')\n",
    "    \n",
    "                  parte_valida = '.'.join(frases[:-1]) + '.' if len(frases) > 1 else frases[0] + '.'\n",
    "                  restante = frases[-1]  # √∫ltima frase incompleta\n",
    "                  # if(restante):\n",
    "                  #   parte_valida += '.'\n",
    "                  if len(restante) + len(palavra) + 1 >= tamanho_maximo:\n",
    "                    partes.append(parte_valida)\n",
    "                    partes.append(restante +  ('.' if lastCaracter == '.' else \"\"))\n",
    "                    parte_atual = palavra\n",
    "                  else:\n",
    "                    partes.append(parte_valida)\n",
    "                    parte_atual = restante + \" \" + palavra\n",
    "                else:\n",
    "                    partes.append(parte_atual)\n",
    "                    parte_atual = palavra\n",
    "    \n",
    "        if parte_atual:\n",
    "            partes.append(parte_atual)\n",
    "            \n",
    "        print(f\"üîÑ{idx} Dividido em {len(partes)} partes para tradu√ß√£o\")\n",
    "    \n",
    "    \n",
    "    \n",
    "        # Traduz cada parte e junta\n",
    "        traducoes = []\n",
    "        headers = {\n",
    "            \"Authorization\": f\"Bearer {API_KEY}\",\n",
    "            \"Content-Type\": \"application/json\"\n",
    "        }\n",
    "    \n",
    "        for idx, parte in enumerate(partes):\n",
    "            print(f\"üåç Traduzindo parte {idx+1}/{len(partes)}...\")\n",
    "            prompt = (\n",
    "                \"Traduza o seguinte texto cient√≠fico para portugu√™s do Brasil. \"\n",
    "                \"A tradu√ß√£o deve ser natural, precisa e manter o sentido original. \"\n",
    "                \"A resposta deve conter apenas o texto traduzido, sem coment√°rios, explica√ß√µes ou marca√ß√µes extras.\"\n",
    "                \"Mantenha termos t√©cnicos quando apropriado.:\\n\\n\"\n",
    "                f\"{parte}\"\n",
    "            )\n",
    "    \n",
    "            payload = {\n",
    "                \"model\": \"llama3-8b-8192\",  # ou outro modelo dispon√≠vel na Groq\n",
    "                \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "                \"temperature\": 0.2\n",
    "            }\n",
    "    \n",
    "            # Taxa de limita√ß√£o para n√£o sobrecarregar a API\n",
    "            time.sleep(10)\n",
    "    \n",
    "            try:\n",
    "                response = requests.post(GROQ_API_URL, headers=headers, json=payload)\n",
    "                response.raise_for_status()\n",
    "                traducao = response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "                print(traducao)\n",
    "                traducoes.append(traducao)\n",
    "                print(\"‚úÖ Parte traduzida.\")\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Erro na tradu√ß√£o da parte {idx+1}: {e}\")\n",
    "                time.sleep(30)  # Espera mais tempo em caso de erro\n",
    "                sys.exit()\n",
    "    \n",
    "        texto_traduzido = \"\\n\".join(traducoes)\n",
    "        nome_arquivo = os.path.basename(caminho_pdf).replace('.pdf', '_traduzido.txt')\n",
    "        with open(\"artigos_traduzidos_pt/\" + nome_arquivo, 'w', encoding='utf-8') as f:\n",
    "            f.write(texto_traduzido)\n",
    "        print(f\"üìù Tradu√ß√£o salva em: {nome_arquivo}\")\n",
    "        print(f\"‚úÖ Tradu√ß√£o conclu√≠da: {len(texto_traduzido)} caracteres\")\n",
    "    else:\n",
    "        print(\"PDF: \" + caminho_pdf + \" j√° traduzido, pulando..\")\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "  print(f\"Erro ao processar artigo: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "topicosdb",
   "language": "python",
   "name": "venvdb"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
